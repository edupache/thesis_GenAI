{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artefact I - RAG Application just with Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initial Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python \n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# LangChain \n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "# Set OpenAi key as an environment variable\n",
    "os.environ[\"sk-proj-Sm1whIiewmhrMZpq7rlBT3BlbkFJQ5PTl7vQLyybJYSzeUFC\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stream_name</th>\n",
       "      <th>created_date</th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>like_count</th>\n",
       "      <th>report_count</th>\n",
       "      <th>username</th>\n",
       "      <th>author_user_id</th>\n",
       "      <th>author_position</th>\n",
       "      <th>author_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85876</th>\n",
       "      <td>Jobs</td>\n",
       "      <td>2022-10-20 17:49:14</td>\n",
       "      <td>5888937</td>\n",
       "      <td>4939735</td>\n",
       "      <td>Me</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Risa_Gross</td>\n",
       "      <td>efe02e94-0e60-462a-a619-a5bc67fc2da4</td>\n",
       "      <td>Advanced Crew Leader</td>\n",
       "      <td>suspended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65568</th>\n",
       "      <td>Jobs</td>\n",
       "      <td>2023-02-12 18:23:49</td>\n",
       "      <td>6250664</td>\n",
       "      <td>5368074</td>\n",
       "      <td>@Brady_Macklin</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Ricky_Ellis</td>\n",
       "      <td>7f996efb-c280-4fbc-aed3-890599eba1e9</td>\n",
       "      <td>Advanced Crew Leader</td>\n",
       "      <td>suspended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15290</th>\n",
       "      <td>Jobs</td>\n",
       "      <td>2023-12-08 22:47:47</td>\n",
       "      <td>7319986</td>\n",
       "      <td>6529232</td>\n",
       "      <td>Refer to previous comment. Maybe she didn‚Äôt kn...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Megan_Urias</td>\n",
       "      <td>c590a2b1-9d02-442e-8a6a-fc89de0ae23a</td>\n",
       "      <td>Crew Member</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      stream_name         created_date  post_id  comment_id  \\\n",
       "85876        Jobs  2022-10-20 17:49:14  5888937     4939735   \n",
       "65568        Jobs  2023-02-12 18:23:49  6250664     5368074   \n",
       "15290        Jobs  2023-12-08 22:47:47  7319986     6529232   \n",
       "\n",
       "                                            comment_text  like_count  \\\n",
       "85876                                                 Me           0   \n",
       "65568                                     @Brady_Macklin           1   \n",
       "15290  Refer to previous comment. Maybe she didn‚Äôt kn...           0   \n",
       "\n",
       "       report_count     username                        author_user_id  \\\n",
       "85876             0   Risa_Gross  efe02e94-0e60-462a-a619-a5bc67fc2da4   \n",
       "65568             0  Ricky_Ellis  7f996efb-c280-4fbc-aed3-890599eba1e9   \n",
       "15290             0  Megan_Urias  c590a2b1-9d02-442e-8a6a-fc89de0ae23a   \n",
       "\n",
       "            author_position author_status  \n",
       "85876  Advanced Crew Leader     suspended  \n",
       "65568  Advanced Crew Leader     suspended  \n",
       "15290           Crew Member        active  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import users file\n",
    "#path = \"/home/ubuntu/thesis_GenAI/data/production_datasets/cleaned_datasets\"\n",
    "path = \"C:\\\\Users\\\\eduar\\\\Documents\\\\Master_Thesis\\\\GenAI_Thesis_Beekeeper\\\\data\\\\production_datasets\\\\cleaned_datasets\"\n",
    "file_name = \"comments_cleaned.csv\"\n",
    "file_path = os.path.join(path, file_name)\n",
    "df_comments = pd.read_csv(file_path)\n",
    "\n",
    "# Create a sample of 50,000 comments to test\n",
    "df_comments_to_test = df_comments.sample(300)\n",
    "# Print a sample\n",
    "df_comments.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Data for Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Congratulations üéâ ü•≥',\n",
       " 'I need a cm',\n",
       " 'I can do it',\n",
       " 'Yeah but where is his ppe lol üòÜ',\n",
       " 'I just spoke with my as I believe they are sending over the crew that is on standby if we finish our current job we can go help as well we are a team here at ppl tannersville',\n",
       " 'Do you not meet your crew lead there (1405 Bay Ridge)??',\n",
       " 'Filled - thank you all',\n",
       " 'Me',\n",
       " 'Considering the space you have there, the shift looks good! I appreciate that you have the stop slow paddle available just in case it is needed. \\n\\n     Coachable moment: place the paddle in a safer location. It appears to be staged across the pedestrian path way. Maybe place it back towards the fence or near the trash can out of the way. \\n   \\n  Over all great job team. \\n\\nThe eagle is perched watching ove the site ready to act if needed. (Picture #4)',\n",
       " '@Lance_Fountain thank you! we have added you to the order, thank you everyone who volunteered!']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to prepare the data to be loaded to the database\n",
    "def prepare_data(df):   \n",
    "    documents = []\n",
    "    metadatas = []\n",
    "    ids = []\n",
    "        \n",
    "    for idx, row in df.iterrows(): \n",
    "        documents.append(row.iloc[4])\n",
    "        metadatas.append({\n",
    "            'stream_name': row.iloc[0],\n",
    "            'created_date': row.iloc[1],\n",
    "            'post_id': row.iloc[2],\n",
    "            'comment_id': row.iloc[3],\n",
    "            'like_count': row.iloc[5],\n",
    "            'report_count': row.iloc[6],\n",
    "            'username': row.iloc[7],\n",
    "            'author_user_id': row.iloc[8],\n",
    "            'author_position': row.iloc[9],\n",
    "            'author_status': row.iloc[10]\n",
    "        })\n",
    "        ids.append(str(idx+1))       \n",
    "    \n",
    "    return documents, metadatas, ids\n",
    "\n",
    "documents, metadatas, ids = prepare_data(df_comments_to_test)\n",
    "\n",
    "print(type(documents))\n",
    "documents[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Congratulations üéâ ü•≥', metadata={'stream_name': 'Safety & Operations', 'created_date': '2022-12-02 15:39:40', 'post_id': 6032891, 'comment_id': 5102820, 'like_count': 0, 'report_count': 0, 'username': 'Maegan_Winters', 'author_user_id': '809b6f68-e69a-4217-84eb-30c53a08b05a', 'author_position': 'Crew Leader', 'author_status': 'active'}),\n",
       " Document(page_content='I need a cm', metadata={'stream_name': 'Jobs', 'created_date': '2022-01-21 13:47:25', 'post_id': 4978497, 'comment_id': 3914808, 'like_count': 0, 'report_count': 0, 'username': 'weekend_dispatch', 'author_user_id': 'cd381448-d11f-41b6-b15c-b2dd0a884bf5', 'author_position': 'Weekend Dispatch', 'author_status': 'active'})]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text splitter\n",
    "PERSIST_DIRECTORY = \"C:\\\\Users\\\\eduar\\\\Documents\\\\Master_Thesis\\\\GenAI_Thesis_Beekeeper\\\\data\\\\datasets_db\"\n",
    "\n",
    "# split it into chunks\n",
    "text_splitter = CharacterTextSplitter(    \n",
    "    separator=\"\\n\\n\",\n",
    "    chunk_size=350,\n",
    "    chunk_overlap=0,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,        \n",
    "    )\n",
    "\n",
    "docs = text_splitter.create_documents(documents, metadatas=metadatas)\n",
    "docs[:2]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have a safe day, @Jonathan_Muha!\n"
     ]
    }
   ],
   "source": [
    "# Create a database\n",
    "\n",
    "# create the open-source embedding function\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-mpnet-base-v2\")\n",
    "\n",
    "# save to disk\n",
    "db = Chroma.from_documents(docs,\n",
    "                           embedding_function,\n",
    "                           #ids=ids,\n",
    "                           persist_directory=PERSIST_DIRECTORY)\n",
    "\n",
    "# Test the db\n",
    "query = \"What it got said about Jonathan_Muha\"\n",
    "docs = db.similarity_search(query)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating our self-querying retriever\n",
    "\n",
    "Now we can instantiate our retriever. To do this we‚Äôll need to provide some information upfront about the metadata fields that our documents support and a short description of the document contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata description\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"stream_name\",\n",
    "        description=\"The stream where the comment was poste. One of ['Jobs','Water Break','Safety & Operations','OSC, We Can Help','Flagger Force Connect','The Whiteboard','Test Stream']\",\n",
    "        type=\"object\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"created_date\",\n",
    "        description=\"The datetime when the comment was posted\",\n",
    "        type=\"object\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"post_id\",\n",
    "        description=\"The id of the post where the comment was posted\",\n",
    "        type=\"int64\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"comment_id\",\n",
    "        description=\"The id of the comment\",\n",
    "        type=\"int64\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"like_count\",\n",
    "        description=\"The number of likes received by the comment\",\n",
    "        type=\"int64\",        \n",
    "    ),    \n",
    "    AttributeInfo(\n",
    "        name=\"report_count\",\n",
    "        description=\"The number of reports where the comment appears\",\n",
    "        type=\"int64\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"username\",\n",
    "        description=\"The username of the author of the comment\",\n",
    "        type=\"object\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"author_user_id\",\n",
    "        description=\"The id of the author of the comment\",\n",
    "        type=\"object\",\n",
    "    ),    \n",
    "    AttributeInfo(\n",
    "        name=\"author_position\",\n",
    "        description=\"The position of the author of the comment. One of ['Advanced Crew Leader','Crew Member','Crew Leader','Weekend Dispatch','Lead Instructor','Area Supervisor','Field Trainer 1','Warehouse Coordinator','Field Trainer 2','Executive Assistant','Internal Communications Manager','Field Manager','Safety Professional','Internal Communications Coordinator', 'Employee Services Supervisor','Safety Advocate', and many more...]\",\n",
    "        type=\"object\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"author_status\",\n",
    "        description=\"The position of the author of the comment. One of ['active','suspended']\",\n",
    "        type=\"object\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Creating our self-querying retriever\n",
    "document_content_description = \"Comments on social network posts\"\n",
    "llm = ChatOllama(model=\"mistral\")\n",
    "\n",
    "retriever = SelfQueryRetriever.from_llm(    \n",
    "    llm,\n",
    "    db,\n",
    "    document_content_description,    \n",
    "    metadata_field_info,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Testing out the retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Congratulations', metadata={'author_position': 'Crew Leader', 'author_status': 'suspended', 'author_user_id': 'e62d292b-7a01-4aa9-ab5a-e6fbfaa6e326', 'comment_id': 3927754, 'created_date': '2022-01-26 00:17:59', 'like_count': 0, 'post_id': 4989194, 'report_count': 0, 'stream_name': 'Safety & Operations', 'username': 'Donnie_Ziegler'}),\n",
       " Document(page_content='Congratulations', metadata={'author_position': 'Advanced Crew Leader', 'author_status': 'active', 'author_user_id': '5a3ca39e-5c41-4501-8eab-6a9ed0a62044', 'comment_id': 4686674, 'created_date': '2022-08-14 02:01:54', 'like_count': 0, 'post_id': 5643777, 'report_count': 0, 'stream_name': 'Safety & Operations', 'username': 'William_MobleyJr'}),\n",
       " Document(page_content='Congratulations', metadata={'author_position': 'Crew Member', 'author_status': 'suspended', 'author_user_id': '74f383df-5aa7-4efb-af99-5f96405dadc8', 'comment_id': 5163635, 'created_date': '2022-12-17 00:01:52', 'like_count': 0, 'post_id': 6082644, 'report_count': 0, 'stream_name': 'Safety & Operations', 'username': 'Tiffanie_Gaskins'}),\n",
       " Document(page_content='Congratulations üëèüëè', metadata={'author_position': 'Advanced Crew Leader', 'author_status': 'active', 'author_user_id': '9c0fe286-e9ab-4000-a826-dbe70230a4c2', 'comment_id': 5528987, 'created_date': '2023-03-26 19:08:11', 'like_count': 0, 'post_id': 6337268, 'report_count': 0, 'stream_name': 'Safety & Operations', 'username': 'Towanda_Gordon'})]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This example only specifies a query\n",
    "retriever.invoke(\"What are two comments about congratulations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "username\n",
       "FlaggerForce        8\n",
       "weekend_dispatch    8\n",
       "Karen_Stroup        8\n",
       "Linwood_DavisJr     6\n",
       "Jessica_Beers       5\n",
       "                   ..\n",
       "Deon_McDaniel       1\n",
       "Adrienne_Long       1\n",
       "Stephen_Michael     1\n",
       "Towanda_Gordon      1\n",
       "Kyndra_Edwards      1\n",
       "Name: count, Length: 201, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comments_to_test['username'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='What did the buffalo say to his son when he dropped him off at school?\\nBison!!!! üòÇü§£üò≠ @Jeffrey_Williams @Seth_Lee üòÇü§£üò≠', metadata={'author_position': 'Field Trainer 1', 'author_status': 'suspended', 'author_user_id': 'f1555029-1597-4d3e-9199-4ebc04ed9702', 'comment_id': 4695288, 'created_date': '2022-08-16 19:19:26', 'like_count': 6, 'post_id': 5653172, 'report_count': 0, 'stream_name': 'Water Break', 'username': 'Collette_Monaghan'}),\n",
       " Document(page_content='As @Julie_Snedeker mentioned the focus here is to stop tampering with Flagger Forced issued equipment. The cameras believe it or not are in the vehicles for YOUR SAFETY. If you pick up the cell phone it says to put it down... if your following to close it says to back off... it is easy to sit and nitpick a photo but it is difficult to follow company policy.', metadata={'author_position': 'Safety Manager', 'author_status': 'active', 'author_user_id': '2aac35e8-f970-4434-9b46-56274384cf89', 'comment_id': 6601009, 'created_date': '2023-12-28 01:54:16', 'like_count': 6, 'post_id': 7367779, 'report_count': 0, 'stream_name': 'Safety & Operations', 'username': 'Scott_Richwine'}),\n",
       " Document(page_content='The background is clearly in a parking lot... anyone who has towed a PCMS understands the drum bases go in the back of the pickup truck.', metadata={'author_position': 'Safety Manager', 'author_status': 'active', 'author_user_id': '2aac35e8-f970-4434-9b46-56274384cf89', 'comment_id': 6601009, 'created_date': '2023-12-28 01:54:16', 'like_count': 6, 'post_id': 7367779, 'report_count': 0, 'stream_name': 'Safety & Operations', 'username': 'Scott_Richwine'})]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This example only specifies a filter\n",
    "retriever.invoke(\"What is a highly liked (above 4) comment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment_id\n",
       "6601009    6\n",
       "4695288    6\n",
       "5959837    4\n",
       "3993841    4\n",
       "6468179    4\n",
       "          ..\n",
       "5031138    0\n",
       "5049534    0\n",
       "5067432    0\n",
       "5068273    0\n",
       "6865894    0\n",
       "Name: like_count, Length: 300, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group by to find the comments with highest number of likes\n",
    "df_comments_to_test.groupby('comment_id')['like_count'].sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting the client\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "PERSIST_DIRECTORY = \"C:\\\\Users\\\\eduar\\\\Documents\\\\Master_Thesis\\\\GenAI_Thesis_Beekeeper\\\\data\\\\datasets_db\"\n",
    "\n",
    "chromadb_client = chromadb.PersistentClient(path=PERSIST_DIRECTORY, settings=Settings(allow_reset=True))\n",
    "chromadb_client.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Thank you Robert, I appreciate your knowledge\"\n",
    "docs = db.similarity_search(query)\n",
    "print(docs[0].page_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artefact II - RAG using Two Collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "\n",
    "PERSIST_DIRECTORY = \"C:\\\\Users\\\\eduar\\\\Documents\\\\Master_Thesis\\\\GenAI_Thesis_Beekeeper\\\\data\\\\datasets_db\"\n",
    "# embeddings = SentenceTransformerEmbeddings(model_name=\"all-mpnet-base-v2\")\n",
    "embeddings = OllamaEmbeddings(model=\"mistral\") \n",
    "\n",
    "persistent_client = chromadb.PersistentClient(path=PERSIST_DIRECTORY, settings=Settings(allow_reset=True))\n",
    "collection_comments = persistent_client.get_or_create_collection(\"collection_comments\",\n",
    "                                                        metadata={\"hnsw:space\": \"l2\"}, # Squared L2 norm(l2) is the default, inner product('ip') or cosine similarity('cosine')                                                              \n",
    "                                                        embedding_function=embeddings\n",
    "                                                        )\n",
    " # Add data to collection\n",
    "collection_comments.add(documents=documents,\n",
    "                        metadatas=metadatas,\n",
    "                        ids=ids\n",
    "                        )\n",
    "\n",
    "langchain_chroma = Chroma(\n",
    "    client=persistent_client,\n",
    "    collection_name=\"collection_comments\",\n",
    "    embedding_function=embeddings\n",
    ")\n",
    "\n",
    "print(\"There are\", langchain_chroma._collection.count(), \"in the collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting the client\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "PERSIST_DIRECTORY = \"C:\\\\Users\\\\eduar\\\\Documents\\\\Master_Thesis\\\\GenAI_Thesis_Beekeeper\\\\data\\\\datasets_db\"\n",
    "\n",
    "chromadb_client = chromadb.PersistentClient(path=PERSIST_DIRECTORY, settings=Settings(allow_reset=True))\n",
    "chromadb_client.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "#from langchain_chroma import Chroma\n",
    "#from langchain_community.embeddings import OllamaEmbeddings\n",
    "#import chromadb.utils.embedding_functions as embedding_functions\n",
    "from chromadb.config import Settings\n",
    "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "      \n",
    "PERSIST_DIRECTORY = \"C:\\\\Users\\\\eduar\\\\Documents\\\\Master_Thesis\\\\GenAI_Thesis_Beekeeper\\\\data\\\\datasets_db\"\n",
    "embeddings = SentenceTransformerEmbeddings(model_name=\"all-mpnet-base-v2\")    \n",
    "    \n",
    "\n",
    "# Function to create and load data to the database\n",
    "\"\"\"\n",
    "The embedding function takes text as input, and performs tokenization and embedding. If no embedding function is supplied, Chroma will use sentence transformer as a default.\n",
    "https://docs.trychroma.com/embeddings#sentence-transformers\n",
    "By default, Chroma uses all-MiniLM-L6-v2\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def upload_to_chromadb(documents, metadatas, ids):\n",
    "    try:            \n",
    "        # create the open-source embedding function\n",
    "        # embedding = OllamaEmbeddings(model=\"mistral\")\n",
    "        # embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")   # Default\n",
    "        embeddings = SentenceTransformerEmbeddings(model_name=\"all-mpnet-base-v2\")          # Best model from included in ChromaDB\n",
    "        \n",
    "        # Initialize ChromaDB client\n",
    "        # load it into Chroma\n",
    "        db = Chroma.from_documents(documents, embeddings,\n",
    "                                    persist_directory=PERSIST_DIRECTORY)\n",
    "               \n",
    "        # Create a comment's collection\n",
    "        collection_comments = chromadb_client.create_collection(name=\"comments_collection\",\n",
    "                                                              metadata={\"hnsw:space\": \"l2\"}, # Squared L2 norm(l2) is the default, inner product('ip') or cosine similarity('cosine')                                                              \n",
    "                                                              embedding_function=embeddings\n",
    "                                                              )        \n",
    "        \n",
    "        # Add data to collection\n",
    "        collection_comments.add(documents=documents,\n",
    "                                metadatas=metadatas,\n",
    "                                ids=ids\n",
    "                                )\n",
    "        print(\"Data uploaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to upload data: {e}\")\n",
    "\n",
    "upload_to_chromadb(documents, metadatas, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ollama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
