{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artefact II - RAG using Two Collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python \n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ChromaDB\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "# LangChain \n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "# Set OpenAi key as an environment variable\n",
    "os.environ[\"sk-proj-Sm1whIiewmhrMZpq7rlBT3BlbkFJQ5PTl7vQLyybJYSzeUFC\"] = \"\"\n",
    "\n",
    "# Directory path\n",
    "#PERSIST_DIRECTORY = \"C:\\\\Users\\\\eduar\\\\Documents\\\\Master_Thesis\\\\GenAI_Thesis_Beekeeper\\\\data\\\\vector_db\"\n",
    "PERSIST_DIRECTORY = \"C:\\\\Users\\\\eduar\\\\Documents\\\\Master_Thesis\\\\GenAI_Thesis_Beekeeper\\\\data\\\\datasets_db\"\n",
    "\n",
    "# Define the open-source embedding function ()\n",
    "embedding_func = SentenceTransformerEmbeddings(model_name=\"all-mpnet-base-v2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Importing Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stream_name</th>\n",
       "      <th>created_date</th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>like_count</th>\n",
       "      <th>report_count</th>\n",
       "      <th>username</th>\n",
       "      <th>author_user_id</th>\n",
       "      <th>author_position</th>\n",
       "      <th>author_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48902</th>\n",
       "      <td>Jobs</td>\n",
       "      <td>2023-05-14 14:36:36</td>\n",
       "      <td>6579917</td>\n",
       "      <td>5725077</td>\n",
       "      <td>Just let me know</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Brad_Mentzer</td>\n",
       "      <td>033e3592-37f8-4462-9eb0-f3cb38129b2d</td>\n",
       "      <td>Advanced Crew Leader</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40035</th>\n",
       "      <td>Jobs</td>\n",
       "      <td>2023-07-06 11:01:08</td>\n",
       "      <td>6787738</td>\n",
       "      <td>5934909</td>\n",
       "      <td>Lol</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Christine_Dioso</td>\n",
       "      <td>070b93d5-955d-4ed7-b6ac-98f1445e8737</td>\n",
       "      <td>Crew Leader</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13687</th>\n",
       "      <td>OSC, We Can Help</td>\n",
       "      <td>2023-12-19 01:00:48</td>\n",
       "      <td>7353091</td>\n",
       "      <td>6566749</td>\n",
       "      <td>I wasn't sure since I'm still a crew member ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Joseph_Gill</td>\n",
       "      <td>d9089068-40c1-42b3-9661-084b73efdba8</td>\n",
       "      <td>Crew Member</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            stream_name         created_date  post_id  comment_id  \\\n",
       "48902              Jobs  2023-05-14 14:36:36  6579917     5725077   \n",
       "40035              Jobs  2023-07-06 11:01:08  6787738     5934909   \n",
       "13687  OSC, We Can Help  2023-12-19 01:00:48  7353091     6566749   \n",
       "\n",
       "                                            comment_text  like_count  \\\n",
       "48902                                   Just let me know           0   \n",
       "40035                                                Lol           0   \n",
       "13687  I wasn't sure since I'm still a crew member ma...           0   \n",
       "\n",
       "       report_count         username                        author_user_id  \\\n",
       "48902             0     Brad_Mentzer  033e3592-37f8-4462-9eb0-f3cb38129b2d   \n",
       "40035             0  Christine_Dioso  070b93d5-955d-4ed7-b6ac-98f1445e8737   \n",
       "13687             0      Joseph_Gill  d9089068-40c1-42b3-9661-084b73efdba8   \n",
       "\n",
       "            author_position author_status  \n",
       "48902  Advanced Crew Leader        active  \n",
       "40035           Crew Leader        active  \n",
       "13687           Crew Member        active  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import users file\n",
    "#path = \"/home/ubuntu/thesis_GenAI/data/production_datasets/cleaned_datasets\"\n",
    "path = \"C:\\\\Users\\\\eduar\\\\Documents\\\\Master_Thesis\\\\GenAI_Thesis_Beekeeper\\\\data\\\\production_datasets\\\\cleaned_datasets\"\n",
    "file_name = \"comments_cleaned.csv\"\n",
    "file_path = os.path.join(path, file_name)\n",
    "df_comments = pd.read_csv(file_path)\n",
    "\n",
    "# Create a sample of comments to test\n",
    "df_comments_to_test = df_comments.sample(250)\n",
    "df_comments_to_test.to_csv(os.path.join(path,\"comments_sample.csv\"), index=False)\n",
    "\n",
    "# Print a sample\n",
    "df_comments.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Importing Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stream_name</th>\n",
       "      <th>stream_id</th>\n",
       "      <th>post_id</th>\n",
       "      <th>action</th>\n",
       "      <th>created</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>like_count</th>\n",
       "      <th>comment_countt</th>\n",
       "      <th>mentions</th>\n",
       "      <th>username</th>\n",
       "      <th>author_user_id</th>\n",
       "      <th>author_position</th>\n",
       "      <th>author_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17940</th>\n",
       "      <td>Jobs</td>\n",
       "      <td>9254</td>\n",
       "      <td>6391160</td>\n",
       "      <td>POSTED</td>\n",
       "      <td>2023-03-25 10:44:09</td>\n",
       "      <td>Available</td>\n",
       "      <td>Mot</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mark_Matthews</td>\n",
       "      <td>72b8fdfd-5278-4fdd-bb81-581ed46f65eb</td>\n",
       "      <td>Advanced Crew Leader</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7795</th>\n",
       "      <td>OSC, We Can Help</td>\n",
       "      <td>22708</td>\n",
       "      <td>7110012</td>\n",
       "      <td>POSTED</td>\n",
       "      <td>2023-10-09 13:16:56</td>\n",
       "      <td>S/O GOING OUT</td>\n",
       "      <td>SHOUT OUT TO @Linwood_DavisJr @maurice_jackson...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>Linwood_DavisJr,maurice_jackson2,Jordan_Feltcorn</td>\n",
       "      <td>Hubert_Radcliff</td>\n",
       "      <td>2c1e808e-da89-4984-8d06-2def06daa397</td>\n",
       "      <td>Advanced Crew Leader</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24603</th>\n",
       "      <td>Jobs</td>\n",
       "      <td>9254</td>\n",
       "      <td>5991182</td>\n",
       "      <td>POSTED</td>\n",
       "      <td>2022-11-18 13:58:49</td>\n",
       "      <td>Gm</td>\n",
       "      <td>I'll be Available After I Go with my Wife to t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Linwood_DavisJr</td>\n",
       "      <td>99d73931-1583-485d-afa7-ee1e20c05868</td>\n",
       "      <td>Advanced Crew Leader</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            stream_name  stream_id  post_id  action              created  \\\n",
       "17940              Jobs       9254  6391160  POSTED  2023-03-25 10:44:09   \n",
       "7795   OSC, We Can Help      22708  7110012  POSTED  2023-10-09 13:16:56   \n",
       "24603              Jobs       9254  5991182  POSTED  2022-11-18 13:58:49   \n",
       "\n",
       "               title                                               text  \\\n",
       "17940      Available                                                Mot   \n",
       "7795   S/O GOING OUT  SHOUT OUT TO @Linwood_DavisJr @maurice_jackson...   \n",
       "24603             Gm  I'll be Available After I Go with my Wife to t...   \n",
       "\n",
       "       like_count  comment_countt  \\\n",
       "17940           1               1   \n",
       "7795           12               0   \n",
       "24603           1               0   \n",
       "\n",
       "                                               mentions         username  \\\n",
       "17940                                               NaN    Mark_Matthews   \n",
       "7795   Linwood_DavisJr,maurice_jackson2,Jordan_Feltcorn  Hubert_Radcliff   \n",
       "24603                                               NaN  Linwood_DavisJr   \n",
       "\n",
       "                             author_user_id       author_position  \\\n",
       "17940  72b8fdfd-5278-4fdd-bb81-581ed46f65eb  Advanced Crew Leader   \n",
       "7795   2c1e808e-da89-4984-8d06-2def06daa397  Advanced Crew Leader   \n",
       "24603  99d73931-1583-485d-afa7-ee1e20c05868  Advanced Crew Leader   \n",
       "\n",
       "      author_status  \n",
       "17940        active  \n",
       "7795         active  \n",
       "24603        active  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import users file\n",
    "#path = \"/home/ubuntu/thesis_GenAI/data/production_datasets/cleaned_datasets\"\n",
    "path = \"C:\\\\Users\\\\eduar\\\\Documents\\\\Master_Thesis\\\\GenAI_Thesis_Beekeeper\\\\data\\\\production_datasets\\\\cleaned_datasets\"\n",
    "file_name = \"posts_cleaned.csv\"\n",
    "file_path = os.path.join(path, file_name)\n",
    "df_posts = pd.read_csv(file_path)\n",
    "# Delete column 'labels'\n",
    "df_posts = df_posts.drop(columns=['labels'])\n",
    "\n",
    "# Create a sample of 50,000 comments to test\n",
    "df_post_to_test = df_posts.sample(200)\n",
    "df_post_to_test.to_csv(os.path.join(path,\"posts_sample.csv\"), index=False)\n",
    "\n",
    "# Print a sample\n",
    "df_posts.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Data for Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Nice going, @John_Bright. Stay safe out there in the winter weather!',\n",
       " 'Let me give you the run down I’d hate to give out the trick but it sounds like you need help you have to set your alarm for 3:30 if you get a job then no job board if you don’t then set your alarm for 5:29 and refresh 10 times a second until jobs come up they will only be up for 5 seconds and if you don’t click one and accept it your done you mi as well just stay up all night partying',\n",
       " 'Available..',\n",
       " 'Me',\n",
       " 'Congratulations 🎉',\n",
       " '@Charles_Yates',\n",
       " 'Congratulations',\n",
       " 'That they dropped us permanently.',\n",
       " \"@Karen_Stroup honestly I watched this and started to think. This is the type of job we are on every single day. This is close to home. This could have honestly been anyone of us out there. I thank God her injuries were mild and she will recover. At the same time it's terrifying to know there are people out there that can hit a person and keep going..\",\n",
       " 'I’ll go how about me']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import comment's sample file\n",
    "file_name = \"comments_sample.csv\"\n",
    "file_path = os.path.join(path, file_name)\n",
    "df_comments_to_test = pd.read_csv(file_path)\n",
    "\n",
    "# Function to prepare the commments data to be loaded to the database\n",
    "def prepare_comments_data(df):   \n",
    "    documents = []\n",
    "    metadatas = []\n",
    "    ids = []\n",
    "        \n",
    "    for idx, row in df.iterrows(): \n",
    "        documents.append(row.iloc[4])\n",
    "        metadatas.append({\n",
    "            'stream_name': row.iloc[0],\n",
    "            'created_date': row.iloc[1],\n",
    "            'post_id': row.iloc[2],\n",
    "            'comment_id': row.iloc[3],\n",
    "            'like_count': row.iloc[5],\n",
    "            'report_count': row.iloc[6],\n",
    "            'username': row.iloc[7],\n",
    "            'author_user_id': row.iloc[8],\n",
    "            'author_position': row.iloc[9],\n",
    "            'author_status': row.iloc[10]\n",
    "        })\n",
    "        ids.append(str(idx+1))       \n",
    "    \n",
    "    return documents, metadatas, ids\n",
    "\n",
    "documents_comments, metadatas_comments, ids_comments = prepare_comments_data(df_comments_to_test)\n",
    "\n",
    "print(type(documents_comments))\n",
    "documents_comments[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Nice going, @John_Bright. Stay safe out there in the winter weather!', metadata={'stream_name': 'Safety & Operations', 'created_date': '2024-01-17 14:41:47', 'post_id': 7442041, 'comment_id': 6673822, 'like_count': 0, 'report_count': 0, 'username': 'FlaggerForce', 'author_user_id': 'b701ab9f-563a-4425-a389-aff803a8da58', 'author_position': nan, 'author_status': 'active'}),\n",
       " Document(page_content='Let me give you the run down I’d hate to give out the trick but it sounds like you need help you have to set your alarm for 3:30 if you get a job then no job board if you don’t then set your alarm for 5:29 and refresh 10 times a second until jobs come up they will only be up for 5 seconds and if you don’t click one and accept it your done you mi as well just stay up all night partying', metadata={'stream_name': 'OSC, We Can Help', 'created_date': '2023-12-13 23:45:50', 'post_id': 7336415, 'comment_id': 6547238, 'like_count': 0, 'report_count': 0, 'username': 'Martin_Gieser', 'author_user_id': 'b64de93d-7786-4bff-9cc1-e4e7529f37fc', 'author_position': 'Crew Member', 'author_status': 'suspended'})]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split it into chunks\n",
    "text_splitter = CharacterTextSplitter(    \n",
    "    separator=\"\\n\\n\",\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=0,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,        \n",
    "    )\n",
    "\n",
    "docs_comments = text_splitter.create_documents(documents_comments,\n",
    "                                               metadatas=metadatas_comments\n",
    "                                                )\n",
    "docs_comments[:2]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import post's sample file\n",
    "file_name = \"posts_sample.csv\"\n",
    "file_path = os.path.join(path, file_name)\n",
    "df_posts_to_test = pd.read_csv(file_path)\n",
    "# print(df_posts_to_test.isnull().sum())\n",
    "\n",
    "# Delete rows with NAN values in the column text\n",
    "df_posts_to_test.dropna(inplace=True, subset=['text','username'])\n",
    "# print()\n",
    "# print(df_posts_to_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['I am having a lot of trouble getting work. What do I do?Everytime I check the job bored it says nothing on there. I need work. I check the job bored all the time and I still get nothing. Even when I check it between 3:30 and 5:30 (I stay on the app) Help please',\n",
       " 'VERA IS WORKING WITH 2 WONDERFUL COOWORKERS, WONDERFUL MENS. PLEASE BE CAREFUL OUT THERE IN THIS WEATHER STAY SAFE GOD BLESS YOU ALL.',\n",
       " 'Started my first assignment today and it went great....so much so that i was literally just about to ask for more work on ITZ...when my cell chimed...and two more assignments to close the week out. And to think...i was worried about nothing.🤑🤑🤑🤑🤑🥰🥰🥰🥰😋',\n",
       " 'Available @weekend_dispatch @weekend_dispatch @weekend_dispatch',\n",
       " 'Is there a way you can get took off a order on a weekend without getting points ??',\n",
       " 'I am still not getting anything for the week I am available too work day or night and if I need equipment just let me know where I need too get it \\nAcl/seo',\n",
       " 'Client didn’t show up this morning so I went and got my fishing gear',\n",
       " 'Client: Duke Energy\\nDate: 2/23/2024\\nTime: ASAP/NOW\\nAddress: 1386 NC-801, Advance, NC 27006\\nOrder: 578159\\n\\n\\nNotes: please comment if you are available',\n",
       " '@Anthony_Mills my cpr card expired May 11, 2022. Do you know how i renew it. Thanks',\n",
       " 'Today worked on transition taper, termination taper. Then a small 107 at the hub. @Melissa_Clarke did a wonderful job on her first ever transition taper. \\n\\nToday is \\n@Ronald_Gosnay first day at Flagger Force. He has experience flagging and also did wonderful. He knows his stuff. \\n\\nRonald welcome to Flagger Force family.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to prepare the posts data to be loaded to the database\n",
    "def prepare_posts_data(df):   \n",
    "    documents = []\n",
    "    metadatas = []\n",
    "    ids = []\n",
    "        \n",
    "    for idx, row in df.iterrows(): \n",
    "        documents.append(row.iloc[6])\n",
    "        metadatas.append({\n",
    "            'stream_name': row.iloc[0],\n",
    "            'stream_id': row.iloc[1],\n",
    "            'post_id': row.iloc[2],\n",
    "            'action': row.iloc[3],            \n",
    "            'created': row.iloc[4],\n",
    "            'title': row.iloc[5],            \n",
    "            'like_count': row.iloc[7],\n",
    "            'comment_countt': row.iloc[8],\n",
    "            'mentions': row.iloc[9],\n",
    "            #'labels': row.iloc[10],\n",
    "            'username': row.iloc[10],\n",
    "            'author_user_id': row.iloc[11],\n",
    "            'author_position': row.iloc[12],\n",
    "            'author_status': row.iloc[13]\n",
    "        })\n",
    "        ids.append(str(idx+1))       \n",
    "    \n",
    "    return documents, metadatas, ids\n",
    "\n",
    "documents_posts, metadatas_posts, ids_posts = prepare_posts_data(df_posts_to_test)\n",
    "\n",
    "print(type(documents_posts))\n",
    "documents_posts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # find the elements of the list documents_posts which are not of string type\\nfor element in documents_posts:\\n    if not isinstance(element, str):\\n        print(documents_posts.index(element))\\n        \\n# Deleting the elements of the list with NaN values\\ndocuments_posts = [element for element in documents_posts if isinstance(element, str)] '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # find the elements of the list documents_posts which are not of string type\n",
    "for element in documents_posts:\n",
    "    if not isinstance(element, str):\n",
    "        print(documents_posts.index(element))\n",
    "        \n",
    "# Deleting the elements of the list with NaN values\n",
    "documents_posts = [element for element in documents_posts if isinstance(element, str)] \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='I am having a lot of trouble getting work. What do I do?Everytime I check the job bored it says nothing on there. I need work. I check the job bored all the time and I still get nothing. Even when I check it between 3:30 and 5:30 (I stay on the app) Help please', metadata={'stream_name': 'Jobs', 'stream_id': 9254, 'post_id': 7251335, 'action': 'POSTED', 'created': '2023-11-17 16:12:44', 'title': nan, 'like_count': 1, 'comment_countt': 3, 'mentions': nan, 'username': 'Jeremie_Prater', 'author_user_id': '242e9a2c-fa00-46c8-9dad-a9889b3624aa', 'author_position': 'Crew Leader', 'author_status': 'active'}),\n",
       " Document(page_content='VERA IS WORKING WITH 2 WONDERFUL COOWORKERS, WONDERFUL MENS. PLEASE BE CAREFUL OUT THERE IN THIS WEATHER STAY SAFE GOD BLESS YOU ALL.', metadata={'stream_name': 'Water Break', 'stream_id': 6787, 'post_id': 7348758, 'action': 'POSTED', 'created': '2023-12-17 22:14:21', 'title': 'Stay safe, bad weather', 'like_count': 3, 'comment_countt': 0, 'mentions': nan, 'username': 'Vera_Rivera', 'author_user_id': '46a5d6ae-52ae-4b13-8add-65e46ed7d98a', 'author_position': 'Crew Member', 'author_status': 'active'})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text splitter\n",
    "\n",
    "# split it into chunks\n",
    "text_splitter = CharacterTextSplitter(    \n",
    "    separator=\"\\n\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=0,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,        \n",
    "    )\n",
    "\n",
    "docs_posts = text_splitter.create_documents(documents_posts, \n",
    "                                            metadatas=metadatas_posts\n",
    "                                            )\n",
    "docs_posts[:2]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create and add data to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 11\u001b[0m\n\u001b[0;32m      4\u001b[0m client_settings \u001b[38;5;241m=\u001b[39m chromadb\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mSettings(        \n\u001b[0;32m      5\u001b[0m     persist_directory\u001b[38;5;241m=\u001b[39mPERSIST_DIRECTORY,\n\u001b[0;32m      6\u001b[0m     anonymized_telemetry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m      7\u001b[0m     allow_reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# save comments to disk\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m db_comments \u001b[38;5;241m=\u001b[39m \u001b[43mChroma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs_comments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                           \u001b[49m\u001b[43membedding_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                           \u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPERSIST_DIRECTORY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Test the db\u001b[39;00m\n\u001b[0;32m     16\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFlaggerForce congratulations\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:790\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[1;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[0;32m    788\u001b[0m texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m    789\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m--> 790\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_texts(\n\u001b[0;32m    791\u001b[0m     texts\u001b[38;5;241m=\u001b[39mtexts,\n\u001b[0;32m    792\u001b[0m     embedding\u001b[38;5;241m=\u001b[39membedding,\n\u001b[0;32m    793\u001b[0m     metadatas\u001b[38;5;241m=\u001b[39mmetadatas,\n\u001b[0;32m    794\u001b[0m     ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[0;32m    795\u001b[0m     collection_name\u001b[38;5;241m=\u001b[39mcollection_name,\n\u001b[0;32m    796\u001b[0m     persist_directory\u001b[38;5;241m=\u001b[39mpersist_directory,\n\u001b[0;32m    797\u001b[0m     client_settings\u001b[38;5;241m=\u001b[39mclient_settings,\n\u001b[0;32m    798\u001b[0m     client\u001b[38;5;241m=\u001b[39mclient,\n\u001b[0;32m    799\u001b[0m     collection_metadata\u001b[38;5;241m=\u001b[39mcollection_metadata,\n\u001b[0;32m    800\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    801\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:748\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[0;32m    740\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_batches\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m create_batches(\n\u001b[0;32m    743\u001b[0m         api\u001b[38;5;241m=\u001b[39mchroma_collection\u001b[38;5;241m.\u001b[39m_client,\n\u001b[0;32m    744\u001b[0m         ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[0;32m    745\u001b[0m         metadatas\u001b[38;5;241m=\u001b[39mmetadatas,\n\u001b[0;32m    746\u001b[0m         documents\u001b[38;5;241m=\u001b[39mtexts,\n\u001b[0;32m    747\u001b[0m     ):\n\u001b[1;32m--> 748\u001b[0m         \u001b[43mchroma_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    749\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[43m            \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    752\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    753\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    754\u001b[0m     chroma_collection\u001b[38;5;241m.\u001b[39madd_texts(texts\u001b[38;5;241m=\u001b[39mtexts, metadatas\u001b[38;5;241m=\u001b[39mmetadatas, ids\u001b[38;5;241m=\u001b[39mids)\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:276\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[1;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[0;32m    274\u001b[0m texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(texts)\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 276\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embedding_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metadatas:\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;66;03m# fill metadatas with empty dicts if somebody\u001b[39;00m\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;66;03m# did not specify metadata for all texts\u001b[39;00m\n\u001b[0;32m    280\u001b[0m     length_diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(texts) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(metadatas)\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\langchain_community\\embeddings\\huggingface.py:98\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.embed_documents\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m     96\u001b[0m     sentence_transformers\u001b[38;5;241m.\u001b[39mSentenceTransformer\u001b[38;5;241m.\u001b[39mstop_multi_process_pool(pool)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 98\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mencode(\n\u001b[0;32m     99\u001b[0m         texts, show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshow_progress, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_kwargs\n\u001b[0;32m    100\u001b[0m     )\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:371\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[1;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[0;32m    368\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate(extra_features)\n\u001b[0;32m    370\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 371\u001b[0m     out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    372\u001b[0m     out_features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m truncate_embeddings(\n\u001b[0;32m    373\u001b[0m         out_features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtruncate_dim\n\u001b[0;32m    374\u001b[0m     )\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_value \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\sentence_transformers\\models\\Transformer.py:98\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[0;32m     96\u001b[0m     trans_features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 98\u001b[0m output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrans_features, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     99\u001b[0m output_tokens \u001b[38;5;241m=\u001b[39m output_states[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    101\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_tokens, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]})\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\transformers\\models\\mpnet\\modeling_mpnet.py:548\u001b[0m, in \u001b[0;36mMPNetModel.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m    546\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m    547\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(input_ids\u001b[38;5;241m=\u001b[39minput_ids, position_ids\u001b[38;5;241m=\u001b[39mposition_ids, inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds)\n\u001b[1;32m--> 548\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    549\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    552\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    553\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    555\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    556\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    557\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\transformers\\models\\mpnet\\modeling_mpnet.py:338\u001b[0m, in \u001b[0;36mMPNetEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[0;32m    336\u001b[0m     all_hidden_states \u001b[38;5;241m=\u001b[39m all_hidden_states \u001b[38;5;241m+\u001b[39m (hidden_states,)\n\u001b[1;32m--> 338\u001b[0m layer_outputs \u001b[38;5;241m=\u001b[39m layer_module(\n\u001b[0;32m    339\u001b[0m     hidden_states,\n\u001b[0;32m    340\u001b[0m     attention_mask,\n\u001b[0;32m    341\u001b[0m     head_mask[i],\n\u001b[0;32m    342\u001b[0m     position_bias,\n\u001b[0;32m    343\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    345\u001b[0m )\n\u001b[0;32m    346\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\transformers\\models\\mpnet\\modeling_mpnet.py:297\u001b[0m, in \u001b[0;36mMPNetLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    290\u001b[0m     hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    296\u001b[0m ):\n\u001b[1;32m--> 297\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    304\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    305\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add self attentions if we output attention weights\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\transformers\\models\\mpnet\\modeling_mpnet.py:238\u001b[0m, in \u001b[0;36mMPNetAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    231\u001b[0m     hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    237\u001b[0m ):\n\u001b[1;32m--> 238\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    245\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(self_outputs[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m+\u001b[39m hidden_states)\n\u001b[0;32m    246\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\transformers\\models\\mpnet\\modeling_mpnet.py:174\u001b[0m, in \u001b[0;36mMPNetSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[0m\n\u001b[0;32m    171\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(v)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;66;03m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[39;00m\n\u001b[1;32m--> 174\u001b[0m attention_scores \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m attention_scores \u001b[38;5;241m=\u001b[39m attention_scores \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention_head_size)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;66;03m# Apply relative position embedding (precomputed in MPNetEncoder) if provided.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\" import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "client_settings = chromadb.config.Settings(        \n",
    "    persist_directory=PERSIST_DIRECTORY,\n",
    "    anonymized_telemetry=False,\n",
    "    allow_reset=True\n",
    ")\n",
    "\n",
    "# save comments to disk\n",
    "db_comments = Chroma.from_documents(docs_comments,\n",
    "                           embedding_func,                           \n",
    "                           persist_directory=PERSIST_DIRECTORY)\n",
    "\n",
    "# Test the db\n",
    "query = \"FlaggerForce congratulations\"\n",
    "docs = db_comments.similarity_search(query)\n",
    "print(docs[0].page_content) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the best team u can have at flagger force\n"
     ]
    }
   ],
   "source": [
    "\"\"\" # save posts to disk\n",
    "db_posts = Chroma.from_documents(docs_posts,\n",
    "                           embedding_func,                           \n",
    "                           persist_directory=PERSIST_DIRECTORY)\n",
    "\n",
    "# Test the db\n",
    "query = \"FlaggerForce congratulations\"\n",
    "docs = db_posts.similarity_search(query)\n",
    "print(docs[0].page_content) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: 1\n",
      "Add of existing embedding ID: 2\n",
      "Add of existing embedding ID: 3\n",
      "Add of existing embedding ID: 4\n",
      "Add of existing embedding ID: 5\n",
      "Add of existing embedding ID: 6\n",
      "Add of existing embedding ID: 7\n",
      "Add of existing embedding ID: 8\n",
      "Add of existing embedding ID: 9\n",
      "Add of existing embedding ID: 10\n",
      "Add of existing embedding ID: 11\n",
      "Add of existing embedding ID: 12\n",
      "Add of existing embedding ID: 13\n",
      "Add of existing embedding ID: 14\n",
      "Add of existing embedding ID: 15\n",
      "Add of existing embedding ID: 16\n",
      "Add of existing embedding ID: 17\n",
      "Add of existing embedding ID: 18\n",
      "Add of existing embedding ID: 19\n",
      "Add of existing embedding ID: 20\n",
      "Add of existing embedding ID: 21\n",
      "Add of existing embedding ID: 22\n",
      "Add of existing embedding ID: 23\n",
      "Add of existing embedding ID: 24\n",
      "Add of existing embedding ID: 25\n",
      "Add of existing embedding ID: 26\n",
      "Add of existing embedding ID: 27\n",
      "Add of existing embedding ID: 28\n",
      "Add of existing embedding ID: 29\n",
      "Add of existing embedding ID: 30\n",
      "Add of existing embedding ID: 31\n",
      "Add of existing embedding ID: 32\n",
      "Add of existing embedding ID: 33\n",
      "Add of existing embedding ID: 34\n",
      "Add of existing embedding ID: 35\n",
      "Add of existing embedding ID: 36\n",
      "Add of existing embedding ID: 37\n",
      "Add of existing embedding ID: 38\n",
      "Add of existing embedding ID: 39\n",
      "Add of existing embedding ID: 40\n",
      "Add of existing embedding ID: 41\n",
      "Add of existing embedding ID: 42\n",
      "Add of existing embedding ID: 43\n",
      "Add of existing embedding ID: 44\n",
      "Add of existing embedding ID: 45\n",
      "Add of existing embedding ID: 46\n",
      "Add of existing embedding ID: 47\n",
      "Add of existing embedding ID: 48\n",
      "Add of existing embedding ID: 49\n",
      "Add of existing embedding ID: 50\n",
      "Add of existing embedding ID: 51\n",
      "Add of existing embedding ID: 52\n",
      "Add of existing embedding ID: 53\n",
      "Add of existing embedding ID: 54\n",
      "Add of existing embedding ID: 55\n",
      "Add of existing embedding ID: 56\n",
      "Add of existing embedding ID: 57\n",
      "Add of existing embedding ID: 58\n",
      "Add of existing embedding ID: 59\n",
      "Add of existing embedding ID: 60\n",
      "Add of existing embedding ID: 61\n",
      "Add of existing embedding ID: 62\n",
      "Add of existing embedding ID: 63\n",
      "Add of existing embedding ID: 64\n",
      "Add of existing embedding ID: 65\n",
      "Add of existing embedding ID: 66\n",
      "Add of existing embedding ID: 67\n",
      "Add of existing embedding ID: 68\n",
      "Add of existing embedding ID: 69\n",
      "Add of existing embedding ID: 70\n",
      "Add of existing embedding ID: 71\n",
      "Add of existing embedding ID: 72\n",
      "Add of existing embedding ID: 73\n",
      "Add of existing embedding ID: 74\n",
      "Add of existing embedding ID: 75\n",
      "Add of existing embedding ID: 76\n",
      "Add of existing embedding ID: 77\n",
      "Add of existing embedding ID: 78\n",
      "Add of existing embedding ID: 79\n",
      "Add of existing embedding ID: 80\n",
      "Add of existing embedding ID: 81\n",
      "Add of existing embedding ID: 82\n",
      "Add of existing embedding ID: 83\n",
      "Add of existing embedding ID: 84\n",
      "Add of existing embedding ID: 85\n",
      "Add of existing embedding ID: 86\n",
      "Add of existing embedding ID: 87\n",
      "Add of existing embedding ID: 88\n",
      "Add of existing embedding ID: 89\n",
      "Add of existing embedding ID: 90\n",
      "Add of existing embedding ID: 91\n",
      "Add of existing embedding ID: 92\n",
      "Add of existing embedding ID: 93\n",
      "Add of existing embedding ID: 94\n",
      "Add of existing embedding ID: 95\n",
      "Add of existing embedding ID: 96\n",
      "Add of existing embedding ID: 97\n",
      "Add of existing embedding ID: 98\n",
      "Add of existing embedding ID: 99\n",
      "Add of existing embedding ID: 100\n",
      "Add of existing embedding ID: 101\n",
      "Add of existing embedding ID: 102\n",
      "Add of existing embedding ID: 103\n",
      "Add of existing embedding ID: 104\n",
      "Add of existing embedding ID: 105\n",
      "Add of existing embedding ID: 106\n",
      "Add of existing embedding ID: 107\n",
      "Add of existing embedding ID: 108\n",
      "Add of existing embedding ID: 109\n",
      "Add of existing embedding ID: 110\n",
      "Add of existing embedding ID: 111\n",
      "Add of existing embedding ID: 112\n",
      "Add of existing embedding ID: 113\n",
      "Add of existing embedding ID: 114\n",
      "Add of existing embedding ID: 115\n",
      "Add of existing embedding ID: 116\n",
      "Add of existing embedding ID: 117\n",
      "Add of existing embedding ID: 118\n",
      "Add of existing embedding ID: 119\n",
      "Add of existing embedding ID: 120\n",
      "Add of existing embedding ID: 121\n",
      "Add of existing embedding ID: 122\n",
      "Add of existing embedding ID: 123\n",
      "Add of existing embedding ID: 124\n",
      "Add of existing embedding ID: 125\n",
      "Add of existing embedding ID: 126\n",
      "Add of existing embedding ID: 127\n",
      "Add of existing embedding ID: 128\n",
      "Add of existing embedding ID: 129\n",
      "Add of existing embedding ID: 130\n",
      "Add of existing embedding ID: 131\n",
      "Add of existing embedding ID: 132\n",
      "Add of existing embedding ID: 133\n",
      "Add of existing embedding ID: 134\n",
      "Add of existing embedding ID: 135\n",
      "Add of existing embedding ID: 136\n",
      "Add of existing embedding ID: 137\n",
      "Add of existing embedding ID: 138\n",
      "Add of existing embedding ID: 139\n",
      "Add of existing embedding ID: 140\n",
      "Add of existing embedding ID: 141\n",
      "Add of existing embedding ID: 142\n",
      "Add of existing embedding ID: 143\n",
      "Add of existing embedding ID: 144\n",
      "Add of existing embedding ID: 145\n",
      "Add of existing embedding ID: 146\n",
      "Add of existing embedding ID: 147\n",
      "Add of existing embedding ID: 148\n",
      "Add of existing embedding ID: 149\n",
      "Add of existing embedding ID: 150\n",
      "Add of existing embedding ID: 151\n",
      "Add of existing embedding ID: 152\n",
      "Add of existing embedding ID: 153\n",
      "Add of existing embedding ID: 154\n",
      "Add of existing embedding ID: 155\n",
      "Add of existing embedding ID: 156\n",
      "Add of existing embedding ID: 157\n",
      "Add of existing embedding ID: 158\n",
      "Add of existing embedding ID: 159\n",
      "Add of existing embedding ID: 160\n",
      "Add of existing embedding ID: 161\n",
      "Add of existing embedding ID: 162\n",
      "Add of existing embedding ID: 163\n",
      "Add of existing embedding ID: 164\n",
      "Add of existing embedding ID: 165\n",
      "Add of existing embedding ID: 166\n",
      "Add of existing embedding ID: 167\n",
      "Add of existing embedding ID: 168\n",
      "Add of existing embedding ID: 169\n",
      "Add of existing embedding ID: 170\n",
      "Add of existing embedding ID: 171\n",
      "Add of existing embedding ID: 172\n",
      "Add of existing embedding ID: 173\n",
      "Add of existing embedding ID: 174\n",
      "Add of existing embedding ID: 175\n",
      "Add of existing embedding ID: 176\n",
      "Add of existing embedding ID: 177\n",
      "Add of existing embedding ID: 178\n",
      "Add of existing embedding ID: 179\n",
      "Add of existing embedding ID: 180\n",
      "Add of existing embedding ID: 181\n",
      "Add of existing embedding ID: 182\n",
      "Add of existing embedding ID: 183\n",
      "Add of existing embedding ID: 184\n",
      "Add of existing embedding ID: 185\n",
      "Add of existing embedding ID: 186\n",
      "Add of existing embedding ID: 187\n",
      "Add of existing embedding ID: 188\n",
      "Add of existing embedding ID: 189\n",
      "Add of existing embedding ID: 190\n",
      "Add of existing embedding ID: 191\n",
      "Add of existing embedding ID: 192\n",
      "Add of existing embedding ID: 193\n",
      "Add of existing embedding ID: 194\n",
      "Add of existing embedding ID: 195\n",
      "Add of existing embedding ID: 196\n",
      "Add of existing embedding ID: 197\n",
      "Add of existing embedding ID: 198\n",
      "Add of existing embedding ID: 199\n",
      "Add of existing embedding ID: 200\n",
      "Add of existing embedding ID: 201\n",
      "Add of existing embedding ID: 202\n",
      "Add of existing embedding ID: 203\n",
      "Add of existing embedding ID: 204\n",
      "Add of existing embedding ID: 205\n",
      "Add of existing embedding ID: 206\n",
      "Add of existing embedding ID: 207\n",
      "Add of existing embedding ID: 208\n",
      "Add of existing embedding ID: 209\n",
      "Add of existing embedding ID: 210\n",
      "Add of existing embedding ID: 211\n",
      "Add of existing embedding ID: 212\n",
      "Add of existing embedding ID: 213\n",
      "Add of existing embedding ID: 214\n",
      "Add of existing embedding ID: 215\n",
      "Add of existing embedding ID: 216\n",
      "Add of existing embedding ID: 217\n",
      "Add of existing embedding ID: 218\n",
      "Add of existing embedding ID: 219\n",
      "Add of existing embedding ID: 220\n",
      "Add of existing embedding ID: 221\n",
      "Add of existing embedding ID: 222\n",
      "Add of existing embedding ID: 223\n",
      "Add of existing embedding ID: 224\n",
      "Add of existing embedding ID: 225\n",
      "Add of existing embedding ID: 226\n",
      "Add of existing embedding ID: 227\n",
      "Add of existing embedding ID: 228\n",
      "Add of existing embedding ID: 229\n",
      "Add of existing embedding ID: 230\n",
      "Add of existing embedding ID: 231\n",
      "Add of existing embedding ID: 232\n",
      "Add of existing embedding ID: 233\n",
      "Add of existing embedding ID: 234\n",
      "Add of existing embedding ID: 235\n",
      "Add of existing embedding ID: 236\n",
      "Add of existing embedding ID: 237\n",
      "Add of existing embedding ID: 238\n",
      "Add of existing embedding ID: 239\n",
      "Add of existing embedding ID: 240\n",
      "Add of existing embedding ID: 241\n",
      "Add of existing embedding ID: 242\n",
      "Add of existing embedding ID: 243\n",
      "Add of existing embedding ID: 244\n",
      "Add of existing embedding ID: 245\n",
      "Add of existing embedding ID: 246\n",
      "Add of existing embedding ID: 247\n",
      "Add of existing embedding ID: 248\n",
      "Add of existing embedding ID: 249\n",
      "Add of existing embedding ID: 250\n",
      "Insert of existing embedding ID: 1\n",
      "Insert of existing embedding ID: 2\n",
      "Insert of existing embedding ID: 3\n",
      "Insert of existing embedding ID: 4\n",
      "Insert of existing embedding ID: 5\n",
      "Insert of existing embedding ID: 6\n",
      "Insert of existing embedding ID: 7\n",
      "Insert of existing embedding ID: 8\n",
      "Insert of existing embedding ID: 9\n",
      "Insert of existing embedding ID: 10\n",
      "Insert of existing embedding ID: 11\n",
      "Insert of existing embedding ID: 12\n",
      "Insert of existing embedding ID: 13\n",
      "Insert of existing embedding ID: 14\n",
      "Insert of existing embedding ID: 15\n",
      "Insert of existing embedding ID: 16\n",
      "Insert of existing embedding ID: 17\n",
      "Insert of existing embedding ID: 18\n",
      "Insert of existing embedding ID: 19\n",
      "Insert of existing embedding ID: 20\n",
      "Insert of existing embedding ID: 21\n",
      "Insert of existing embedding ID: 22\n",
      "Insert of existing embedding ID: 23\n",
      "Insert of existing embedding ID: 24\n",
      "Insert of existing embedding ID: 25\n",
      "Insert of existing embedding ID: 26\n",
      "Insert of existing embedding ID: 27\n",
      "Insert of existing embedding ID: 28\n",
      "Insert of existing embedding ID: 29\n",
      "Insert of existing embedding ID: 30\n",
      "Insert of existing embedding ID: 31\n",
      "Insert of existing embedding ID: 32\n",
      "Insert of existing embedding ID: 33\n",
      "Insert of existing embedding ID: 34\n",
      "Insert of existing embedding ID: 35\n",
      "Insert of existing embedding ID: 36\n",
      "Insert of existing embedding ID: 37\n",
      "Insert of existing embedding ID: 38\n",
      "Insert of existing embedding ID: 39\n",
      "Insert of existing embedding ID: 40\n",
      "Insert of existing embedding ID: 41\n",
      "Insert of existing embedding ID: 42\n",
      "Insert of existing embedding ID: 43\n",
      "Insert of existing embedding ID: 44\n",
      "Insert of existing embedding ID: 45\n",
      "Insert of existing embedding ID: 46\n",
      "Insert of existing embedding ID: 47\n",
      "Insert of existing embedding ID: 48\n",
      "Insert of existing embedding ID: 49\n",
      "Insert of existing embedding ID: 50\n",
      "Insert of existing embedding ID: 51\n",
      "Insert of existing embedding ID: 52\n",
      "Insert of existing embedding ID: 53\n",
      "Insert of existing embedding ID: 54\n",
      "Insert of existing embedding ID: 55\n",
      "Insert of existing embedding ID: 56\n",
      "Insert of existing embedding ID: 57\n",
      "Insert of existing embedding ID: 58\n",
      "Insert of existing embedding ID: 59\n",
      "Insert of existing embedding ID: 60\n",
      "Insert of existing embedding ID: 61\n",
      "Insert of existing embedding ID: 62\n",
      "Insert of existing embedding ID: 63\n",
      "Insert of existing embedding ID: 64\n",
      "Insert of existing embedding ID: 65\n",
      "Insert of existing embedding ID: 66\n",
      "Insert of existing embedding ID: 67\n",
      "Insert of existing embedding ID: 68\n",
      "Insert of existing embedding ID: 69\n",
      "Insert of existing embedding ID: 70\n",
      "Insert of existing embedding ID: 71\n",
      "Insert of existing embedding ID: 72\n",
      "Insert of existing embedding ID: 73\n",
      "Insert of existing embedding ID: 74\n",
      "Insert of existing embedding ID: 75\n",
      "Insert of existing embedding ID: 76\n",
      "Insert of existing embedding ID: 77\n",
      "Insert of existing embedding ID: 78\n",
      "Insert of existing embedding ID: 79\n",
      "Insert of existing embedding ID: 80\n",
      "Insert of existing embedding ID: 81\n",
      "Insert of existing embedding ID: 82\n",
      "Insert of existing embedding ID: 83\n",
      "Insert of existing embedding ID: 84\n",
      "Insert of existing embedding ID: 85\n",
      "Insert of existing embedding ID: 86\n",
      "Insert of existing embedding ID: 87\n",
      "Insert of existing embedding ID: 88\n",
      "Insert of existing embedding ID: 89\n",
      "Insert of existing embedding ID: 90\n",
      "Insert of existing embedding ID: 91\n",
      "Insert of existing embedding ID: 92\n",
      "Insert of existing embedding ID: 93\n",
      "Insert of existing embedding ID: 94\n",
      "Insert of existing embedding ID: 95\n",
      "Insert of existing embedding ID: 96\n",
      "Insert of existing embedding ID: 97\n",
      "Insert of existing embedding ID: 98\n",
      "Insert of existing embedding ID: 99\n",
      "Insert of existing embedding ID: 100\n",
      "Insert of existing embedding ID: 101\n",
      "Insert of existing embedding ID: 102\n",
      "Insert of existing embedding ID: 103\n",
      "Insert of existing embedding ID: 104\n",
      "Insert of existing embedding ID: 105\n",
      "Insert of existing embedding ID: 106\n",
      "Insert of existing embedding ID: 107\n",
      "Insert of existing embedding ID: 108\n",
      "Insert of existing embedding ID: 109\n",
      "Insert of existing embedding ID: 110\n",
      "Insert of existing embedding ID: 111\n",
      "Insert of existing embedding ID: 112\n",
      "Insert of existing embedding ID: 113\n",
      "Insert of existing embedding ID: 114\n",
      "Insert of existing embedding ID: 115\n",
      "Insert of existing embedding ID: 116\n",
      "Insert of existing embedding ID: 117\n",
      "Insert of existing embedding ID: 118\n",
      "Insert of existing embedding ID: 119\n",
      "Insert of existing embedding ID: 120\n",
      "Insert of existing embedding ID: 121\n",
      "Insert of existing embedding ID: 122\n",
      "Insert of existing embedding ID: 123\n",
      "Insert of existing embedding ID: 124\n",
      "Insert of existing embedding ID: 125\n",
      "Insert of existing embedding ID: 126\n",
      "Insert of existing embedding ID: 127\n",
      "Insert of existing embedding ID: 128\n",
      "Insert of existing embedding ID: 129\n",
      "Insert of existing embedding ID: 130\n",
      "Insert of existing embedding ID: 131\n",
      "Insert of existing embedding ID: 132\n",
      "Insert of existing embedding ID: 133\n",
      "Insert of existing embedding ID: 134\n",
      "Insert of existing embedding ID: 135\n",
      "Insert of existing embedding ID: 136\n",
      "Insert of existing embedding ID: 137\n",
      "Insert of existing embedding ID: 138\n",
      "Insert of existing embedding ID: 139\n",
      "Insert of existing embedding ID: 140\n",
      "Insert of existing embedding ID: 141\n",
      "Insert of existing embedding ID: 142\n",
      "Insert of existing embedding ID: 143\n",
      "Insert of existing embedding ID: 144\n",
      "Insert of existing embedding ID: 145\n",
      "Insert of existing embedding ID: 146\n",
      "Insert of existing embedding ID: 147\n",
      "Insert of existing embedding ID: 148\n",
      "Insert of existing embedding ID: 149\n",
      "Insert of existing embedding ID: 150\n",
      "Insert of existing embedding ID: 151\n",
      "Insert of existing embedding ID: 152\n",
      "Insert of existing embedding ID: 153\n",
      "Insert of existing embedding ID: 154\n",
      "Insert of existing embedding ID: 155\n",
      "Insert of existing embedding ID: 156\n",
      "Insert of existing embedding ID: 157\n",
      "Insert of existing embedding ID: 158\n",
      "Insert of existing embedding ID: 159\n",
      "Insert of existing embedding ID: 160\n",
      "Insert of existing embedding ID: 161\n",
      "Insert of existing embedding ID: 162\n",
      "Insert of existing embedding ID: 163\n",
      "Insert of existing embedding ID: 164\n",
      "Insert of existing embedding ID: 165\n",
      "Insert of existing embedding ID: 166\n",
      "Insert of existing embedding ID: 167\n",
      "Insert of existing embedding ID: 168\n",
      "Insert of existing embedding ID: 169\n",
      "Insert of existing embedding ID: 170\n",
      "Insert of existing embedding ID: 171\n",
      "Insert of existing embedding ID: 172\n",
      "Insert of existing embedding ID: 173\n",
      "Insert of existing embedding ID: 174\n",
      "Insert of existing embedding ID: 175\n",
      "Insert of existing embedding ID: 176\n",
      "Insert of existing embedding ID: 177\n",
      "Insert of existing embedding ID: 178\n",
      "Insert of existing embedding ID: 179\n",
      "Insert of existing embedding ID: 180\n",
      "Insert of existing embedding ID: 181\n",
      "Insert of existing embedding ID: 182\n",
      "Insert of existing embedding ID: 183\n",
      "Insert of existing embedding ID: 184\n",
      "Insert of existing embedding ID: 185\n",
      "Insert of existing embedding ID: 186\n",
      "Insert of existing embedding ID: 187\n",
      "Insert of existing embedding ID: 188\n",
      "Insert of existing embedding ID: 189\n",
      "Insert of existing embedding ID: 190\n",
      "Insert of existing embedding ID: 191\n",
      "Insert of existing embedding ID: 192\n",
      "Insert of existing embedding ID: 193\n",
      "Insert of existing embedding ID: 194\n",
      "Insert of existing embedding ID: 195\n",
      "Insert of existing embedding ID: 196\n",
      "Insert of existing embedding ID: 197\n",
      "Insert of existing embedding ID: 198\n",
      "Insert of existing embedding ID: 199\n",
      "Insert of existing embedding ID: 200\n",
      "Insert of existing embedding ID: 201\n",
      "Insert of existing embedding ID: 202\n",
      "Insert of existing embedding ID: 203\n",
      "Insert of existing embedding ID: 204\n",
      "Insert of existing embedding ID: 205\n",
      "Insert of existing embedding ID: 206\n",
      "Insert of existing embedding ID: 207\n",
      "Insert of existing embedding ID: 208\n",
      "Insert of existing embedding ID: 209\n",
      "Insert of existing embedding ID: 210\n",
      "Insert of existing embedding ID: 211\n",
      "Insert of existing embedding ID: 212\n",
      "Insert of existing embedding ID: 213\n",
      "Insert of existing embedding ID: 214\n",
      "Insert of existing embedding ID: 215\n",
      "Insert of existing embedding ID: 216\n",
      "Insert of existing embedding ID: 217\n",
      "Insert of existing embedding ID: 218\n",
      "Insert of existing embedding ID: 219\n",
      "Insert of existing embedding ID: 220\n",
      "Insert of existing embedding ID: 221\n",
      "Insert of existing embedding ID: 222\n",
      "Insert of existing embedding ID: 223\n",
      "Insert of existing embedding ID: 224\n",
      "Insert of existing embedding ID: 225\n",
      "Insert of existing embedding ID: 226\n",
      "Insert of existing embedding ID: 227\n",
      "Insert of existing embedding ID: 228\n",
      "Insert of existing embedding ID: 229\n",
      "Insert of existing embedding ID: 230\n",
      "Insert of existing embedding ID: 231\n",
      "Insert of existing embedding ID: 232\n",
      "Insert of existing embedding ID: 233\n",
      "Insert of existing embedding ID: 234\n",
      "Insert of existing embedding ID: 235\n",
      "Insert of existing embedding ID: 236\n",
      "Insert of existing embedding ID: 237\n",
      "Insert of existing embedding ID: 238\n",
      "Insert of existing embedding ID: 239\n",
      "Insert of existing embedding ID: 240\n",
      "Insert of existing embedding ID: 241\n",
      "Insert of existing embedding ID: 242\n",
      "Insert of existing embedding ID: 243\n",
      "Insert of existing embedding ID: 244\n",
      "Insert of existing embedding ID: 245\n",
      "Insert of existing embedding ID: 246\n",
      "Insert of existing embedding ID: 247\n",
      "Insert of existing embedding ID: 248\n",
      "Insert of existing embedding ID: 249\n",
      "Insert of existing embedding ID: 250\n",
      "Add of existing embedding ID: 1\n",
      "Add of existing embedding ID: 2\n",
      "Add of existing embedding ID: 3\n",
      "Add of existing embedding ID: 4\n",
      "Add of existing embedding ID: 5\n",
      "Add of existing embedding ID: 6\n",
      "Add of existing embedding ID: 7\n",
      "Add of existing embedding ID: 8\n",
      "Add of existing embedding ID: 9\n",
      "Add of existing embedding ID: 10\n",
      "Add of existing embedding ID: 11\n",
      "Add of existing embedding ID: 12\n",
      "Add of existing embedding ID: 13\n",
      "Add of existing embedding ID: 14\n",
      "Add of existing embedding ID: 15\n",
      "Add of existing embedding ID: 16\n",
      "Add of existing embedding ID: 17\n",
      "Add of existing embedding ID: 18\n",
      "Add of existing embedding ID: 19\n",
      "Add of existing embedding ID: 20\n",
      "Add of existing embedding ID: 21\n",
      "Add of existing embedding ID: 22\n",
      "Add of existing embedding ID: 23\n",
      "Add of existing embedding ID: 24\n",
      "Add of existing embedding ID: 25\n",
      "Add of existing embedding ID: 26\n",
      "Add of existing embedding ID: 27\n",
      "Add of existing embedding ID: 28\n",
      "Add of existing embedding ID: 29\n",
      "Add of existing embedding ID: 30\n",
      "Add of existing embedding ID: 31\n",
      "Add of existing embedding ID: 32\n",
      "Add of existing embedding ID: 33\n",
      "Add of existing embedding ID: 34\n",
      "Add of existing embedding ID: 35\n",
      "Add of existing embedding ID: 36\n",
      "Add of existing embedding ID: 37\n",
      "Add of existing embedding ID: 38\n",
      "Add of existing embedding ID: 39\n",
      "Add of existing embedding ID: 40\n",
      "Add of existing embedding ID: 41\n",
      "Add of existing embedding ID: 42\n",
      "Add of existing embedding ID: 43\n",
      "Add of existing embedding ID: 44\n",
      "Add of existing embedding ID: 45\n",
      "Add of existing embedding ID: 46\n",
      "Add of existing embedding ID: 47\n",
      "Add of existing embedding ID: 48\n",
      "Add of existing embedding ID: 49\n",
      "Add of existing embedding ID: 50\n",
      "Add of existing embedding ID: 51\n",
      "Add of existing embedding ID: 52\n",
      "Add of existing embedding ID: 53\n",
      "Add of existing embedding ID: 54\n",
      "Add of existing embedding ID: 55\n",
      "Add of existing embedding ID: 56\n",
      "Add of existing embedding ID: 57\n",
      "Add of existing embedding ID: 58\n",
      "Add of existing embedding ID: 59\n",
      "Add of existing embedding ID: 60\n",
      "Add of existing embedding ID: 61\n",
      "Add of existing embedding ID: 62\n",
      "Add of existing embedding ID: 63\n",
      "Add of existing embedding ID: 64\n",
      "Add of existing embedding ID: 65\n",
      "Add of existing embedding ID: 66\n",
      "Add of existing embedding ID: 67\n",
      "Add of existing embedding ID: 68\n",
      "Add of existing embedding ID: 69\n",
      "Add of existing embedding ID: 70\n",
      "Add of existing embedding ID: 71\n",
      "Add of existing embedding ID: 72\n",
      "Add of existing embedding ID: 73\n",
      "Add of existing embedding ID: 74\n",
      "Add of existing embedding ID: 75\n",
      "Add of existing embedding ID: 76\n",
      "Add of existing embedding ID: 77\n",
      "Add of existing embedding ID: 78\n",
      "Add of existing embedding ID: 79\n",
      "Add of existing embedding ID: 80\n",
      "Add of existing embedding ID: 81\n",
      "Add of existing embedding ID: 82\n",
      "Add of existing embedding ID: 83\n",
      "Add of existing embedding ID: 84\n",
      "Add of existing embedding ID: 85\n",
      "Add of existing embedding ID: 86\n",
      "Add of existing embedding ID: 87\n",
      "Add of existing embedding ID: 88\n",
      "Add of existing embedding ID: 89\n",
      "Add of existing embedding ID: 90\n",
      "Add of existing embedding ID: 91\n",
      "Add of existing embedding ID: 92\n",
      "Add of existing embedding ID: 93\n",
      "Add of existing embedding ID: 94\n",
      "Add of existing embedding ID: 95\n",
      "Add of existing embedding ID: 96\n",
      "Add of existing embedding ID: 97\n",
      "Add of existing embedding ID: 98\n",
      "Add of existing embedding ID: 99\n",
      "Add of existing embedding ID: 100\n",
      "Add of existing embedding ID: 101\n",
      "Add of existing embedding ID: 102\n",
      "Add of existing embedding ID: 103\n",
      "Add of existing embedding ID: 104\n",
      "Add of existing embedding ID: 105\n",
      "Add of existing embedding ID: 106\n",
      "Add of existing embedding ID: 107\n",
      "Add of existing embedding ID: 108\n",
      "Add of existing embedding ID: 109\n",
      "Add of existing embedding ID: 110\n",
      "Add of existing embedding ID: 111\n",
      "Add of existing embedding ID: 112\n",
      "Add of existing embedding ID: 113\n",
      "Add of existing embedding ID: 114\n",
      "Add of existing embedding ID: 115\n",
      "Add of existing embedding ID: 116\n",
      "Add of existing embedding ID: 117\n",
      "Add of existing embedding ID: 118\n",
      "Add of existing embedding ID: 119\n",
      "Add of existing embedding ID: 120\n",
      "Add of existing embedding ID: 121\n",
      "Add of existing embedding ID: 122\n",
      "Add of existing embedding ID: 123\n",
      "Add of existing embedding ID: 124\n",
      "Add of existing embedding ID: 125\n",
      "Add of existing embedding ID: 126\n",
      "Add of existing embedding ID: 127\n",
      "Add of existing embedding ID: 128\n",
      "Add of existing embedding ID: 129\n",
      "Add of existing embedding ID: 130\n",
      "Add of existing embedding ID: 131\n",
      "Add of existing embedding ID: 132\n",
      "Add of existing embedding ID: 133\n",
      "Add of existing embedding ID: 134\n",
      "Add of existing embedding ID: 135\n",
      "Add of existing embedding ID: 136\n",
      "Add of existing embedding ID: 137\n",
      "Add of existing embedding ID: 138\n",
      "Add of existing embedding ID: 139\n",
      "Add of existing embedding ID: 140\n",
      "Add of existing embedding ID: 141\n",
      "Add of existing embedding ID: 142\n",
      "Add of existing embedding ID: 143\n",
      "Add of existing embedding ID: 144\n",
      "Add of existing embedding ID: 145\n",
      "Add of existing embedding ID: 146\n",
      "Add of existing embedding ID: 147\n",
      "Add of existing embedding ID: 148\n",
      "Add of existing embedding ID: 149\n",
      "Add of existing embedding ID: 150\n",
      "Add of existing embedding ID: 151\n",
      "Add of existing embedding ID: 152\n",
      "Add of existing embedding ID: 153\n",
      "Add of existing embedding ID: 154\n",
      "Add of existing embedding ID: 155\n",
      "Add of existing embedding ID: 156\n",
      "Add of existing embedding ID: 157\n",
      "Add of existing embedding ID: 158\n",
      "Add of existing embedding ID: 159\n",
      "Add of existing embedding ID: 160\n",
      "Add of existing embedding ID: 161\n",
      "Add of existing embedding ID: 162\n",
      "Add of existing embedding ID: 163\n",
      "Add of existing embedding ID: 164\n",
      "Add of existing embedding ID: 165\n",
      "Add of existing embedding ID: 166\n",
      "Add of existing embedding ID: 167\n",
      "Add of existing embedding ID: 168\n",
      "Add of existing embedding ID: 169\n",
      "Add of existing embedding ID: 170\n",
      "Add of existing embedding ID: 171\n",
      "Add of existing embedding ID: 172\n",
      "Add of existing embedding ID: 173\n",
      "Add of existing embedding ID: 174\n",
      "Add of existing embedding ID: 175\n",
      "Add of existing embedding ID: 176\n",
      "Add of existing embedding ID: 177\n",
      "Add of existing embedding ID: 178\n",
      "Add of existing embedding ID: 179\n",
      "Add of existing embedding ID: 180\n",
      "Add of existing embedding ID: 181\n",
      "Add of existing embedding ID: 182\n",
      "Add of existing embedding ID: 183\n",
      "Add of existing embedding ID: 184\n",
      "Add of existing embedding ID: 185\n",
      "Add of existing embedding ID: 186\n",
      "Add of existing embedding ID: 187\n",
      "Add of existing embedding ID: 188\n",
      "Add of existing embedding ID: 189\n",
      "Add of existing embedding ID: 190\n",
      "Add of existing embedding ID: 191\n",
      "Add of existing embedding ID: 192\n",
      "Add of existing embedding ID: 193\n",
      "Add of existing embedding ID: 194\n",
      "Add of existing embedding ID: 195\n",
      "Add of existing embedding ID: 196\n",
      "Add of existing embedding ID: 197\n",
      "Add of existing embedding ID: 198\n",
      "Add of existing embedding ID: 199\n",
      "Add of existing embedding ID: 200\n",
      "Add of existing embedding ID: 201\n",
      "Add of existing embedding ID: 202\n",
      "Add of existing embedding ID: 203\n",
      "Add of existing embedding ID: 204\n",
      "Add of existing embedding ID: 205\n",
      "Add of existing embedding ID: 206\n",
      "Add of existing embedding ID: 207\n",
      "Add of existing embedding ID: 208\n",
      "Add of existing embedding ID: 209\n",
      "Add of existing embedding ID: 210\n",
      "Add of existing embedding ID: 211\n",
      "Add of existing embedding ID: 212\n",
      "Add of existing embedding ID: 213\n",
      "Add of existing embedding ID: 214\n",
      "Add of existing embedding ID: 215\n",
      "Add of existing embedding ID: 216\n",
      "Add of existing embedding ID: 217\n",
      "Add of existing embedding ID: 218\n",
      "Add of existing embedding ID: 219\n",
      "Add of existing embedding ID: 220\n",
      "Add of existing embedding ID: 221\n",
      "Add of existing embedding ID: 222\n",
      "Add of existing embedding ID: 223\n",
      "Add of existing embedding ID: 224\n",
      "Add of existing embedding ID: 225\n",
      "Add of existing embedding ID: 226\n",
      "Add of existing embedding ID: 227\n",
      "Add of existing embedding ID: 228\n",
      "Add of existing embedding ID: 229\n",
      "Add of existing embedding ID: 230\n",
      "Add of existing embedding ID: 231\n",
      "Add of existing embedding ID: 232\n",
      "Add of existing embedding ID: 233\n",
      "Add of existing embedding ID: 234\n",
      "Add of existing embedding ID: 235\n",
      "Add of existing embedding ID: 236\n",
      "Add of existing embedding ID: 237\n",
      "Add of existing embedding ID: 238\n",
      "Add of existing embedding ID: 239\n",
      "Add of existing embedding ID: 240\n",
      "Add of existing embedding ID: 241\n",
      "Add of existing embedding ID: 242\n",
      "Add of existing embedding ID: 243\n",
      "Add of existing embedding ID: 244\n",
      "Add of existing embedding ID: 245\n",
      "Add of existing embedding ID: 246\n",
      "Add of existing embedding ID: 247\n",
      "Add of existing embedding ID: 248\n",
      "Add of existing embedding ID: 249\n",
      "Add of existing embedding ID: 250\n"
     ]
    }
   ],
   "source": [
    "# Create db and comment's collection\n",
    "PERSIST_DIRECTORY = \"C:\\\\Users\\\\eduar\\\\Documents\\\\Master_Thesis\\\\GenAI_Thesis_Beekeeper\\\\data\\\\vector_db\"\n",
    "\n",
    "# Initialize the database\n",
    "vectordb_2datasets = chromadb.PersistentClient(path=PERSIST_DIRECTORY, \n",
    "                                               settings=Settings(allow_reset=True,\n",
    "                                                                 ))\n",
    "# Define the open-source embedding function ()\n",
    "#embedding_func = SentenceTransformerEmbeddings(model_name=\"all-mpnet-base-v2\")\n",
    "embedding_func = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Create a collection for the comments\n",
    "collection_comments = vectordb_2datasets.get_or_create_collection(name=\"collection_comments\",\n",
    "                                                                  #embedding_function=embedding_func\n",
    "                                                                  )\n",
    "collection_comments.add(documents=documents_comments,\n",
    "                        metadatas=metadatas_comments,\n",
    "                        ids=ids_comments\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a collection for the posts\n",
    "collection_posts = vectordb_2datasets.get_or_create_collection(name=\"collection_posts\",\n",
    "                                                               )\n",
    "collection_posts.add(documents=documents_posts,\n",
    "                     metadatas=metadatas_posts,\n",
    "                     ids=ids_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the client\n",
    "#vectordb_2datasets.reset()\n",
    "\n",
    "# Delete the collection\n",
    "#vectordb_2datasets.delete_collection(name=\"collection_comments\")\n",
    "#vectordb_2datasets.delete_collection(name=\"collection_posts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 250 in the collection of comments.\n",
      "There are 198 in the collection of comments.\n"
     ]
    }
   ],
   "source": [
    "# Define the open-source embedding function ()\n",
    "#embedding_func = SentenceTransformerEmbeddings(model_name=\"all-mpnet-base-v2\")\n",
    "embedding_func = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Passing a Chroma Client into Langchain\n",
    "langchain_chroma_comments = Chroma(client=vectordb_2datasets,                        \n",
    "                         collection_name=\"collection_comments\",\n",
    "                         embedding_function=embedding_func,\n",
    ")\n",
    "print(\"There are\", langchain_chroma_comments._collection.count(), \"in the collection of comments.\")\n",
    "\n",
    "\n",
    "# Passing a Chroma Client into Langchain\n",
    "langchain_chroma_posts = Chroma(client=vectordb_2datasets,                        \n",
    "                         collection_name=\"collection_posts\",\n",
    "                         embedding_function=embedding_func,\n",
    ")\n",
    "print(\"There are\", langchain_chroma_posts._collection.count(), \"in the collection of comments.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata description\n",
    "metadata_field_info_comments = [\n",
    "    AttributeInfo(\n",
    "        name=\"stream_name\",\n",
    "        description=\"The stream where the comment was poste. One of ['Jobs','Water Break','Safety & Operations','OSC, We Can Help','Flagger Force Connect','The Whiteboard','Test Stream']\",\n",
    "        type=\"object\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"created_date\",\n",
    "        description=\"The datetime when the comment was posted\",\n",
    "        type=\"object\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"post_id\",\n",
    "        description=\"The id of the post where the comment was posted\",\n",
    "        type=\"int64\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"comment_id\",\n",
    "        description=\"The id of the comment\",\n",
    "        type=\"int64\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"like_count\",\n",
    "        description=\"The number of likes received by the comment\",\n",
    "        type=\"int64\",        \n",
    "    ),    \n",
    "    AttributeInfo(\n",
    "        name=\"report_count\",\n",
    "        description=\"The number of reports where the comment appears\",\n",
    "        type=\"int64\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"username\",\n",
    "        description=\"The username of the author of the comment\",\n",
    "        type=\"object\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"author_user_id\",\n",
    "        description=\"The id of the author of the comment\",\n",
    "        type=\"object\",\n",
    "    ),    \n",
    "    AttributeInfo(\n",
    "        name=\"author_position\",\n",
    "        description=\"The position of the author of the comment. One of ['Advanced Crew Leader','Crew Member','Crew Leader','Weekend Dispatch','Lead Instructor','Area Supervisor','Field Trainer 1','Warehouse Coordinator','Field Trainer 2','Executive Assistant','Internal Communications Manager','Field Manager','Safety Professional','Internal Communications Coordinator', 'Employee Services Supervisor','Safety Advocate', and many more...]\",\n",
    "        type=\"object\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"author_status\",\n",
    "        description=\"The status of the author of the comment. One of ['active','suspended']\",\n",
    "        type=\"object\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Creating our self-querying retriever\n",
    "document_content_description = \"Comments on social network posts\"\n",
    "llm = ChatOllama(model=\"mistral\")\n",
    "\n",
    "retriever_comments = SelfQueryRetriever.from_llm(    \n",
    "    llm,\n",
    "    langchain_chroma_comments,\n",
    "    document_content_description,    \n",
    "    metadata_field_info_comments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example only specifies a query\n",
    "results_a = retriever_comments.invoke(\"What are some comments about birthday congratulations\")\n",
    "results_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posts Metadata description\n",
    "metadata_field_info_post = [\n",
    "    AttributeInfo(\n",
    "        name=\"stream_name\",\n",
    "        description=\"The stream where the comment was poste. One of ['Jobs','Water Break','Safety & Operations','OSC, We Can Help','Flagger Force Connect','The Whiteboard','Test Stream']\",\n",
    "        type=\"object\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"stream_id\",\n",
    "        description=\"The id of the stream where the post was posted\",\n",
    "        type=\"int64\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"post_id\",\n",
    "        description=\"The id of the post\",\n",
    "        type=\"int64\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"action\",\n",
    "        description=\"The id of the post where the comment was posted\",\n",
    "        type=\"object\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"created\",\n",
    "        description=\"The datetime when the post was create\",\n",
    "        type=\"object\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"title\",\n",
    "        description=\"The title of the post\",\n",
    "        type=\"object\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"like_count\",\n",
    "        description=\"The number of likes received by the post\",\n",
    "        type=\"int64\",        \n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"comment_countt\",\n",
    "        description=\"The number of comments received by the post\",\n",
    "        type=\"int64\",        \n",
    "    ),   \n",
    "    AttributeInfo(\n",
    "        name=\"mentions\",\n",
    "        description=\"The usernames that were mention in the post\",\n",
    "        type=\"object\",\n",
    "    ),        \n",
    "    # AttributeInfo(\n",
    "    #     name=\"labels\",\n",
    "    #     description=\"The keywords found in the post\",\n",
    "    #     type=\"int64\",\n",
    "    # ),\n",
    "    AttributeInfo(\n",
    "        name=\"username\",\n",
    "        description=\"The username of the author of the post\",\n",
    "        type=\"object\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"author_user_id\",\n",
    "        description=\"The id of the author of the post\",\n",
    "        type=\"object\",\n",
    "    ),    \n",
    "    AttributeInfo(\n",
    "        name=\"author_position\",\n",
    "        description=\"The position of the author of the post. One of ['Advanced Crew Leader','Crew Member','Crew Leader','Weekend Dispatch','Lead Instructor','Area Supervisor','Field Trainer 1','Warehouse Coordinator','Field Trainer 2','Executive Assistant','Internal Communications Manager','Field Manager','Safety Professional','Internal Communications Coordinator', 'Employee Services Supervisor','Safety Advocate', and many more...]\",\n",
    "        type=\"object\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"author_status\",\n",
    "        description=\"The status of the author of the post. One of ['active','suspended']\",\n",
    "        type=\"object\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Creating our self-querying retriever\n",
    "document_content_description = \"Posts in social network\"\n",
    "llm = ChatOllama(model=\"mistral\")\n",
    "\n",
    "retriever_posts = SelfQueryRetriever.from_llm(    \n",
    "    llm,\n",
    "    langchain_chroma_posts,\n",
    "    document_content_description,    \n",
    "    metadata_field_info_post,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutputParserException",
     "evalue": "Parsing text\n ```json\n{\n    \"query\": \"congratulations\",\n    \"filter\": \"and(or(eq(\\\"labels\\\".\\\"0\\\", \\\"congratulations\\\"), eq(\\\"labels\\\".\\\"1\\\", \\\"congratulations\\\")))\"\n}\n```\n raised following error:\nNo terminal matches '.' in the current parser context, at line 1 col 19\n\nand(or(eq(\"labels\".\"0\", \"congratulations\"), eq(\"labels\".\"1\n                  ^\nExpected one of: \n\t* COMMA\n\t* RPAR\n\t* RSQB\n\nPrevious tokens: Token('ESCAPED_STRING', '\"labels\"')\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnexpectedCharacters\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\lark\\lexer.py:673\u001b[0m, in \u001b[0;36mContextualLexer.lex\u001b[1;34m(self, lexer_state, parser_state)\u001b[0m\n\u001b[0;32m    672\u001b[0m last_token \u001b[38;5;241m=\u001b[39m lexer_state\u001b[38;5;241m.\u001b[39mlast_token  \u001b[38;5;66;03m# Save last_token. Calling root_lexer.next_token will change this to the wrong token\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot_lexer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlexer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m UnexpectedToken(token, e\u001b[38;5;241m.\u001b[39mallowed, state\u001b[38;5;241m=\u001b[39mparser_state, token_history\u001b[38;5;241m=\u001b[39m[last_token], terminals_by_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_lexer\u001b[38;5;241m.\u001b[39mterminals_by_name)\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\lark\\lexer.py:598\u001b[0m, in \u001b[0;36mBasicLexer.next_token\u001b[1;34m(self, lex_state, parser_state)\u001b[0m\n\u001b[0;32m    597\u001b[0m         allowed \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<END-OF-FILE>\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m--> 598\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnexpectedCharacters(lex_state\u001b[38;5;241m.\u001b[39mtext, line_ctr\u001b[38;5;241m.\u001b[39mchar_pos, line_ctr\u001b[38;5;241m.\u001b[39mline, line_ctr\u001b[38;5;241m.\u001b[39mcolumn,\n\u001b[0;32m    599\u001b[0m                                allowed\u001b[38;5;241m=\u001b[39mallowed, token_history\u001b[38;5;241m=\u001b[39mlex_state\u001b[38;5;241m.\u001b[39mlast_token \u001b[38;5;129;01mand\u001b[39;00m [lex_state\u001b[38;5;241m.\u001b[39mlast_token],\n\u001b[0;32m    600\u001b[0m                                state\u001b[38;5;241m=\u001b[39mparser_state, terminals_by_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mterminals_by_name)\n\u001b[0;32m    602\u001b[0m value, type_ \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[1;31mUnexpectedCharacters\u001b[0m: No terminal matches '.' in the current parser context, at line 1 col 19\n\nand(or(eq(\"labels\".\"0\", \"congratulations\"), eq(\"labels\".\"1\n                  ^\nExpected one of: \n\t* COMMA\n\t* SIGNED_INT\n\t* /'[^']*'/\n\t* DATE\n\t* LPAR\n\t* RPAR\n\t* ESCAPED_STRING\n\t* SIGNED_FLOAT\n\t* RSQB\n\t* CNAME\n\t* LSQB\n\nPrevious tokens: Token('ESCAPED_STRING', '\"labels\"')\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUnexpectedCharacters\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\langchain\\chains\\query_constructor\\base.py:56\u001b[0m, in \u001b[0;36mStructuredQueryOutputParser.parse\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 56\u001b[0m     parsed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilter\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mast_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparsed\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfilter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parsed\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlimit\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\lark\\lark.py:658\u001b[0m, in \u001b[0;36mLark.parse\u001b[1;34m(self, text, start, on_error)\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Parse the given text, according to the options provided.\u001b[39;00m\n\u001b[0;32m    642\u001b[0m \n\u001b[0;32m    643\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    656\u001b[0m \n\u001b[0;32m    657\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 658\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\lark\\parser_frontends.py:104\u001b[0m, in \u001b[0;36mParsingFrontend.parse\u001b[1;34m(self, text, start, on_error)\u001b[0m\n\u001b[0;32m    103\u001b[0m stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_lexer_thread(text)\n\u001b[1;32m--> 104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparser\u001b[38;5;241m.\u001b[39mparse(stream, chosen_start, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\lark\\parsers\\lalr_parser.py:42\u001b[0m, in \u001b[0;36mLALR_Parser.parse\u001b[1;34m(self, lexer, start, on_error)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m UnexpectedInput \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\lark\\parsers\\lalr_parser.py:88\u001b[0m, in \u001b[0;36m_Parser.parse\u001b[1;34m(self, lexer, start, value_stack, state_stack, start_interactive)\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m InteractiveParser(\u001b[38;5;28mself\u001b[39m, parser_state, parser_state\u001b[38;5;241m.\u001b[39mlexer)\n\u001b[1;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_from_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparser_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\lark\\parsers\\lalr_parser.py:111\u001b[0m, in \u001b[0;36m_Parser.parse_from_state\u001b[1;34m(self, state, last_token)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m--> 111\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\lark\\parsers\\lalr_parser.py:100\u001b[0m, in \u001b[0;36m_Parser.parse_from_state\u001b[1;34m(self, state, last_token)\u001b[0m\n\u001b[0;32m     99\u001b[0m token \u001b[38;5;241m=\u001b[39m last_token\n\u001b[1;32m--> 100\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m state\u001b[38;5;241m.\u001b[39mlexer\u001b[38;5;241m.\u001b[39mlex(state):\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\lark\\lexer.py:676\u001b[0m, in \u001b[0;36mContextualLexer.lex\u001b[1;34m(self, lexer_state, parser_state)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m UnexpectedCharacters:\n\u001b[1;32m--> 676\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\lark\\lexer.py:665\u001b[0m, in \u001b[0;36mContextualLexer.lex\u001b[1;34m(self, lexer_state, parser_state)\u001b[0m\n\u001b[0;32m    664\u001b[0m         lexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlexers[parser_state\u001b[38;5;241m.\u001b[39mposition]\n\u001b[1;32m--> 665\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mlexer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlexer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\lark\\lexer.py:598\u001b[0m, in \u001b[0;36mBasicLexer.next_token\u001b[1;34m(self, lex_state, parser_state)\u001b[0m\n\u001b[0;32m    597\u001b[0m         allowed \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<END-OF-FILE>\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m--> 598\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnexpectedCharacters(lex_state\u001b[38;5;241m.\u001b[39mtext, line_ctr\u001b[38;5;241m.\u001b[39mchar_pos, line_ctr\u001b[38;5;241m.\u001b[39mline, line_ctr\u001b[38;5;241m.\u001b[39mcolumn,\n\u001b[0;32m    599\u001b[0m                                allowed\u001b[38;5;241m=\u001b[39mallowed, token_history\u001b[38;5;241m=\u001b[39mlex_state\u001b[38;5;241m.\u001b[39mlast_token \u001b[38;5;129;01mand\u001b[39;00m [lex_state\u001b[38;5;241m.\u001b[39mlast_token],\n\u001b[0;32m    600\u001b[0m                                state\u001b[38;5;241m=\u001b[39mparser_state, terminals_by_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mterminals_by_name)\n\u001b[0;32m    602\u001b[0m value, type_ \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[1;31mUnexpectedCharacters\u001b[0m: No terminal matches '.' in the current parser context, at line 1 col 19\n\nand(or(eq(\"labels\".\"0\", \"congratulations\"), eq(\"labels\".\"1\n                  ^\nExpected one of: \n\t* COMMA\n\t* RPAR\n\t* RSQB\n\nPrevious tokens: Token('ESCAPED_STRING', '\"labels\"')\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# This example only specifies a query\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m result_b \u001b[38;5;241m=\u001b[39m \u001b[43mretriever_posts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat are two posts about congratulations\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m result_b\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\langchain_core\\retrievers.py:194\u001b[0m, in \u001b[0;36mBaseRetriever.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Invoke the retriever to get relevant documents.\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \n\u001b[0;32m    177\u001b[0m \u001b[38;5;124;03mMain entry point for synchronous retriever invocations.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;124;03m    retriever.invoke(\"query\")\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    193\u001b[0m config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m--> 194\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_relevant_documents(\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    196\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    197\u001b[0m     tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    198\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    199\u001b[0m     run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    201\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:148\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    146\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     emit_warning()\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\langchain_core\\retrievers.py:323\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[1;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    322\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_error(e)\n\u001b[1;32m--> 323\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    325\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_end(\n\u001b[0;32m    326\u001b[0m         result,\n\u001b[0;32m    327\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\langchain_core\\retrievers.py:316\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[1;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m _kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_arg_supported:\n\u001b[1;32m--> 316\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(\n\u001b[0;32m    317\u001b[0m         query, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs\n\u001b[0;32m    318\u001b[0m     )\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    320\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\langchain\\retrievers\\self_query\\base.py:217\u001b[0m, in \u001b[0;36mSelfQueryRetriever._get_relevant_documents\u001b[1;34m(self, query, run_manager)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_relevant_documents\u001b[39m(\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m, run_manager: CallbackManagerForRetrieverRun\n\u001b[0;32m    208\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[0;32m    209\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get documents relevant for a query.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \n\u001b[0;32m    211\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;124;03m        List of relevant documents\u001b[39;00m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m     structured_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_constructor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[0;32m    221\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated Query: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstructured_query\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\langchain_core\\runnables\\base.py:4525\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   4519\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m   4520\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4521\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[0;32m   4522\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   4523\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   4524\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[1;32m-> 4525\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m   4526\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   4527\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[0;32m   4528\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[0;32m   4529\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\langchain_core\\runnables\\base.py:2499\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m   2497\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2498\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[1;32m-> 2499\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2500\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2501\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[0;32m   2502\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2503\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2504\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2505\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2506\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   2507\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\langchain_core\\output_parsers\\base.py:169\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Union[\u001b[38;5;28mstr\u001b[39m, BaseMessage], config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    167\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[1;32m--> 169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[0;32m    179\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result([Generation(text\u001b[38;5;241m=\u001b[39minner_input)]),\n\u001b[0;32m    180\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    181\u001b[0m             config,\n\u001b[0;32m    182\u001b[0m             run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    183\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\langchain_core\\runnables\\base.py:1626\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[1;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[0;32m   1622\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[0;32m   1623\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(var_child_runnable_config\u001b[38;5;241m.\u001b[39mset, child_config)\n\u001b[0;32m   1624\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m   1625\u001b[0m         Output,\n\u001b[1;32m-> 1626\u001b[0m         context\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m   1627\u001b[0m             call_func_with_variable_args,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1628\u001b[0m             func,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1629\u001b[0m             \u001b[38;5;28minput\u001b[39m,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1630\u001b[0m             config,\n\u001b[0;32m   1631\u001b[0m             run_manager,\n\u001b[0;32m   1632\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1633\u001b[0m         ),\n\u001b[0;32m   1634\u001b[0m     )\n\u001b[0;32m   1635\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1636\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\langchain_core\\runnables\\config.py:347\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    346\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\langchain_core\\output_parsers\\base.py:170\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke.<locals>.<lambda>\u001b[1;34m(inner_input)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Union[\u001b[38;5;28mstr\u001b[39m, BaseMessage], config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    167\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[0;32m    169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[1;32m--> 170\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    173\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    174\u001b[0m             config,\n\u001b[0;32m    175\u001b[0m             run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    176\u001b[0m         )\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[0;32m    179\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result([Generation(text\u001b[38;5;241m=\u001b[39minner_input)]),\n\u001b[0;32m    180\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    181\u001b[0m             config,\n\u001b[0;32m    182\u001b[0m             run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    183\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\langchain_core\\output_parsers\\base.py:221\u001b[0m, in \u001b[0;36mBaseOutputParser.parse_result\u001b[1;34m(self, result, partial)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_result\u001b[39m(\u001b[38;5;28mself\u001b[39m, result: List[Generation], \u001b[38;5;241m*\u001b[39m, partial: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m    209\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Parse a list of candidate model Generations into a specific format.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \n\u001b[0;32m    211\u001b[0m \u001b[38;5;124;03m    The return value is parsed from only the first Generation in the result, which\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;124;03m        Structured output.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\langchain\\chains\\query_constructor\\base.py:63\u001b[0m, in \u001b[0;36mStructuredQueryOutputParser.parse\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m StructuredQuery(\n\u001b[0;32m     60\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m parsed\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m allowed_keys}\n\u001b[0;32m     61\u001b[0m     )\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 63\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\n\u001b[0;32m     64\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParsing text\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m raised following error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     65\u001b[0m     )\n",
      "\u001b[1;31mOutputParserException\u001b[0m: Parsing text\n ```json\n{\n    \"query\": \"congratulations\",\n    \"filter\": \"and(or(eq(\\\"labels\\\".\\\"0\\\", \\\"congratulations\\\"), eq(\\\"labels\\\".\\\"1\\\", \\\"congratulations\\\")))\"\n}\n```\n raised following error:\nNo terminal matches '.' in the current parser context, at line 1 col 19\n\nand(or(eq(\"labels\".\"0\", \"congratulations\"), eq(\"labels\".\"1\n                  ^\nExpected one of: \n\t* COMMA\n\t* RPAR\n\t* RSQB\n\nPrevious tokens: Token('ESCAPED_STRING', '\"labels\"')\n"
     ]
    }
   ],
   "source": [
    "# This example only specifies a query\n",
    "result_b = retriever_posts.invoke(\"What are two posts about birthday congratulations\")\n",
    "result_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 200 in the collection of comments.\n"
     ]
    }
   ],
   "source": [
    "# Passing a Chroma Client into Langchain\n",
    "langchain_chroma = Chroma(    \n",
    "    client=vectordb_2datasets,\n",
    "    collection_name=\"collection_comments\",\n",
    "    #embedding_function=embedding_func,\n",
    ")\n",
    "\n",
    "print(\"There are\", langchain_chroma._collection.count(), \"in the collection of comments.\")\n",
    "#print(\"There are\", langchain_chroma._collection_posts.count(), \"in the collection of posts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 50 in the collection.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Collection(name=collection_posts)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Passing a Chroma Client into Langchain\n",
    "langchain_chroma_post = Chroma(    \n",
    "    client=vectordb_2datasets,\n",
    "    collection_name=\"collection_posts\",\n",
    "    #embedding_function=embedding_func,\n",
    ")\n",
    "\n",
    "print(\"There are\", langchain_chroma_post._collection.count(), \"in the collection.\")\n",
    "#print(\"There are\", langchain_chroma._collection_posts.count(), \"in the collection of posts.\")\n",
    "langchain_chroma_post._collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You must provide embeddings or a function to compute them",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[101], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Test the langchain_chroma_post\u001b[39;00m\n\u001b[0;32m      2\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat it got said about Jonathan_Muha\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m docs \u001b[38;5;241m=\u001b[39m \u001b[43mlangchain_chroma_post\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(docs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mpage_content)\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:349\u001b[0m, in \u001b[0;36mChroma.similarity_search\u001b[1;34m(self, query, k, filter, **kwargs)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimilarity_search\u001b[39m(\n\u001b[0;32m    333\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    334\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    338\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[0;32m    339\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run similarity search with Chroma.\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \n\u001b[0;32m    341\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;124;03m        List[Document]: List of documents most similar to the query text.\u001b[39;00m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 349\u001b[0m     docs_and_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimilarity_search_with_score(\n\u001b[0;32m    350\u001b[0m         query, k, \u001b[38;5;28mfilter\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfilter\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    351\u001b[0m     )\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [doc \u001b[38;5;28;01mfor\u001b[39;00m doc, _ \u001b[38;5;129;01min\u001b[39;00m docs_and_scores]\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:430\u001b[0m, in \u001b[0;36mChroma.similarity_search_with_score\u001b[1;34m(self, query, k, filter, where_document, **kwargs)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run similarity search with Chroma with distance.\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \n\u001b[0;32m    419\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;124;03m    Lower score represents more similarity.\u001b[39;00m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    429\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 430\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__query_collection(\n\u001b[0;32m    431\u001b[0m         query_texts\u001b[38;5;241m=\u001b[39m[query],\n\u001b[0;32m    432\u001b[0m         n_results\u001b[38;5;241m=\u001b[39mk,\n\u001b[0;32m    433\u001b[0m         where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfilter\u001b[39m,\n\u001b[0;32m    434\u001b[0m         where_document\u001b[38;5;241m=\u001b[39mwhere_document,\n\u001b[0;32m    435\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    436\u001b[0m     )\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m     query_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function\u001b[38;5;241m.\u001b[39membed_query(query)\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\langchain_core\\utils\\utils.py:35\u001b[0m, in \u001b[0;36mxor_args.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     29\u001b[0m     invalid_group_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(arg_groups[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m invalid_groups]\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     31\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExactly one argument in each of the following\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     32\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m groups must be defined:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(invalid_group_names)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     34\u001b[0m     )\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:156\u001b[0m, in \u001b[0;36mChroma.__query_collection\u001b[1;34m(self, query_texts, query_embeddings, n_results, where, where_document, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m    153\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import chromadb python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    154\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install chromadb`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    155\u001b[0m     )\n\u001b[1;32m--> 156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collection\u001b[38;5;241m.\u001b[39mquery(\n\u001b[0;32m    157\u001b[0m     query_texts\u001b[38;5;241m=\u001b[39mquery_texts,\n\u001b[0;32m    158\u001b[0m     query_embeddings\u001b[38;5;241m=\u001b[39mquery_embeddings,\n\u001b[0;32m    159\u001b[0m     n_results\u001b[38;5;241m=\u001b[39mn_results,\n\u001b[0;32m    160\u001b[0m     where\u001b[38;5;241m=\u001b[39mwhere,\n\u001b[0;32m    161\u001b[0m     where_document\u001b[38;5;241m=\u001b[39mwhere_document,\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    163\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\chromadb\\api\\models\\Collection.py:207\u001b[0m, in \u001b[0;36mCollection.query\u001b[1;34m(self, query_embeddings, query_texts, n_results, where, where_document, include)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m query_embeddings \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 207\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    208\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must provide embeddings or a function to compute them\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;66;03m# We know query texts is not None at this point, cast for the typechecker\u001b[39;00m\n\u001b[0;32m    211\u001b[0m     query_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function(\n\u001b[0;32m    212\u001b[0m         cast(List[Document], query_texts)\n\u001b[0;32m    213\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: You must provide embeddings or a function to compute them"
     ]
    }
   ],
   "source": [
    "# Test the langchain_chroma_post\n",
    "query = \"What it got said about Jonathan_Muha\"\n",
    "docs = langchain_chroma_post.similarity_search(query)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have a safe day, @Jonathan_Muha!\n"
     ]
    }
   ],
   "source": [
    "# Create a database\n",
    "\n",
    "# create the open-source embedding function\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-mpnet-base-v2\")\n",
    "\n",
    "# save to disk\n",
    "db = Chroma.from_documents(docs,\n",
    "                           embedding_function,\n",
    "                           #ids=ids,\n",
    "                           persist_directory=PERSIST_DIRECTORY)\n",
    "\n",
    "# Test the db\n",
    "query = \"What it got said about Jonathan_Muha\"\n",
    "docs = db.similarity_search(query)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating our self-querying retriever\n",
    "\n",
    "Now we can instantiate our retriever. To do this we’ll need to provide some information upfront about the metadata fields that our documents support and a short description of the document contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata description\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"stream_name\",\n",
    "        description=\"The stream where the comment was poste. One of ['Jobs','Water Break','Safety & Operations','OSC, We Can Help','Flagger Force Connect','The Whiteboard','Test Stream']\",\n",
    "        type=\"object\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"created_date\",\n",
    "        description=\"The datetime when the comment was posted\",\n",
    "        type=\"object\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"post_id\",\n",
    "        description=\"The id of the post where the comment was posted\",\n",
    "        type=\"int64\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"comment_id\",\n",
    "        description=\"The id of the comment\",\n",
    "        type=\"int64\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"like_count\",\n",
    "        description=\"The number of likes received by the comment\",\n",
    "        type=\"int64\",        \n",
    "    ),    \n",
    "    AttributeInfo(\n",
    "        name=\"report_count\",\n",
    "        description=\"The number of reports where the comment appears\",\n",
    "        type=\"int64\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"username\",\n",
    "        description=\"The username of the author of the comment\",\n",
    "        type=\"object\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"author_user_id\",\n",
    "        description=\"The id of the author of the comment\",\n",
    "        type=\"object\",\n",
    "    ),    \n",
    "    AttributeInfo(\n",
    "        name=\"author_position\",\n",
    "        description=\"The position of the author of the comment. One of ['Advanced Crew Leader','Crew Member','Crew Leader','Weekend Dispatch','Lead Instructor','Area Supervisor','Field Trainer 1','Warehouse Coordinator','Field Trainer 2','Executive Assistant','Internal Communications Manager','Field Manager','Safety Professional','Internal Communications Coordinator', 'Employee Services Supervisor','Safety Advocate', and many more...]\",\n",
    "        type=\"object\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"author_status\",\n",
    "        description=\"The position of the author of the comment. One of ['active','suspended']\",\n",
    "        type=\"object\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Creating our self-querying retriever\n",
    "document_content_description = \"Comments on social network posts\"\n",
    "llm = ChatOllama(model=\"mistral\")\n",
    "\n",
    "retriever = SelfQueryRetriever.from_llm(    \n",
    "    llm,\n",
    "    db,\n",
    "    document_content_description,    \n",
    "    metadata_field_info,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Testing out the retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Congratulations', metadata={'author_position': 'Crew Leader', 'author_status': 'suspended', 'author_user_id': 'e62d292b-7a01-4aa9-ab5a-e6fbfaa6e326', 'comment_id': 3927754, 'created_date': '2022-01-26 00:17:59', 'like_count': 0, 'post_id': 4989194, 'report_count': 0, 'stream_name': 'Safety & Operations', 'username': 'Donnie_Ziegler'}),\n",
       " Document(page_content='Congratulations', metadata={'author_position': 'Advanced Crew Leader', 'author_status': 'active', 'author_user_id': '5a3ca39e-5c41-4501-8eab-6a9ed0a62044', 'comment_id': 4686674, 'created_date': '2022-08-14 02:01:54', 'like_count': 0, 'post_id': 5643777, 'report_count': 0, 'stream_name': 'Safety & Operations', 'username': 'William_MobleyJr'}),\n",
       " Document(page_content='Congratulations', metadata={'author_position': 'Crew Member', 'author_status': 'suspended', 'author_user_id': '74f383df-5aa7-4efb-af99-5f96405dadc8', 'comment_id': 5163635, 'created_date': '2022-12-17 00:01:52', 'like_count': 0, 'post_id': 6082644, 'report_count': 0, 'stream_name': 'Safety & Operations', 'username': 'Tiffanie_Gaskins'}),\n",
       " Document(page_content='Congratulations 👏👏', metadata={'author_position': 'Advanced Crew Leader', 'author_status': 'active', 'author_user_id': '9c0fe286-e9ab-4000-a826-dbe70230a4c2', 'comment_id': 5528987, 'created_date': '2023-03-26 19:08:11', 'like_count': 0, 'post_id': 6337268, 'report_count': 0, 'stream_name': 'Safety & Operations', 'username': 'Towanda_Gordon'})]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This example only specifies a query\n",
    "retriever.invoke(\"What are two comments about congratulations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "username\n",
       "FlaggerForce        8\n",
       "weekend_dispatch    8\n",
       "Karen_Stroup        8\n",
       "Linwood_DavisJr     6\n",
       "Jessica_Beers       5\n",
       "                   ..\n",
       "Deon_McDaniel       1\n",
       "Adrienne_Long       1\n",
       "Stephen_Michael     1\n",
       "Towanda_Gordon      1\n",
       "Kyndra_Edwards      1\n",
       "Name: count, Length: 201, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comments_to_test['username'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='What did the buffalo say to his son when he dropped him off at school?\\nBison!!!! 😂🤣😭 @Jeffrey_Williams @Seth_Lee 😂🤣😭', metadata={'author_position': 'Field Trainer 1', 'author_status': 'suspended', 'author_user_id': 'f1555029-1597-4d3e-9199-4ebc04ed9702', 'comment_id': 4695288, 'created_date': '2022-08-16 19:19:26', 'like_count': 6, 'post_id': 5653172, 'report_count': 0, 'stream_name': 'Water Break', 'username': 'Collette_Monaghan'}),\n",
       " Document(page_content='As @Julie_Snedeker mentioned the focus here is to stop tampering with Flagger Forced issued equipment. The cameras believe it or not are in the vehicles for YOUR SAFETY. If you pick up the cell phone it says to put it down... if your following to close it says to back off... it is easy to sit and nitpick a photo but it is difficult to follow company policy.', metadata={'author_position': 'Safety Manager', 'author_status': 'active', 'author_user_id': '2aac35e8-f970-4434-9b46-56274384cf89', 'comment_id': 6601009, 'created_date': '2023-12-28 01:54:16', 'like_count': 6, 'post_id': 7367779, 'report_count': 0, 'stream_name': 'Safety & Operations', 'username': 'Scott_Richwine'}),\n",
       " Document(page_content='The background is clearly in a parking lot... anyone who has towed a PCMS understands the drum bases go in the back of the pickup truck.', metadata={'author_position': 'Safety Manager', 'author_status': 'active', 'author_user_id': '2aac35e8-f970-4434-9b46-56274384cf89', 'comment_id': 6601009, 'created_date': '2023-12-28 01:54:16', 'like_count': 6, 'post_id': 7367779, 'report_count': 0, 'stream_name': 'Safety & Operations', 'username': 'Scott_Richwine'})]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This example only specifies a filter\n",
    "retriever.invoke(\"What is a highly liked (above 4) comment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment_id\n",
       "6601009    6\n",
       "4695288    6\n",
       "5959837    4\n",
       "3993841    4\n",
       "6468179    4\n",
       "          ..\n",
       "5031138    0\n",
       "5049534    0\n",
       "5067432    0\n",
       "5068273    0\n",
       "6865894    0\n",
       "Name: like_count, Length: 300, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group by to find the comments with highest number of likes\n",
    "df_comments_to_test.groupby('comment_id')['like_count'].sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting the client\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "PERSIST_DIRECTORY = \"C:\\\\Users\\\\eduar\\\\Documents\\\\Master_Thesis\\\\GenAI_Thesis_Beekeeper\\\\data\\\\datasets_db\"\n",
    "\n",
    "chromadb_client = chromadb.PersistentClient(path=PERSIST_DIRECTORY, settings=Settings(allow_reset=True))\n",
    "chromadb_client.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Thank you Robert, I appreciate your knowledge\"\n",
    "docs = db.similarity_search(query)\n",
    "print(docs[0].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "\n",
    "PERSIST_DIRECTORY = \"C:\\\\Users\\\\eduar\\\\Documents\\\\Master_Thesis\\\\GenAI_Thesis_Beekeeper\\\\data\\\\datasets_db\"\n",
    "# embeddings = SentenceTransformerEmbeddings(model_name=\"all-mpnet-base-v2\")\n",
    "embeddings = OllamaEmbeddings(model=\"mistral\") \n",
    "\n",
    "persistent_client = chromadb.PersistentClient(path=PERSIST_DIRECTORY, settings=Settings(allow_reset=True))\n",
    "collection_comments = persistent_client.get_or_create_collection(\"collection_comments\",\n",
    "                                                        metadata={\"hnsw:space\": \"l2\"}, # Squared L2 norm(l2) is the default, inner product('ip') or cosine similarity('cosine')                                                              \n",
    "                                                        embedding_function=embeddings\n",
    "                                                        )\n",
    " # Add data to collection\n",
    "collection_comments.add(documents=documents,\n",
    "                        metadatas=metadatas,\n",
    "                        ids=ids\n",
    "                        )\n",
    "\n",
    "langchain_chroma = Chroma(\n",
    "    client=persistent_client,\n",
    "    collection_name=\"collection_comments\",\n",
    "    embedding_function=embeddings\n",
    ")\n",
    "\n",
    "print(\"There are\", langchain_chroma._collection.count(), \"in the collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting the client\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "PERSIST_DIRECTORY = \"C:\\\\Users\\\\eduar\\\\Documents\\\\Master_Thesis\\\\GenAI_Thesis_Beekeeper\\\\data\\\\datasets_db\"\n",
    "\n",
    "chromadb_client = chromadb.PersistentClient(path=PERSIST_DIRECTORY, settings=Settings(allow_reset=True))\n",
    "chromadb_client.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "#from langchain_chroma import Chroma\n",
    "#from langchain_community.embeddings import OllamaEmbeddings\n",
    "#import chromadb.utils.embedding_functions as embedding_functions\n",
    "from chromadb.config import Settings\n",
    "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "      \n",
    "PERSIST_DIRECTORY = \"C:\\\\Users\\\\eduar\\\\Documents\\\\Master_Thesis\\\\GenAI_Thesis_Beekeeper\\\\data\\\\datasets_db\"\n",
    "embeddings = SentenceTransformerEmbeddings(model_name=\"all-mpnet-base-v2\")    \n",
    "    \n",
    "\n",
    "# Function to create and load data to the database\n",
    "\"\"\"\n",
    "The embedding function takes text as input, and performs tokenization and embedding. If no embedding function is supplied, Chroma will use sentence transformer as a default.\n",
    "https://docs.trychroma.com/embeddings#sentence-transformers\n",
    "By default, Chroma uses all-MiniLM-L6-v2\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def upload_to_chromadb(documents, metadatas, ids):\n",
    "    try:            \n",
    "        # create the open-source embedding function\n",
    "        # embedding = OllamaEmbeddings(model=\"mistral\")\n",
    "        # embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")   # Default\n",
    "        embeddings = SentenceTransformerEmbeddings(model_name=\"all-mpnet-base-v2\")          # Best model from included in ChromaDB\n",
    "        \n",
    "        # Initialize ChromaDB client\n",
    "        # load it into Chroma\n",
    "        db = Chroma.from_documents(documents, embeddings,\n",
    "                                    persist_directory=PERSIST_DIRECTORY)\n",
    "               \n",
    "        # Create a comment's collection\n",
    "        collection_comments = chromadb_client.create_collection(name=\"comments_collection\",\n",
    "                                                              metadata={\"hnsw:space\": \"l2\"}, # Squared L2 norm(l2) is the default, inner product('ip') or cosine similarity('cosine')                                                              \n",
    "                                                              embedding_function=embeddings\n",
    "                                                              )        \n",
    "        \n",
    "        # Add data to collection\n",
    "        collection_comments.add(documents=documents,\n",
    "                                metadatas=metadatas,\n",
    "                                ids=ids\n",
    "                                )\n",
    "        print(\"Data uploaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to upload data: {e}\")\n",
    "\n",
    "upload_to_chromadb(documents, metadatas, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ollama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
