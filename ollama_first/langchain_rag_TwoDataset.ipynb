{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artefact II - RAG using Two Collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/thesis_GenAI/ollama_first/.env_rag/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/ubuntu/thesis_GenAI/ollama_first/.env_rag/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Python \n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ChromaDB\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "# LangChain \n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "\n",
    "# Directory path\n",
    "#PERSIST_DIRECTORY = \"C:\\\\Users\\\\eduar\\\\Documents\\\\Master_Thesis\\\\GenAI_Thesis_Beekeeper\\\\data\\\\vector_db\"\n",
    "PERSIST_DIRECTORY = \"C:\\\\Users\\\\eduar\\\\Documents\\\\Master_Thesis\\\\GenAI_Thesis_Beekeeper\\\\data\\\\datasets_db\"\n",
    "\n",
    "# Define the open-source embedding function ()\n",
    "embedding_func = SentenceTransformerEmbeddings(model_name=\"all-mpnet-base-v2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Importing Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stream_name</th>\n",
       "      <th>created_date</th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>like_count</th>\n",
       "      <th>report_count</th>\n",
       "      <th>username</th>\n",
       "      <th>author_user_id</th>\n",
       "      <th>author_position</th>\n",
       "      <th>author_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11882</th>\n",
       "      <td>Jobs</td>\n",
       "      <td>2023-12-29 21:10:33</td>\n",
       "      <td>7386024</td>\n",
       "      <td>6606515</td>\n",
       "      <td>Available</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Corbin_Kesner</td>\n",
       "      <td>8b12d0d2-9fb5-474a-a896-f1ce1c2197d9</td>\n",
       "      <td>Crew Member</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61912</th>\n",
       "      <td>Safety &amp; Operations</td>\n",
       "      <td>2023-03-06 21:28:14</td>\n",
       "      <td>6276963</td>\n",
       "      <td>5453365</td>\n",
       "      <td>Congratulations to the following:\\n\\n@Dominiqu...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>FlaggerForce</td>\n",
       "      <td>b701ab9f-563a-4425-a389-aff803a8da58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22170</th>\n",
       "      <td>Jobs</td>\n",
       "      <td>2023-10-20 17:03:45</td>\n",
       "      <td>7151430</td>\n",
       "      <td>6342159</td>\n",
       "      <td>Hey @Connard_Edlin I've put you on the availab...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>client_services_transition</td>\n",
       "      <td>f206abd1-e46c-4d35-be75-a3b937edf885</td>\n",
       "      <td>NaN</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               stream_name         created_date  post_id  comment_id  \\\n",
       "11882                 Jobs  2023-12-29 21:10:33  7386024     6606515   \n",
       "61912  Safety & Operations  2023-03-06 21:28:14  6276963     5453365   \n",
       "22170                 Jobs  2023-10-20 17:03:45  7151430     6342159   \n",
       "\n",
       "                                            comment_text  like_count  \\\n",
       "11882                                          Available           0   \n",
       "61912  Congratulations to the following:\\n\\n@Dominiqu...           4   \n",
       "22170  Hey @Connard_Edlin I've put you on the availab...           1   \n",
       "\n",
       "       report_count                    username  \\\n",
       "11882             0               Corbin_Kesner   \n",
       "61912             0                FlaggerForce   \n",
       "22170             0  client_services_transition   \n",
       "\n",
       "                             author_user_id author_position author_status  \n",
       "11882  8b12d0d2-9fb5-474a-a896-f1ce1c2197d9     Crew Member        active  \n",
       "61912  b701ab9f-563a-4425-a389-aff803a8da58             NaN        active  \n",
       "22170  f206abd1-e46c-4d35-be75-a3b937edf885             NaN        active  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import users file\n",
    "path = \"/home/ubuntu/thesis_GenAI/data/production_datasets/cleaned_datasets\"\n",
    "#path = \"C:\\\\Users\\\\eduar\\\\Documents\\\\Master_Thesis\\\\GenAI_Thesis_Beekeeper\\\\data\\\\production_datasets\\\\cleaned_datasets\"\n",
    "\n",
    "file_name = \"comments_cleaned.csv\"\n",
    "file_path = os.path.join(path, file_name)\n",
    "df_comments = pd.read_csv(file_path)\n",
    "\n",
    "# Create a sample of comments to test\n",
    "df_comments_to_test = df_comments.sample(250, random_state=123)\n",
    "df_comments_to_test.to_csv(os.path.join(path,\"comments_sample.csv\"), index=False)\n",
    "\n",
    "# Print a sample\n",
    "df_comments.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Importing Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stream_name</th>\n",
       "      <th>stream_id</th>\n",
       "      <th>post_id</th>\n",
       "      <th>action</th>\n",
       "      <th>created</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>like_count</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>mentions</th>\n",
       "      <th>username</th>\n",
       "      <th>author_user_id</th>\n",
       "      <th>author_position</th>\n",
       "      <th>author_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37439</th>\n",
       "      <td>Test Stream</td>\n",
       "      <td>6943</td>\n",
       "      <td>5219691</td>\n",
       "      <td>POSTED</td>\n",
       "      <td>2022-04-11 12:51:06</td>\n",
       "      <td>Basic Work Zone Training, Day 2, SPEED....</td>\n",
       "      <td>As part of an unscheduled visit to our King of...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Queteya_SandersCole,Latif_Miller,Steven_Jones,...</td>\n",
       "      <td>luke_lazar</td>\n",
       "      <td>7cac4e9f-323b-449c-b78a-3e51945df4a5</td>\n",
       "      <td>VP of Risk &amp; Safety</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22391</th>\n",
       "      <td>OSC, We Can Help</td>\n",
       "      <td>22708</td>\n",
       "      <td>6107804</td>\n",
       "      <td>POSTED</td>\n",
       "      <td>2022-12-24 19:38:22</td>\n",
       "      <td>I need help changing my direct deposit</td>\n",
       "      <td>I looked everywhere on the UKG app trying to f...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dylan_Dewitt</td>\n",
       "      <td>9e93b30b-157d-4762-a283-04ba11a3e712</td>\n",
       "      <td>Crew Member</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37440</th>\n",
       "      <td>Water Break</td>\n",
       "      <td>6787</td>\n",
       "      <td>5219641</td>\n",
       "      <td>POSTED</td>\n",
       "      <td>2022-04-11 12:40:05</td>\n",
       "      <td>Fresh week fresh site</td>\n",
       "      <td>Its my first day and i already love it @somewh...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Christopher_Schaffer</td>\n",
       "      <td>dbe4b413-342b-4103-970b-f6f398d01346</td>\n",
       "      <td>Crew Leader</td>\n",
       "      <td>suspended</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            stream_name  stream_id  post_id  action              created  \\\n",
       "37439      Test Stream        6943  5219691  POSTED  2022-04-11 12:51:06   \n",
       "22391  OSC, We Can Help      22708  6107804  POSTED  2022-12-24 19:38:22   \n",
       "37440       Water Break       6787  5219641  POSTED  2022-04-11 12:40:05   \n",
       "\n",
       "                                            title  \\\n",
       "37439  Basic Work Zone Training, Day 2, SPEED....   \n",
       "22391      I need help changing my direct deposit   \n",
       "37440                       Fresh week fresh site   \n",
       "\n",
       "                                                    text  like_count  \\\n",
       "37439  As part of an unscheduled visit to our King of...           0   \n",
       "22391  I looked everywhere on the UKG app trying to f...           0   \n",
       "37440  Its my first day and i already love it @somewh...           4   \n",
       "\n",
       "       comment_count                                           mentions  \\\n",
       "37439              0  Queteya_SandersCole,Latif_Miller,Steven_Jones,...   \n",
       "22391              2                                                NaN   \n",
       "37440              1                                                NaN   \n",
       "\n",
       "                   username                        author_user_id  \\\n",
       "37439            luke_lazar  7cac4e9f-323b-449c-b78a-3e51945df4a5   \n",
       "22391          Dylan_Dewitt  9e93b30b-157d-4762-a283-04ba11a3e712   \n",
       "37440  Christopher_Schaffer  dbe4b413-342b-4103-970b-f6f398d01346   \n",
       "\n",
       "           author_position author_status  \n",
       "37439  VP of Risk & Safety        active  \n",
       "22391          Crew Member        active  \n",
       "37440          Crew Leader     suspended  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import users file\n",
    "path = \"/home/ubuntu/thesis_GenAI/data/production_datasets/cleaned_datasets\"\n",
    "#path = \"C:\\\\Users\\\\eduar\\\\Documents\\\\Master_Thesis\\\\GenAI_Thesis_Beekeeper\\\\data\\\\production_datasets\\\\cleaned_datasets\"\n",
    "file_name = \"posts_cleaned.csv\"\n",
    "file_path = os.path.join(path, file_name)\n",
    "df_posts = pd.read_csv(file_path)\n",
    "\n",
    "# Delete column 'labels'\n",
    "df_posts = df_posts.drop(columns=['labels'])\n",
    "# Rename comment_count column\n",
    "df_posts.rename({'comment_countt': 'comment_count'}, axis=1, inplace=True)\n",
    "# Replace in column 'text' the value '\\u200d♀️' by ''\n",
    "df_posts['text'] = df_posts['text'].str.replace('\\u200d♀️', '')\n",
    "\n",
    "# Create a sample of 50,000 comments to test\n",
    "# set a seed\n",
    "\n",
    "df_post_to_test = df_posts.sample(200, random_state=123)\n",
    "df_post_to_test.to_csv(os.path.join(path,\"posts_sample.csv\"), index=False)\n",
    "\n",
    "# Print a sample\n",
    "df_posts.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Data for Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Ok',\n",
       " '@Waylon_Curtis',\n",
       " 'Wow.... you too',\n",
       " '**This order has been cancelled**',\n",
       " 'We can not control what other companies do. It is not our place. \\n    \\n    I even commented that it was a good video to remind ourselves that WE can and will do better based upon our training.',\n",
       " \"I'm available\",\n",
       " \"@Delano_Haines... It was great to see you today. I'm happy to hear that Seth and his crew is pleased with us. As for training  @Natisha_Nwankwo and @Jeffrey_Brodsky .. they make my job easy and fun. They are both very eager to learn everything. Btw, today I personally didn't set the cones. Jeff set the transition and tangent, and Natisha set the termination with a little bit of assistance. I'm very proud of both of them.  I'll keep on doing what I do best. \\nI appreciate the kind words.\",\n",
       " 'What is the scope of this job',\n",
       " 'Congratulations and welcome back!! \\n🎉👷🏼\\u200d♀️🛑🎉',\n",
       " '@Portia_Dougherty it’s for crew lead and up only']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import comment's sample file\n",
    "file_name = \"comments_sample.csv\"\n",
    "file_path = os.path.join(path, file_name)\n",
    "df_comments_to_test = pd.read_csv(file_path)\n",
    "\n",
    "# Function to prepare the commments data to be loaded to the database\n",
    "def prepare_comments_data(df):   \n",
    "    documents = []\n",
    "    metadatas = []\n",
    "    ids = []\n",
    "        \n",
    "    for idx, row in df.iterrows(): \n",
    "        documents.append(row.iloc[4])\n",
    "        metadatas.append({\n",
    "            'stream_name': row.iloc[0],\n",
    "            'created_date': row.iloc[1],\n",
    "            'post_id': row.iloc[2],\n",
    "            'comment_id': row.iloc[3],\n",
    "            'like_count': row.iloc[5],\n",
    "            'report_count': row.iloc[6],\n",
    "            'username': row.iloc[7],\n",
    "            'author_user_id': row.iloc[8],\n",
    "            'author_position': row.iloc[9],\n",
    "            'author_status': row.iloc[10]\n",
    "        })\n",
    "        ids.append(str(idx+1))       \n",
    "    \n",
    "    return documents, metadatas, ids\n",
    "\n",
    "documents_comments, metadatas_comments, ids_comments = prepare_comments_data(df_comments_to_test)\n",
    "\n",
    "print(type(documents_comments))\n",
    "documents_comments[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Ok', metadata={'stream_name': 'Jobs', 'created_date': '2022-04-02 13:36:11', 'post_id': 5195364, 'comment_id': 4179344, 'like_count': 1, 'report_count': 0, 'username': 'Christopher_Young', 'author_user_id': '940f777e-ebc8-4bae-b1c8-aecb92a62438', 'author_position': 'Crew Leader', 'author_status': 'suspended'}),\n",
       " Document(page_content='@Waylon_Curtis', metadata={'stream_name': 'Jobs', 'created_date': '2022-11-13 21:47:13', 'post_id': 5974128, 'comment_id': 5033739, 'like_count': 0, 'report_count': 0, 'username': 'John_Ware', 'author_user_id': 'e93ab132-8a53-4a66-89a6-b256e82b7956', 'author_position': 'Advanced Crew Leader', 'author_status': 'suspended'})]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split it into chunks\n",
    "text_splitter = CharacterTextSplitter(    \n",
    "    separator=\"\\n\\n\",\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=0,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,        \n",
    "    )\n",
    "\n",
    "docs_comments = text_splitter.create_documents(documents_comments,\n",
    "                                               metadatas=metadatas_comments\n",
    "                                                )\n",
    "docs_comments[:2]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stream_name          0\n",
      "stream_id            0\n",
      "post_id              0\n",
      "action               0\n",
      "created              0\n",
      "title               31\n",
      "text                 0\n",
      "like_count           0\n",
      "comment_count        0\n",
      "mentions           166\n",
      "username             0\n",
      "author_user_id       0\n",
      "author_position     39\n",
      "author_status        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Import post's sample file\n",
    "file_name = \"posts_sample.csv\"\n",
    "file_path = os.path.join(path, file_name)\n",
    "df_posts_to_test = pd.read_csv(file_path)\n",
    "# print(df_posts_to_test.isnull().sum())\n",
    "\n",
    "# Delete rows with NAN values in the column text\n",
    "df_posts_to_test.dropna(inplace=True, subset=['text','username'])\n",
    "# print()\n",
    "print(df_posts_to_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['I’m up now I’m available @client_services_am @weekend_dispatch',\n",
       " 'BEEN UNDER THE WEATHER FOR A FEW DAYS BUT I CAN’T COMPLAIN CAUSE I’M STILL LIVING & ABLE….LET’S MAKE TODAY BETTER THAN YESTERDAY',\n",
       " 'Client: Verizon - MD\\nDate: 1/19/2024\\nTime: ASAP\\nAddress:  Flagger Force\\nOrder: 574952\\nNotes:  Please comment if you are available, thank you!',\n",
       " 'Client: NPL - Washington, PA\\nDate: 12/13/22\\nAddress: 69 Market St Brownsville Pa \\nOrder# 536569\\nStart Time:  ASAP\\nNotes: Please comment below or call the OSC if you are available.',\n",
       " 'It’s suppose to storm tonight so I’m available @client_services_transition @client_services_pm @client_services_transition @client_services_pm',\n",
       " 'Order: 577546\\nClient: BGE Front Street\\nAddress: 1101 Russell Street, Baltimore\\nDate: 2/16/24\\nStart: 19:00\\n\\n\\nOrder: 577549\\nClient: BGE Piney Orchard\\nAddress: 730 New Waugh Chapel Road, Ondeton\\nDate: 2/16/24\\nStart: 19:00',\n",
       " 'Cl available in cpa but willing to travel',\n",
       " 'Pick Up: 220 8th Avenue NW, Glen Burnie, MD 21061\\nDrop Off: 6256 Shady Side Road , Shady Side MD, 20764\\n\\n\\nCrew Leads on site will take PLTs back when job is completed.',\n",
       " 'Client: Verizon - MD\\nDate: 8/11/22\\nAddress:  29321 Gaither Rd. Gaithersburg, MD\\nOrder #: 526933\\nStart time: ASAP\\nNotes: Please comment below or call the OSC if you are available, thank you! 🙂',\n",
       " 'Waiting to find out where the lines are down']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to prepare the posts data to be loaded to the database\n",
    "def prepare_posts_data(df):   \n",
    "    documents = []\n",
    "    metadatas = []\n",
    "    ids = []\n",
    "        \n",
    "    for idx, row in df.iterrows(): \n",
    "        documents.append(row.iloc[6])\n",
    "        metadatas.append({\n",
    "            'stream_name': row.iloc[0],\n",
    "            'stream_id': row.iloc[1],\n",
    "            'post_id': row.iloc[2],\n",
    "            'action': row.iloc[3],            \n",
    "            'created': row.iloc[4],\n",
    "            'title': row.iloc[5],            \n",
    "            'like_count': row.iloc[7],\n",
    "            'comment_count': row.iloc[8],\n",
    "            'mentions': row.iloc[9],\n",
    "            #'labels': row.iloc[10],\n",
    "            'username': row.iloc[10],\n",
    "            'author_user_id': row.iloc[11],\n",
    "            'author_position': row.iloc[12],\n",
    "            'author_status': row.iloc[13]\n",
    "        })\n",
    "        ids.append(str(idx+1))       \n",
    "    \n",
    "    return documents, metadatas, ids\n",
    "\n",
    "documents_posts, metadatas_posts, ids_posts = prepare_posts_data(df_posts_to_test)\n",
    "\n",
    "print(type(documents_posts))\n",
    "documents_posts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # find the elements of the list documents_posts which are not of string type\\nfor element in documents_posts:\\n    if not isinstance(element, str):\\n        print(documents_posts.index(element))\\n        \\n# Deleting the elements of the list with NaN values\\ndocuments_posts = [element for element in documents_posts if isinstance(element, str)] '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # find the elements of the list documents_posts which are not of string type\n",
    "for element in documents_posts:\n",
    "    if not isinstance(element, str):\n",
    "        print(documents_posts.index(element))\n",
    "        \n",
    "# Deleting the elements of the list with NaN values\n",
    "documents_posts = [element for element in documents_posts if isinstance(element, str)] \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='I’m up now I’m available @client_services_am @weekend_dispatch', metadata={'stream_name': 'Jobs', 'stream_id': 9254, 'post_id': 6988496, 'action': 'POSTED', 'created': '2023-09-04 08:26:06', 'title': nan, 'like_count': 4, 'comment_count': 0, 'mentions': 'client_services_am,weekend_dispatch', 'username': 'Latasha_Clayton', 'author_user_id': '6e89af7c-c527-493a-93f7-a8c0205c331d', 'author_position': 'Advanced Crew Leader', 'author_status': 'suspended'}),\n",
       " Document(page_content='BEEN UNDER THE WEATHER FOR A FEW DAYS BUT I CAN’T COMPLAIN CAUSE I’M STILL LIVING & ABLE….LET’S MAKE TODAY BETTER THAN YESTERDAY', metadata={'stream_name': 'Water Break', 'stream_id': 6787, 'post_id': 5066545, 'action': 'POSTED', 'created': '2022-02-21 14:38:06', 'title': nan, 'like_count': 8, 'comment_count': 6, 'mentions': nan, 'username': 'Dontavius_Smith', 'author_user_id': '93f404c0-922b-49f9-b1cb-ecdbc0703e37', 'author_position': 'Area Supervisor', 'author_status': 'active'})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text splitter\n",
    "\n",
    "# split it into chunks\n",
    "text_splitter = CharacterTextSplitter(    \n",
    "    separator=\"\\n\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=0,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,        \n",
    "    )\n",
    "\n",
    "docs_posts = text_splitter.create_documents(documents_posts, \n",
    "                                            metadatas=metadatas_posts\n",
    "                                            )\n",
    "docs_posts[:2]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create and add data to database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 First approach: Load data with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the best team u can have at flagger force\n"
     ]
    }
   ],
   "source": [
    "# First approach: Set the client with chromadb but load data with Chroma from LangChain\n",
    "\n",
    "\"\"\" import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "client_settings = chromadb.config.Settings(        \n",
    "    persist_directory=PERSIST_DIRECTORY,\n",
    "    anonymized_telemetry=False,\n",
    "    allow_reset=True\n",
    ")\n",
    "\n",
    "# save comments to disk\n",
    "db_comments = Chroma.from_documents(docs_comments,\n",
    "                           embedding_func,                           \n",
    "                           persist_directory=PERSIST_DIRECTORY)\n",
    "\n",
    "# Test the db\n",
    "query = \"FlaggerForce congratulations\"\n",
    "docs = db_comments.similarity_search(query)\n",
    "print(docs[0].page_content) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anyways, Flagger force has opened up my eyes to a whole new future and I can’t be more excited for the journey I have ahead of me. Knowing that working in SC will be a few week project, I can’t help but feel honored to be selected as one of the few to go down and represent FF in hopes to obtain more work in the area. WE GOTTA SHINE AS BRIGHT AS OUR PPE. 😂😂. \n",
      "\n",
      "shout out to @Danny_Rice and his team granted I can be a pain and run my mouth occasionally, y’all’s hard work doesn’t go unnoticed. I really do appreciate  the hard work and effort y’all put in. I look forward to making y’all proud. \n",
      "\n",
      "well if you made it this far, stay safe Ff family! \n",
      "\n",
      "@Keionna_Lee @Ayeisha_Forbes @Matthew_Geis @Kyle_Schall\n"
     ]
    }
   ],
   "source": [
    "# This is here just as documentation\n",
    "\n",
    "\"\"\" # save posts to disk\n",
    "db_posts = Chroma.from_documents(docs_posts,\n",
    "                           embedding_func,                           \n",
    "                           persist_directory=PERSIST_DIRECTORY)\n",
    "\n",
    "# Test the db\n",
    "query = \"FlaggerForce congratulations\"\n",
    "docs = db_posts.similarity_search(query)\n",
    "print(docs[0].page_content) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Second Approach: Load data with Chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/thesis_GenAI/ollama_first/.env_rag/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Add of existing embedding ID: 1\n",
      "Add of existing embedding ID: 2\n",
      "Add of existing embedding ID: 3\n",
      "Add of existing embedding ID: 4\n",
      "Add of existing embedding ID: 5\n",
      "Add of existing embedding ID: 6\n",
      "Add of existing embedding ID: 7\n",
      "Add of existing embedding ID: 8\n",
      "Add of existing embedding ID: 9\n",
      "Add of existing embedding ID: 10\n",
      "Add of existing embedding ID: 11\n",
      "Add of existing embedding ID: 12\n",
      "Add of existing embedding ID: 13\n",
      "Add of existing embedding ID: 14\n",
      "Add of existing embedding ID: 15\n",
      "Add of existing embedding ID: 16\n",
      "Add of existing embedding ID: 17\n",
      "Add of existing embedding ID: 18\n",
      "Add of existing embedding ID: 19\n",
      "Add of existing embedding ID: 20\n",
      "Add of existing embedding ID: 21\n",
      "Add of existing embedding ID: 22\n",
      "Add of existing embedding ID: 23\n",
      "Add of existing embedding ID: 24\n",
      "Add of existing embedding ID: 25\n",
      "Add of existing embedding ID: 26\n",
      "Add of existing embedding ID: 27\n",
      "Add of existing embedding ID: 28\n",
      "Add of existing embedding ID: 29\n",
      "Add of existing embedding ID: 30\n",
      "Add of existing embedding ID: 31\n",
      "Add of existing embedding ID: 32\n",
      "Add of existing embedding ID: 33\n",
      "Add of existing embedding ID: 34\n",
      "Add of existing embedding ID: 35\n",
      "Add of existing embedding ID: 36\n",
      "Add of existing embedding ID: 37\n",
      "Add of existing embedding ID: 38\n",
      "Add of existing embedding ID: 39\n",
      "Add of existing embedding ID: 40\n",
      "Add of existing embedding ID: 41\n",
      "Add of existing embedding ID: 42\n",
      "Add of existing embedding ID: 43\n",
      "Add of existing embedding ID: 44\n",
      "Add of existing embedding ID: 45\n",
      "Add of existing embedding ID: 46\n",
      "Add of existing embedding ID: 47\n",
      "Add of existing embedding ID: 48\n",
      "Add of existing embedding ID: 49\n",
      "Add of existing embedding ID: 50\n",
      "Add of existing embedding ID: 51\n",
      "Add of existing embedding ID: 52\n",
      "Add of existing embedding ID: 53\n",
      "Add of existing embedding ID: 54\n",
      "Add of existing embedding ID: 55\n",
      "Add of existing embedding ID: 56\n",
      "Add of existing embedding ID: 57\n",
      "Add of existing embedding ID: 58\n",
      "Add of existing embedding ID: 59\n",
      "Add of existing embedding ID: 60\n",
      "Add of existing embedding ID: 61\n",
      "Add of existing embedding ID: 62\n",
      "Add of existing embedding ID: 63\n",
      "Add of existing embedding ID: 64\n",
      "Add of existing embedding ID: 65\n",
      "Add of existing embedding ID: 66\n",
      "Add of existing embedding ID: 67\n",
      "Add of existing embedding ID: 68\n",
      "Add of existing embedding ID: 69\n",
      "Add of existing embedding ID: 70\n",
      "Add of existing embedding ID: 71\n",
      "Add of existing embedding ID: 72\n",
      "Add of existing embedding ID: 73\n",
      "Add of existing embedding ID: 74\n",
      "Add of existing embedding ID: 75\n",
      "Add of existing embedding ID: 76\n",
      "Add of existing embedding ID: 77\n",
      "Add of existing embedding ID: 78\n",
      "Add of existing embedding ID: 79\n",
      "Add of existing embedding ID: 80\n",
      "Add of existing embedding ID: 81\n",
      "Add of existing embedding ID: 82\n",
      "Add of existing embedding ID: 83\n",
      "Add of existing embedding ID: 84\n",
      "Add of existing embedding ID: 85\n",
      "Add of existing embedding ID: 86\n",
      "Add of existing embedding ID: 87\n",
      "Add of existing embedding ID: 88\n",
      "Add of existing embedding ID: 89\n",
      "Add of existing embedding ID: 90\n",
      "Add of existing embedding ID: 91\n",
      "Add of existing embedding ID: 92\n",
      "Add of existing embedding ID: 93\n",
      "Add of existing embedding ID: 94\n",
      "Add of existing embedding ID: 95\n",
      "Add of existing embedding ID: 96\n",
      "Add of existing embedding ID: 97\n",
      "Add of existing embedding ID: 98\n",
      "Add of existing embedding ID: 99\n",
      "Add of existing embedding ID: 100\n",
      "Add of existing embedding ID: 101\n",
      "Add of existing embedding ID: 102\n",
      "Add of existing embedding ID: 103\n",
      "Add of existing embedding ID: 104\n",
      "Add of existing embedding ID: 105\n",
      "Add of existing embedding ID: 106\n",
      "Add of existing embedding ID: 107\n",
      "Add of existing embedding ID: 108\n",
      "Add of existing embedding ID: 109\n",
      "Add of existing embedding ID: 110\n",
      "Add of existing embedding ID: 111\n",
      "Add of existing embedding ID: 112\n",
      "Add of existing embedding ID: 113\n",
      "Add of existing embedding ID: 114\n",
      "Add of existing embedding ID: 115\n",
      "Add of existing embedding ID: 116\n",
      "Add of existing embedding ID: 117\n",
      "Add of existing embedding ID: 118\n",
      "Add of existing embedding ID: 119\n",
      "Add of existing embedding ID: 120\n",
      "Add of existing embedding ID: 121\n",
      "Add of existing embedding ID: 122\n",
      "Add of existing embedding ID: 123\n",
      "Add of existing embedding ID: 124\n",
      "Add of existing embedding ID: 125\n",
      "Add of existing embedding ID: 126\n",
      "Add of existing embedding ID: 127\n",
      "Add of existing embedding ID: 128\n",
      "Add of existing embedding ID: 129\n",
      "Add of existing embedding ID: 130\n",
      "Add of existing embedding ID: 131\n",
      "Add of existing embedding ID: 132\n",
      "Add of existing embedding ID: 133\n",
      "Add of existing embedding ID: 134\n",
      "Add of existing embedding ID: 135\n",
      "Add of existing embedding ID: 136\n",
      "Add of existing embedding ID: 137\n",
      "Add of existing embedding ID: 138\n",
      "Add of existing embedding ID: 139\n",
      "Add of existing embedding ID: 140\n",
      "Add of existing embedding ID: 141\n",
      "Add of existing embedding ID: 142\n",
      "Add of existing embedding ID: 143\n",
      "Add of existing embedding ID: 144\n",
      "Add of existing embedding ID: 145\n",
      "Add of existing embedding ID: 146\n",
      "Add of existing embedding ID: 147\n",
      "Add of existing embedding ID: 148\n",
      "Add of existing embedding ID: 149\n",
      "Add of existing embedding ID: 150\n",
      "Add of existing embedding ID: 151\n",
      "Add of existing embedding ID: 152\n",
      "Add of existing embedding ID: 153\n",
      "Add of existing embedding ID: 154\n",
      "Add of existing embedding ID: 155\n",
      "Add of existing embedding ID: 156\n",
      "Add of existing embedding ID: 157\n",
      "Add of existing embedding ID: 158\n",
      "Add of existing embedding ID: 159\n",
      "Add of existing embedding ID: 160\n",
      "Add of existing embedding ID: 161\n",
      "Add of existing embedding ID: 162\n",
      "Add of existing embedding ID: 163\n",
      "Add of existing embedding ID: 164\n",
      "Add of existing embedding ID: 165\n",
      "Add of existing embedding ID: 166\n",
      "Add of existing embedding ID: 167\n",
      "Add of existing embedding ID: 168\n",
      "Add of existing embedding ID: 169\n",
      "Add of existing embedding ID: 170\n",
      "Add of existing embedding ID: 171\n",
      "Add of existing embedding ID: 172\n",
      "Add of existing embedding ID: 173\n",
      "Add of existing embedding ID: 174\n",
      "Add of existing embedding ID: 175\n",
      "Add of existing embedding ID: 176\n",
      "Add of existing embedding ID: 177\n",
      "Add of existing embedding ID: 178\n",
      "Add of existing embedding ID: 179\n",
      "Add of existing embedding ID: 180\n",
      "Add of existing embedding ID: 181\n",
      "Add of existing embedding ID: 182\n",
      "Add of existing embedding ID: 183\n",
      "Add of existing embedding ID: 184\n",
      "Add of existing embedding ID: 185\n",
      "Add of existing embedding ID: 186\n",
      "Add of existing embedding ID: 187\n",
      "Add of existing embedding ID: 188\n",
      "Add of existing embedding ID: 189\n",
      "Add of existing embedding ID: 190\n",
      "Add of existing embedding ID: 191\n",
      "Add of existing embedding ID: 192\n",
      "Add of existing embedding ID: 193\n",
      "Add of existing embedding ID: 194\n",
      "Add of existing embedding ID: 195\n",
      "Add of existing embedding ID: 196\n",
      "Add of existing embedding ID: 197\n",
      "Add of existing embedding ID: 198\n",
      "Add of existing embedding ID: 199\n",
      "Add of existing embedding ID: 200\n",
      "Add of existing embedding ID: 201\n",
      "Add of existing embedding ID: 202\n",
      "Add of existing embedding ID: 203\n",
      "Add of existing embedding ID: 204\n",
      "Add of existing embedding ID: 205\n",
      "Add of existing embedding ID: 206\n",
      "Add of existing embedding ID: 207\n",
      "Add of existing embedding ID: 208\n",
      "Add of existing embedding ID: 209\n",
      "Add of existing embedding ID: 210\n",
      "Add of existing embedding ID: 211\n",
      "Add of existing embedding ID: 212\n",
      "Add of existing embedding ID: 213\n",
      "Add of existing embedding ID: 214\n",
      "Add of existing embedding ID: 215\n",
      "Add of existing embedding ID: 216\n",
      "Add of existing embedding ID: 217\n",
      "Add of existing embedding ID: 218\n",
      "Add of existing embedding ID: 219\n",
      "Add of existing embedding ID: 220\n",
      "Add of existing embedding ID: 221\n",
      "Add of existing embedding ID: 222\n",
      "Add of existing embedding ID: 223\n",
      "Add of existing embedding ID: 224\n",
      "Add of existing embedding ID: 225\n",
      "Add of existing embedding ID: 226\n",
      "Add of existing embedding ID: 227\n",
      "Add of existing embedding ID: 228\n",
      "Add of existing embedding ID: 229\n",
      "Add of existing embedding ID: 230\n",
      "Add of existing embedding ID: 231\n",
      "Add of existing embedding ID: 232\n",
      "Add of existing embedding ID: 233\n",
      "Add of existing embedding ID: 234\n",
      "Add of existing embedding ID: 235\n",
      "Add of existing embedding ID: 236\n",
      "Add of existing embedding ID: 237\n",
      "Add of existing embedding ID: 238\n",
      "Add of existing embedding ID: 239\n",
      "Add of existing embedding ID: 240\n",
      "Add of existing embedding ID: 241\n",
      "Add of existing embedding ID: 242\n",
      "Add of existing embedding ID: 243\n",
      "Add of existing embedding ID: 244\n",
      "Add of existing embedding ID: 245\n",
      "Add of existing embedding ID: 246\n",
      "Add of existing embedding ID: 247\n",
      "Add of existing embedding ID: 248\n",
      "Add of existing embedding ID: 249\n",
      "Add of existing embedding ID: 250\n",
      "Insert of existing embedding ID: 1\n",
      "Insert of existing embedding ID: 2\n",
      "Insert of existing embedding ID: 3\n",
      "Insert of existing embedding ID: 4\n",
      "Insert of existing embedding ID: 5\n",
      "Insert of existing embedding ID: 6\n",
      "Insert of existing embedding ID: 7\n",
      "Insert of existing embedding ID: 8\n",
      "Insert of existing embedding ID: 9\n",
      "Insert of existing embedding ID: 10\n",
      "Insert of existing embedding ID: 11\n",
      "Insert of existing embedding ID: 12\n",
      "Insert of existing embedding ID: 13\n",
      "Insert of existing embedding ID: 14\n",
      "Insert of existing embedding ID: 15\n",
      "Insert of existing embedding ID: 16\n",
      "Insert of existing embedding ID: 17\n",
      "Insert of existing embedding ID: 18\n",
      "Insert of existing embedding ID: 19\n",
      "Insert of existing embedding ID: 20\n",
      "Insert of existing embedding ID: 21\n",
      "Insert of existing embedding ID: 22\n",
      "Insert of existing embedding ID: 23\n",
      "Insert of existing embedding ID: 24\n",
      "Insert of existing embedding ID: 25\n",
      "Insert of existing embedding ID: 26\n",
      "Insert of existing embedding ID: 27\n",
      "Insert of existing embedding ID: 28\n",
      "Insert of existing embedding ID: 29\n",
      "Insert of existing embedding ID: 30\n",
      "Insert of existing embedding ID: 31\n",
      "Insert of existing embedding ID: 32\n",
      "Insert of existing embedding ID: 33\n",
      "Insert of existing embedding ID: 34\n",
      "Insert of existing embedding ID: 35\n",
      "Insert of existing embedding ID: 36\n",
      "Insert of existing embedding ID: 37\n",
      "Insert of existing embedding ID: 38\n",
      "Insert of existing embedding ID: 39\n",
      "Insert of existing embedding ID: 40\n",
      "Insert of existing embedding ID: 41\n",
      "Insert of existing embedding ID: 42\n",
      "Insert of existing embedding ID: 43\n",
      "Insert of existing embedding ID: 44\n",
      "Insert of existing embedding ID: 45\n",
      "Insert of existing embedding ID: 46\n",
      "Insert of existing embedding ID: 47\n",
      "Insert of existing embedding ID: 48\n",
      "Insert of existing embedding ID: 49\n",
      "Insert of existing embedding ID: 50\n",
      "Insert of existing embedding ID: 51\n",
      "Insert of existing embedding ID: 52\n",
      "Insert of existing embedding ID: 53\n",
      "Insert of existing embedding ID: 54\n",
      "Insert of existing embedding ID: 55\n",
      "Insert of existing embedding ID: 56\n",
      "Insert of existing embedding ID: 57\n",
      "Insert of existing embedding ID: 58\n",
      "Insert of existing embedding ID: 59\n",
      "Insert of existing embedding ID: 60\n",
      "Insert of existing embedding ID: 61\n",
      "Insert of existing embedding ID: 62\n",
      "Insert of existing embedding ID: 63\n",
      "Insert of existing embedding ID: 64\n",
      "Insert of existing embedding ID: 65\n",
      "Insert of existing embedding ID: 66\n",
      "Insert of existing embedding ID: 67\n",
      "Insert of existing embedding ID: 68\n",
      "Insert of existing embedding ID: 69\n",
      "Insert of existing embedding ID: 70\n",
      "Insert of existing embedding ID: 71\n",
      "Insert of existing embedding ID: 72\n",
      "Insert of existing embedding ID: 73\n",
      "Insert of existing embedding ID: 74\n",
      "Insert of existing embedding ID: 75\n",
      "Insert of existing embedding ID: 76\n",
      "Insert of existing embedding ID: 77\n",
      "Insert of existing embedding ID: 78\n",
      "Insert of existing embedding ID: 79\n",
      "Insert of existing embedding ID: 80\n",
      "Insert of existing embedding ID: 81\n",
      "Insert of existing embedding ID: 82\n",
      "Insert of existing embedding ID: 83\n",
      "Insert of existing embedding ID: 84\n",
      "Insert of existing embedding ID: 85\n",
      "Insert of existing embedding ID: 86\n",
      "Insert of existing embedding ID: 87\n",
      "Insert of existing embedding ID: 88\n",
      "Insert of existing embedding ID: 89\n",
      "Insert of existing embedding ID: 90\n",
      "Insert of existing embedding ID: 91\n",
      "Insert of existing embedding ID: 92\n",
      "Insert of existing embedding ID: 93\n",
      "Insert of existing embedding ID: 94\n",
      "Insert of existing embedding ID: 95\n",
      "Insert of existing embedding ID: 96\n",
      "Insert of existing embedding ID: 97\n",
      "Insert of existing embedding ID: 98\n",
      "Insert of existing embedding ID: 99\n",
      "Insert of existing embedding ID: 100\n",
      "Insert of existing embedding ID: 101\n",
      "Insert of existing embedding ID: 102\n",
      "Insert of existing embedding ID: 103\n",
      "Insert of existing embedding ID: 104\n",
      "Insert of existing embedding ID: 105\n",
      "Insert of existing embedding ID: 106\n",
      "Insert of existing embedding ID: 107\n",
      "Insert of existing embedding ID: 108\n",
      "Insert of existing embedding ID: 109\n",
      "Insert of existing embedding ID: 110\n",
      "Insert of existing embedding ID: 111\n",
      "Insert of existing embedding ID: 112\n",
      "Insert of existing embedding ID: 113\n",
      "Insert of existing embedding ID: 114\n",
      "Insert of existing embedding ID: 115\n",
      "Insert of existing embedding ID: 116\n",
      "Insert of existing embedding ID: 117\n",
      "Insert of existing embedding ID: 118\n",
      "Insert of existing embedding ID: 119\n",
      "Insert of existing embedding ID: 120\n",
      "Insert of existing embedding ID: 121\n",
      "Insert of existing embedding ID: 122\n",
      "Insert of existing embedding ID: 123\n",
      "Insert of existing embedding ID: 124\n",
      "Insert of existing embedding ID: 125\n",
      "Insert of existing embedding ID: 126\n",
      "Insert of existing embedding ID: 127\n",
      "Insert of existing embedding ID: 128\n",
      "Insert of existing embedding ID: 129\n",
      "Insert of existing embedding ID: 130\n",
      "Insert of existing embedding ID: 131\n",
      "Insert of existing embedding ID: 132\n",
      "Insert of existing embedding ID: 133\n",
      "Insert of existing embedding ID: 134\n",
      "Insert of existing embedding ID: 135\n",
      "Insert of existing embedding ID: 136\n",
      "Insert of existing embedding ID: 137\n",
      "Insert of existing embedding ID: 138\n",
      "Insert of existing embedding ID: 139\n",
      "Insert of existing embedding ID: 140\n",
      "Insert of existing embedding ID: 141\n",
      "Insert of existing embedding ID: 142\n",
      "Insert of existing embedding ID: 143\n",
      "Insert of existing embedding ID: 144\n",
      "Insert of existing embedding ID: 145\n",
      "Insert of existing embedding ID: 146\n",
      "Insert of existing embedding ID: 147\n",
      "Insert of existing embedding ID: 148\n",
      "Insert of existing embedding ID: 149\n",
      "Insert of existing embedding ID: 150\n",
      "Insert of existing embedding ID: 151\n",
      "Insert of existing embedding ID: 152\n",
      "Insert of existing embedding ID: 153\n",
      "Insert of existing embedding ID: 154\n",
      "Insert of existing embedding ID: 155\n",
      "Insert of existing embedding ID: 156\n",
      "Insert of existing embedding ID: 157\n",
      "Insert of existing embedding ID: 158\n",
      "Insert of existing embedding ID: 159\n",
      "Insert of existing embedding ID: 160\n",
      "Insert of existing embedding ID: 161\n",
      "Insert of existing embedding ID: 162\n",
      "Insert of existing embedding ID: 163\n",
      "Insert of existing embedding ID: 164\n",
      "Insert of existing embedding ID: 165\n",
      "Insert of existing embedding ID: 166\n",
      "Insert of existing embedding ID: 167\n",
      "Insert of existing embedding ID: 168\n",
      "Insert of existing embedding ID: 169\n",
      "Insert of existing embedding ID: 170\n",
      "Insert of existing embedding ID: 171\n",
      "Insert of existing embedding ID: 172\n",
      "Insert of existing embedding ID: 173\n",
      "Insert of existing embedding ID: 174\n",
      "Insert of existing embedding ID: 175\n",
      "Insert of existing embedding ID: 176\n",
      "Insert of existing embedding ID: 177\n",
      "Insert of existing embedding ID: 178\n",
      "Insert of existing embedding ID: 179\n",
      "Insert of existing embedding ID: 180\n",
      "Insert of existing embedding ID: 181\n",
      "Insert of existing embedding ID: 182\n",
      "Insert of existing embedding ID: 183\n",
      "Insert of existing embedding ID: 184\n",
      "Insert of existing embedding ID: 185\n",
      "Insert of existing embedding ID: 186\n",
      "Insert of existing embedding ID: 187\n",
      "Insert of existing embedding ID: 188\n",
      "Insert of existing embedding ID: 189\n",
      "Insert of existing embedding ID: 190\n",
      "Insert of existing embedding ID: 191\n",
      "Insert of existing embedding ID: 192\n",
      "Insert of existing embedding ID: 193\n",
      "Insert of existing embedding ID: 194\n",
      "Insert of existing embedding ID: 195\n",
      "Insert of existing embedding ID: 196\n",
      "Insert of existing embedding ID: 197\n",
      "Insert of existing embedding ID: 198\n",
      "Insert of existing embedding ID: 199\n",
      "Insert of existing embedding ID: 200\n",
      "Insert of existing embedding ID: 201\n",
      "Insert of existing embedding ID: 202\n",
      "Insert of existing embedding ID: 203\n",
      "Insert of existing embedding ID: 204\n",
      "Insert of existing embedding ID: 205\n",
      "Insert of existing embedding ID: 206\n",
      "Insert of existing embedding ID: 207\n",
      "Insert of existing embedding ID: 208\n",
      "Insert of existing embedding ID: 209\n",
      "Insert of existing embedding ID: 210\n",
      "Insert of existing embedding ID: 211\n",
      "Insert of existing embedding ID: 212\n",
      "Insert of existing embedding ID: 213\n",
      "Insert of existing embedding ID: 214\n",
      "Insert of existing embedding ID: 215\n",
      "Insert of existing embedding ID: 216\n",
      "Insert of existing embedding ID: 217\n",
      "Insert of existing embedding ID: 218\n",
      "Insert of existing embedding ID: 219\n",
      "Insert of existing embedding ID: 220\n",
      "Insert of existing embedding ID: 221\n",
      "Insert of existing embedding ID: 222\n",
      "Insert of existing embedding ID: 223\n",
      "Insert of existing embedding ID: 224\n",
      "Insert of existing embedding ID: 225\n",
      "Insert of existing embedding ID: 226\n",
      "Insert of existing embedding ID: 227\n",
      "Insert of existing embedding ID: 228\n",
      "Insert of existing embedding ID: 229\n",
      "Insert of existing embedding ID: 230\n",
      "Insert of existing embedding ID: 231\n",
      "Insert of existing embedding ID: 232\n",
      "Insert of existing embedding ID: 233\n",
      "Insert of existing embedding ID: 234\n",
      "Insert of existing embedding ID: 235\n",
      "Insert of existing embedding ID: 236\n",
      "Insert of existing embedding ID: 237\n",
      "Insert of existing embedding ID: 238\n",
      "Insert of existing embedding ID: 239\n",
      "Insert of existing embedding ID: 240\n",
      "Insert of existing embedding ID: 241\n",
      "Insert of existing embedding ID: 242\n",
      "Insert of existing embedding ID: 243\n",
      "Insert of existing embedding ID: 244\n",
      "Insert of existing embedding ID: 245\n",
      "Insert of existing embedding ID: 246\n",
      "Insert of existing embedding ID: 247\n",
      "Insert of existing embedding ID: 248\n",
      "Insert of existing embedding ID: 249\n",
      "Insert of existing embedding ID: 250\n",
      "Add of existing embedding ID: 1\n",
      "Add of existing embedding ID: 2\n",
      "Add of existing embedding ID: 3\n",
      "Add of existing embedding ID: 4\n",
      "Add of existing embedding ID: 5\n",
      "Add of existing embedding ID: 6\n",
      "Add of existing embedding ID: 7\n",
      "Add of existing embedding ID: 8\n",
      "Add of existing embedding ID: 9\n",
      "Add of existing embedding ID: 10\n",
      "Add of existing embedding ID: 11\n",
      "Add of existing embedding ID: 12\n",
      "Add of existing embedding ID: 13\n",
      "Add of existing embedding ID: 14\n",
      "Add of existing embedding ID: 15\n",
      "Add of existing embedding ID: 16\n",
      "Add of existing embedding ID: 17\n",
      "Add of existing embedding ID: 18\n",
      "Add of existing embedding ID: 19\n",
      "Add of existing embedding ID: 20\n",
      "Add of existing embedding ID: 21\n",
      "Add of existing embedding ID: 22\n",
      "Add of existing embedding ID: 23\n",
      "Add of existing embedding ID: 24\n",
      "Add of existing embedding ID: 25\n",
      "Add of existing embedding ID: 26\n",
      "Add of existing embedding ID: 27\n",
      "Add of existing embedding ID: 28\n",
      "Add of existing embedding ID: 29\n",
      "Add of existing embedding ID: 30\n",
      "Add of existing embedding ID: 31\n",
      "Add of existing embedding ID: 32\n",
      "Add of existing embedding ID: 33\n",
      "Add of existing embedding ID: 34\n",
      "Add of existing embedding ID: 35\n",
      "Add of existing embedding ID: 36\n",
      "Add of existing embedding ID: 37\n",
      "Add of existing embedding ID: 38\n",
      "Add of existing embedding ID: 39\n",
      "Add of existing embedding ID: 40\n",
      "Add of existing embedding ID: 41\n",
      "Add of existing embedding ID: 42\n",
      "Add of existing embedding ID: 43\n",
      "Add of existing embedding ID: 44\n",
      "Add of existing embedding ID: 45\n",
      "Add of existing embedding ID: 46\n",
      "Add of existing embedding ID: 47\n",
      "Add of existing embedding ID: 48\n",
      "Add of existing embedding ID: 49\n",
      "Add of existing embedding ID: 50\n",
      "Add of existing embedding ID: 51\n",
      "Add of existing embedding ID: 52\n",
      "Add of existing embedding ID: 53\n",
      "Add of existing embedding ID: 54\n",
      "Add of existing embedding ID: 55\n",
      "Add of existing embedding ID: 56\n",
      "Add of existing embedding ID: 57\n",
      "Add of existing embedding ID: 58\n",
      "Add of existing embedding ID: 59\n",
      "Add of existing embedding ID: 60\n",
      "Add of existing embedding ID: 61\n",
      "Add of existing embedding ID: 62\n",
      "Add of existing embedding ID: 63\n",
      "Add of existing embedding ID: 64\n",
      "Add of existing embedding ID: 65\n",
      "Add of existing embedding ID: 66\n",
      "Add of existing embedding ID: 67\n",
      "Add of existing embedding ID: 68\n",
      "Add of existing embedding ID: 69\n",
      "Add of existing embedding ID: 70\n",
      "Add of existing embedding ID: 71\n",
      "Add of existing embedding ID: 72\n",
      "Add of existing embedding ID: 73\n",
      "Add of existing embedding ID: 74\n",
      "Add of existing embedding ID: 75\n",
      "Add of existing embedding ID: 76\n",
      "Add of existing embedding ID: 77\n",
      "Add of existing embedding ID: 78\n",
      "Add of existing embedding ID: 79\n",
      "Add of existing embedding ID: 80\n",
      "Add of existing embedding ID: 81\n",
      "Add of existing embedding ID: 82\n",
      "Add of existing embedding ID: 83\n",
      "Add of existing embedding ID: 84\n",
      "Add of existing embedding ID: 85\n",
      "Add of existing embedding ID: 86\n",
      "Add of existing embedding ID: 87\n",
      "Add of existing embedding ID: 88\n",
      "Add of existing embedding ID: 89\n",
      "Add of existing embedding ID: 90\n",
      "Add of existing embedding ID: 91\n",
      "Add of existing embedding ID: 92\n",
      "Add of existing embedding ID: 93\n",
      "Add of existing embedding ID: 94\n",
      "Add of existing embedding ID: 95\n",
      "Add of existing embedding ID: 96\n",
      "Add of existing embedding ID: 97\n",
      "Add of existing embedding ID: 98\n",
      "Add of existing embedding ID: 99\n",
      "Add of existing embedding ID: 100\n",
      "Add of existing embedding ID: 101\n",
      "Add of existing embedding ID: 102\n",
      "Add of existing embedding ID: 103\n",
      "Add of existing embedding ID: 104\n",
      "Add of existing embedding ID: 105\n",
      "Add of existing embedding ID: 106\n",
      "Add of existing embedding ID: 107\n",
      "Add of existing embedding ID: 108\n",
      "Add of existing embedding ID: 109\n",
      "Add of existing embedding ID: 110\n",
      "Add of existing embedding ID: 111\n",
      "Add of existing embedding ID: 112\n",
      "Add of existing embedding ID: 113\n",
      "Add of existing embedding ID: 114\n",
      "Add of existing embedding ID: 115\n",
      "Add of existing embedding ID: 116\n",
      "Add of existing embedding ID: 117\n",
      "Add of existing embedding ID: 118\n",
      "Add of existing embedding ID: 119\n",
      "Add of existing embedding ID: 120\n",
      "Add of existing embedding ID: 121\n",
      "Add of existing embedding ID: 122\n",
      "Add of existing embedding ID: 123\n",
      "Add of existing embedding ID: 124\n",
      "Add of existing embedding ID: 125\n",
      "Add of existing embedding ID: 126\n",
      "Add of existing embedding ID: 127\n",
      "Add of existing embedding ID: 128\n",
      "Add of existing embedding ID: 129\n",
      "Add of existing embedding ID: 130\n",
      "Add of existing embedding ID: 131\n",
      "Add of existing embedding ID: 132\n",
      "Add of existing embedding ID: 133\n",
      "Add of existing embedding ID: 134\n",
      "Add of existing embedding ID: 135\n",
      "Add of existing embedding ID: 136\n",
      "Add of existing embedding ID: 137\n",
      "Add of existing embedding ID: 138\n",
      "Add of existing embedding ID: 139\n",
      "Add of existing embedding ID: 140\n",
      "Add of existing embedding ID: 141\n",
      "Add of existing embedding ID: 142\n",
      "Add of existing embedding ID: 143\n",
      "Add of existing embedding ID: 144\n",
      "Add of existing embedding ID: 145\n",
      "Add of existing embedding ID: 146\n",
      "Add of existing embedding ID: 147\n",
      "Add of existing embedding ID: 148\n",
      "Add of existing embedding ID: 149\n",
      "Add of existing embedding ID: 150\n",
      "Add of existing embedding ID: 151\n",
      "Add of existing embedding ID: 152\n",
      "Add of existing embedding ID: 153\n",
      "Add of existing embedding ID: 154\n",
      "Add of existing embedding ID: 155\n",
      "Add of existing embedding ID: 156\n",
      "Add of existing embedding ID: 157\n",
      "Add of existing embedding ID: 158\n",
      "Add of existing embedding ID: 159\n",
      "Add of existing embedding ID: 160\n",
      "Add of existing embedding ID: 161\n",
      "Add of existing embedding ID: 162\n",
      "Add of existing embedding ID: 163\n",
      "Add of existing embedding ID: 164\n",
      "Add of existing embedding ID: 165\n",
      "Add of existing embedding ID: 166\n",
      "Add of existing embedding ID: 167\n",
      "Add of existing embedding ID: 168\n",
      "Add of existing embedding ID: 169\n",
      "Add of existing embedding ID: 170\n",
      "Add of existing embedding ID: 171\n",
      "Add of existing embedding ID: 172\n",
      "Add of existing embedding ID: 173\n",
      "Add of existing embedding ID: 174\n",
      "Add of existing embedding ID: 175\n",
      "Add of existing embedding ID: 176\n",
      "Add of existing embedding ID: 177\n",
      "Add of existing embedding ID: 178\n",
      "Add of existing embedding ID: 179\n",
      "Add of existing embedding ID: 180\n",
      "Add of existing embedding ID: 181\n",
      "Add of existing embedding ID: 182\n",
      "Add of existing embedding ID: 183\n",
      "Add of existing embedding ID: 184\n",
      "Add of existing embedding ID: 185\n",
      "Add of existing embedding ID: 186\n",
      "Add of existing embedding ID: 187\n",
      "Add of existing embedding ID: 188\n",
      "Add of existing embedding ID: 189\n",
      "Add of existing embedding ID: 190\n",
      "Add of existing embedding ID: 191\n",
      "Add of existing embedding ID: 192\n",
      "Add of existing embedding ID: 193\n",
      "Add of existing embedding ID: 194\n",
      "Add of existing embedding ID: 195\n",
      "Add of existing embedding ID: 196\n",
      "Add of existing embedding ID: 197\n",
      "Add of existing embedding ID: 198\n",
      "Add of existing embedding ID: 199\n",
      "Add of existing embedding ID: 200\n",
      "Add of existing embedding ID: 201\n",
      "Add of existing embedding ID: 202\n",
      "Add of existing embedding ID: 203\n",
      "Add of existing embedding ID: 204\n",
      "Add of existing embedding ID: 205\n",
      "Add of existing embedding ID: 206\n",
      "Add of existing embedding ID: 207\n",
      "Add of existing embedding ID: 208\n",
      "Add of existing embedding ID: 209\n",
      "Add of existing embedding ID: 210\n",
      "Add of existing embedding ID: 211\n",
      "Add of existing embedding ID: 212\n",
      "Add of existing embedding ID: 213\n",
      "Add of existing embedding ID: 214\n",
      "Add of existing embedding ID: 215\n",
      "Add of existing embedding ID: 216\n",
      "Add of existing embedding ID: 217\n",
      "Add of existing embedding ID: 218\n",
      "Add of existing embedding ID: 219\n",
      "Add of existing embedding ID: 220\n",
      "Add of existing embedding ID: 221\n",
      "Add of existing embedding ID: 222\n",
      "Add of existing embedding ID: 223\n",
      "Add of existing embedding ID: 224\n",
      "Add of existing embedding ID: 225\n",
      "Add of existing embedding ID: 226\n",
      "Add of existing embedding ID: 227\n",
      "Add of existing embedding ID: 228\n",
      "Add of existing embedding ID: 229\n",
      "Add of existing embedding ID: 230\n",
      "Add of existing embedding ID: 231\n",
      "Add of existing embedding ID: 232\n",
      "Add of existing embedding ID: 233\n",
      "Add of existing embedding ID: 234\n",
      "Add of existing embedding ID: 235\n",
      "Add of existing embedding ID: 236\n",
      "Add of existing embedding ID: 237\n",
      "Add of existing embedding ID: 238\n",
      "Add of existing embedding ID: 239\n",
      "Add of existing embedding ID: 240\n",
      "Add of existing embedding ID: 241\n",
      "Add of existing embedding ID: 242\n",
      "Add of existing embedding ID: 243\n",
      "Add of existing embedding ID: 244\n",
      "Add of existing embedding ID: 245\n",
      "Add of existing embedding ID: 246\n",
      "Add of existing embedding ID: 247\n",
      "Add of existing embedding ID: 248\n",
      "Add of existing embedding ID: 249\n",
      "Add of existing embedding ID: 250\n"
     ]
    }
   ],
   "source": [
    "# Create db and comment's collection\n",
    "#PERSIST_DIRECTORY = \"C:\\\\Users\\\\eduar\\\\Documents\\\\Master_Thesis\\\\GenAI_Thesis_Beekeeper\\\\data\\\\vector_db\"\n",
    "PERSIST_DIRECTORY = \"/home/ubuntu/thesis_GenAI/data/vector_db\"\n",
    "\n",
    "# Initialize the database\n",
    "vectordb_2datasets = chromadb.PersistentClient(path=PERSIST_DIRECTORY, \n",
    "                                               settings=Settings(allow_reset=True),\n",
    "                                                                                                              \n",
    "                                                                 )\n",
    "# Define the open-source embedding function ()\n",
    "#embedding_func = SentenceTransformerEmbeddings(model_name=\"all-mpnet-base-v2\")\n",
    "embedding_func = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Create a collection for the comments\n",
    "collection_comments = vectordb_2datasets.get_or_create_collection(name=\"collection_comments\",\n",
    "                                                                  #embedding_function=embedding_func\n",
    "                                                                  )\n",
    "collection_comments.add(documents=documents_comments,\n",
    "                        metadatas=metadatas_comments,\n",
    "                        ids=ids_comments\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ok',\n",
       " '@Waylon_Curtis',\n",
       " 'Wow.... you too',\n",
       " '**This order has been cancelled**',\n",
       " 'We can not control what other companies do. It is not our place. \\n    \\n    I even commented that it was a good video to remind ourselves that WE can and will do better based upon our training.',\n",
       " \"I'm available\",\n",
       " \"@Delano_Haines... It was great to see you today. I'm happy to hear that Seth and his crew is pleased with us. As for training  @Natisha_Nwankwo and @Jeffrey_Brodsky .. they make my job easy and fun. They are both very eager to learn everything. Btw, today I personally didn't set the cones. Jeff set the transition and tangent, and Natisha set the termination with a little bit of assistance. I'm very proud of both of them.  I'll keep on doing what I do best. \\nI appreciate the kind words.\",\n",
       " 'What is the scope of this job',\n",
       " 'Congratulations and welcome back!! \\n🎉👷🏼\\u200d♀️🛑🎉',\n",
       " '@Portia_Dougherty it’s for crew lead and up only']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns a list of the first 10 items in the collection\n",
    "collection_comments.peek()['documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: 1\n",
      "Add of existing embedding ID: 2\n",
      "Add of existing embedding ID: 3\n",
      "Add of existing embedding ID: 4\n",
      "Add of existing embedding ID: 5\n",
      "Add of existing embedding ID: 6\n",
      "Add of existing embedding ID: 7\n",
      "Add of existing embedding ID: 8\n",
      "Add of existing embedding ID: 9\n",
      "Add of existing embedding ID: 10\n",
      "Add of existing embedding ID: 11\n",
      "Add of existing embedding ID: 12\n",
      "Add of existing embedding ID: 13\n",
      "Add of existing embedding ID: 14\n",
      "Add of existing embedding ID: 15\n",
      "Add of existing embedding ID: 16\n",
      "Add of existing embedding ID: 17\n",
      "Add of existing embedding ID: 18\n",
      "Add of existing embedding ID: 19\n",
      "Add of existing embedding ID: 20\n",
      "Add of existing embedding ID: 21\n",
      "Add of existing embedding ID: 22\n",
      "Add of existing embedding ID: 23\n",
      "Add of existing embedding ID: 24\n",
      "Add of existing embedding ID: 25\n",
      "Add of existing embedding ID: 26\n",
      "Add of existing embedding ID: 27\n",
      "Add of existing embedding ID: 28\n",
      "Add of existing embedding ID: 29\n",
      "Add of existing embedding ID: 30\n",
      "Add of existing embedding ID: 31\n",
      "Add of existing embedding ID: 32\n",
      "Add of existing embedding ID: 34\n",
      "Add of existing embedding ID: 35\n",
      "Add of existing embedding ID: 36\n",
      "Add of existing embedding ID: 37\n",
      "Add of existing embedding ID: 38\n",
      "Add of existing embedding ID: 39\n",
      "Add of existing embedding ID: 40\n",
      "Add of existing embedding ID: 41\n",
      "Add of existing embedding ID: 42\n",
      "Add of existing embedding ID: 43\n",
      "Add of existing embedding ID: 44\n",
      "Add of existing embedding ID: 45\n",
      "Add of existing embedding ID: 46\n",
      "Add of existing embedding ID: 47\n",
      "Add of existing embedding ID: 48\n",
      "Add of existing embedding ID: 49\n",
      "Add of existing embedding ID: 50\n",
      "Add of existing embedding ID: 51\n",
      "Add of existing embedding ID: 52\n",
      "Add of existing embedding ID: 53\n",
      "Add of existing embedding ID: 54\n",
      "Add of existing embedding ID: 55\n",
      "Add of existing embedding ID: 57\n",
      "Add of existing embedding ID: 58\n",
      "Add of existing embedding ID: 59\n",
      "Add of existing embedding ID: 60\n",
      "Add of existing embedding ID: 61\n",
      "Add of existing embedding ID: 62\n",
      "Add of existing embedding ID: 63\n",
      "Add of existing embedding ID: 64\n",
      "Add of existing embedding ID: 65\n",
      "Add of existing embedding ID: 66\n",
      "Add of existing embedding ID: 67\n",
      "Add of existing embedding ID: 68\n",
      "Add of existing embedding ID: 69\n",
      "Add of existing embedding ID: 71\n",
      "Add of existing embedding ID: 72\n",
      "Add of existing embedding ID: 73\n",
      "Add of existing embedding ID: 74\n",
      "Add of existing embedding ID: 75\n",
      "Add of existing embedding ID: 76\n",
      "Add of existing embedding ID: 77\n",
      "Add of existing embedding ID: 78\n",
      "Add of existing embedding ID: 79\n",
      "Add of existing embedding ID: 80\n",
      "Add of existing embedding ID: 81\n",
      "Add of existing embedding ID: 82\n",
      "Add of existing embedding ID: 83\n",
      "Add of existing embedding ID: 84\n",
      "Add of existing embedding ID: 85\n",
      "Add of existing embedding ID: 86\n",
      "Add of existing embedding ID: 87\n",
      "Add of existing embedding ID: 88\n",
      "Add of existing embedding ID: 89\n",
      "Add of existing embedding ID: 90\n",
      "Add of existing embedding ID: 91\n",
      "Add of existing embedding ID: 92\n",
      "Add of existing embedding ID: 93\n",
      "Add of existing embedding ID: 94\n",
      "Add of existing embedding ID: 95\n",
      "Add of existing embedding ID: 96\n",
      "Add of existing embedding ID: 97\n",
      "Add of existing embedding ID: 98\n",
      "Add of existing embedding ID: 99\n",
      "Add of existing embedding ID: 100\n",
      "Add of existing embedding ID: 101\n",
      "Add of existing embedding ID: 102\n",
      "Add of existing embedding ID: 103\n",
      "Add of existing embedding ID: 104\n",
      "Add of existing embedding ID: 105\n",
      "Add of existing embedding ID: 106\n",
      "Add of existing embedding ID: 107\n",
      "Add of existing embedding ID: 108\n",
      "Add of existing embedding ID: 109\n",
      "Add of existing embedding ID: 110\n",
      "Add of existing embedding ID: 111\n",
      "Add of existing embedding ID: 112\n",
      "Add of existing embedding ID: 113\n",
      "Add of existing embedding ID: 114\n",
      "Add of existing embedding ID: 115\n",
      "Add of existing embedding ID: 116\n",
      "Add of existing embedding ID: 117\n",
      "Add of existing embedding ID: 118\n",
      "Add of existing embedding ID: 119\n",
      "Add of existing embedding ID: 120\n",
      "Add of existing embedding ID: 121\n",
      "Add of existing embedding ID: 122\n",
      "Add of existing embedding ID: 123\n",
      "Add of existing embedding ID: 124\n",
      "Add of existing embedding ID: 125\n",
      "Add of existing embedding ID: 126\n",
      "Add of existing embedding ID: 127\n",
      "Add of existing embedding ID: 128\n",
      "Add of existing embedding ID: 129\n",
      "Add of existing embedding ID: 130\n",
      "Add of existing embedding ID: 131\n",
      "Add of existing embedding ID: 132\n",
      "Add of existing embedding ID: 133\n",
      "Add of existing embedding ID: 134\n",
      "Add of existing embedding ID: 135\n",
      "Add of existing embedding ID: 136\n",
      "Add of existing embedding ID: 137\n",
      "Add of existing embedding ID: 138\n",
      "Add of existing embedding ID: 139\n",
      "Add of existing embedding ID: 140\n",
      "Add of existing embedding ID: 141\n",
      "Add of existing embedding ID: 142\n",
      "Add of existing embedding ID: 143\n",
      "Add of existing embedding ID: 144\n",
      "Add of existing embedding ID: 145\n",
      "Add of existing embedding ID: 146\n",
      "Add of existing embedding ID: 147\n",
      "Add of existing embedding ID: 148\n",
      "Add of existing embedding ID: 149\n",
      "Add of existing embedding ID: 150\n",
      "Add of existing embedding ID: 151\n",
      "Add of existing embedding ID: 152\n",
      "Add of existing embedding ID: 153\n",
      "Add of existing embedding ID: 154\n",
      "Add of existing embedding ID: 155\n",
      "Add of existing embedding ID: 156\n",
      "Add of existing embedding ID: 157\n",
      "Add of existing embedding ID: 158\n",
      "Add of existing embedding ID: 159\n",
      "Add of existing embedding ID: 160\n",
      "Add of existing embedding ID: 161\n",
      "Add of existing embedding ID: 162\n",
      "Add of existing embedding ID: 163\n",
      "Add of existing embedding ID: 164\n",
      "Add of existing embedding ID: 165\n",
      "Add of existing embedding ID: 166\n",
      "Add of existing embedding ID: 167\n",
      "Add of existing embedding ID: 168\n",
      "Add of existing embedding ID: 169\n",
      "Add of existing embedding ID: 170\n",
      "Add of existing embedding ID: 171\n",
      "Add of existing embedding ID: 172\n",
      "Add of existing embedding ID: 173\n",
      "Add of existing embedding ID: 174\n",
      "Add of existing embedding ID: 175\n",
      "Add of existing embedding ID: 177\n",
      "Add of existing embedding ID: 178\n",
      "Add of existing embedding ID: 179\n",
      "Add of existing embedding ID: 180\n",
      "Add of existing embedding ID: 181\n",
      "Add of existing embedding ID: 182\n",
      "Add of existing embedding ID: 183\n",
      "Add of existing embedding ID: 184\n",
      "Add of existing embedding ID: 185\n",
      "Add of existing embedding ID: 186\n",
      "Add of existing embedding ID: 187\n",
      "Add of existing embedding ID: 188\n",
      "Add of existing embedding ID: 189\n",
      "Add of existing embedding ID: 190\n",
      "Add of existing embedding ID: 191\n",
      "Add of existing embedding ID: 192\n",
      "Add of existing embedding ID: 193\n",
      "Add of existing embedding ID: 194\n",
      "Add of existing embedding ID: 195\n",
      "Add of existing embedding ID: 196\n",
      "Add of existing embedding ID: 197\n",
      "Add of existing embedding ID: 198\n",
      "Add of existing embedding ID: 199\n",
      "Add of existing embedding ID: 200\n",
      "Insert of existing embedding ID: 1\n",
      "Insert of existing embedding ID: 2\n",
      "Insert of existing embedding ID: 3\n",
      "Insert of existing embedding ID: 4\n",
      "Insert of existing embedding ID: 5\n",
      "Insert of existing embedding ID: 6\n",
      "Insert of existing embedding ID: 7\n",
      "Insert of existing embedding ID: 8\n",
      "Insert of existing embedding ID: 9\n",
      "Insert of existing embedding ID: 10\n",
      "Insert of existing embedding ID: 11\n",
      "Insert of existing embedding ID: 12\n",
      "Insert of existing embedding ID: 13\n",
      "Insert of existing embedding ID: 14\n",
      "Insert of existing embedding ID: 15\n",
      "Insert of existing embedding ID: 16\n",
      "Insert of existing embedding ID: 17\n",
      "Insert of existing embedding ID: 18\n",
      "Insert of existing embedding ID: 19\n",
      "Insert of existing embedding ID: 20\n",
      "Insert of existing embedding ID: 21\n",
      "Insert of existing embedding ID: 22\n",
      "Insert of existing embedding ID: 23\n",
      "Insert of existing embedding ID: 24\n",
      "Insert of existing embedding ID: 25\n",
      "Insert of existing embedding ID: 26\n",
      "Insert of existing embedding ID: 27\n",
      "Insert of existing embedding ID: 28\n",
      "Insert of existing embedding ID: 29\n",
      "Insert of existing embedding ID: 30\n",
      "Insert of existing embedding ID: 31\n",
      "Insert of existing embedding ID: 32\n",
      "Insert of existing embedding ID: 34\n",
      "Insert of existing embedding ID: 35\n",
      "Insert of existing embedding ID: 36\n",
      "Insert of existing embedding ID: 37\n",
      "Insert of existing embedding ID: 38\n",
      "Insert of existing embedding ID: 39\n",
      "Insert of existing embedding ID: 40\n",
      "Insert of existing embedding ID: 41\n",
      "Insert of existing embedding ID: 42\n",
      "Insert of existing embedding ID: 43\n",
      "Insert of existing embedding ID: 44\n",
      "Insert of existing embedding ID: 45\n",
      "Insert of existing embedding ID: 46\n",
      "Insert of existing embedding ID: 47\n",
      "Insert of existing embedding ID: 48\n",
      "Insert of existing embedding ID: 49\n",
      "Insert of existing embedding ID: 50\n",
      "Insert of existing embedding ID: 51\n",
      "Insert of existing embedding ID: 52\n",
      "Insert of existing embedding ID: 53\n",
      "Insert of existing embedding ID: 54\n",
      "Insert of existing embedding ID: 55\n",
      "Insert of existing embedding ID: 57\n",
      "Insert of existing embedding ID: 58\n",
      "Insert of existing embedding ID: 59\n",
      "Insert of existing embedding ID: 60\n",
      "Insert of existing embedding ID: 61\n",
      "Insert of existing embedding ID: 62\n",
      "Insert of existing embedding ID: 63\n",
      "Insert of existing embedding ID: 64\n",
      "Insert of existing embedding ID: 65\n",
      "Insert of existing embedding ID: 66\n",
      "Insert of existing embedding ID: 67\n",
      "Insert of existing embedding ID: 68\n",
      "Insert of existing embedding ID: 69\n",
      "Insert of existing embedding ID: 71\n",
      "Insert of existing embedding ID: 72\n",
      "Insert of existing embedding ID: 73\n",
      "Insert of existing embedding ID: 74\n",
      "Insert of existing embedding ID: 75\n",
      "Insert of existing embedding ID: 76\n",
      "Insert of existing embedding ID: 77\n",
      "Insert of existing embedding ID: 78\n",
      "Insert of existing embedding ID: 79\n",
      "Insert of existing embedding ID: 80\n",
      "Insert of existing embedding ID: 81\n",
      "Insert of existing embedding ID: 82\n",
      "Insert of existing embedding ID: 83\n",
      "Insert of existing embedding ID: 84\n",
      "Insert of existing embedding ID: 85\n",
      "Insert of existing embedding ID: 86\n",
      "Insert of existing embedding ID: 87\n",
      "Insert of existing embedding ID: 88\n",
      "Insert of existing embedding ID: 89\n",
      "Insert of existing embedding ID: 90\n",
      "Insert of existing embedding ID: 91\n",
      "Insert of existing embedding ID: 92\n",
      "Insert of existing embedding ID: 93\n",
      "Insert of existing embedding ID: 94\n",
      "Insert of existing embedding ID: 95\n",
      "Insert of existing embedding ID: 96\n",
      "Insert of existing embedding ID: 97\n",
      "Insert of existing embedding ID: 98\n",
      "Insert of existing embedding ID: 99\n",
      "Insert of existing embedding ID: 100\n",
      "Insert of existing embedding ID: 101\n",
      "Insert of existing embedding ID: 102\n",
      "Insert of existing embedding ID: 103\n",
      "Insert of existing embedding ID: 104\n",
      "Insert of existing embedding ID: 105\n",
      "Insert of existing embedding ID: 106\n",
      "Insert of existing embedding ID: 107\n",
      "Insert of existing embedding ID: 108\n",
      "Insert of existing embedding ID: 109\n",
      "Insert of existing embedding ID: 110\n",
      "Insert of existing embedding ID: 111\n",
      "Insert of existing embedding ID: 112\n",
      "Insert of existing embedding ID: 113\n",
      "Insert of existing embedding ID: 114\n",
      "Insert of existing embedding ID: 115\n",
      "Insert of existing embedding ID: 116\n",
      "Insert of existing embedding ID: 117\n",
      "Insert of existing embedding ID: 118\n",
      "Insert of existing embedding ID: 119\n",
      "Insert of existing embedding ID: 120\n",
      "Insert of existing embedding ID: 121\n",
      "Insert of existing embedding ID: 122\n",
      "Insert of existing embedding ID: 123\n",
      "Insert of existing embedding ID: 124\n",
      "Insert of existing embedding ID: 125\n",
      "Insert of existing embedding ID: 126\n",
      "Insert of existing embedding ID: 127\n",
      "Insert of existing embedding ID: 128\n",
      "Insert of existing embedding ID: 129\n",
      "Insert of existing embedding ID: 130\n",
      "Insert of existing embedding ID: 131\n",
      "Insert of existing embedding ID: 132\n",
      "Insert of existing embedding ID: 133\n",
      "Insert of existing embedding ID: 134\n",
      "Insert of existing embedding ID: 135\n",
      "Insert of existing embedding ID: 136\n",
      "Insert of existing embedding ID: 137\n",
      "Insert of existing embedding ID: 138\n",
      "Insert of existing embedding ID: 139\n",
      "Insert of existing embedding ID: 140\n",
      "Insert of existing embedding ID: 141\n",
      "Insert of existing embedding ID: 142\n",
      "Insert of existing embedding ID: 143\n",
      "Insert of existing embedding ID: 144\n",
      "Insert of existing embedding ID: 145\n",
      "Insert of existing embedding ID: 146\n",
      "Insert of existing embedding ID: 147\n",
      "Insert of existing embedding ID: 148\n",
      "Insert of existing embedding ID: 149\n",
      "Insert of existing embedding ID: 150\n",
      "Insert of existing embedding ID: 151\n",
      "Insert of existing embedding ID: 152\n",
      "Insert of existing embedding ID: 153\n",
      "Insert of existing embedding ID: 154\n",
      "Insert of existing embedding ID: 155\n",
      "Insert of existing embedding ID: 156\n",
      "Insert of existing embedding ID: 157\n",
      "Insert of existing embedding ID: 158\n",
      "Insert of existing embedding ID: 159\n",
      "Insert of existing embedding ID: 160\n",
      "Insert of existing embedding ID: 161\n",
      "Insert of existing embedding ID: 162\n",
      "Insert of existing embedding ID: 163\n",
      "Insert of existing embedding ID: 164\n",
      "Insert of existing embedding ID: 165\n",
      "Insert of existing embedding ID: 166\n",
      "Insert of existing embedding ID: 167\n",
      "Insert of existing embedding ID: 168\n",
      "Insert of existing embedding ID: 169\n",
      "Insert of existing embedding ID: 170\n",
      "Insert of existing embedding ID: 171\n",
      "Insert of existing embedding ID: 172\n",
      "Insert of existing embedding ID: 173\n",
      "Insert of existing embedding ID: 174\n",
      "Insert of existing embedding ID: 175\n",
      "Insert of existing embedding ID: 177\n",
      "Insert of existing embedding ID: 178\n",
      "Insert of existing embedding ID: 179\n",
      "Insert of existing embedding ID: 180\n",
      "Insert of existing embedding ID: 181\n",
      "Insert of existing embedding ID: 182\n",
      "Insert of existing embedding ID: 183\n",
      "Insert of existing embedding ID: 184\n",
      "Insert of existing embedding ID: 185\n",
      "Insert of existing embedding ID: 186\n",
      "Insert of existing embedding ID: 187\n",
      "Insert of existing embedding ID: 188\n",
      "Insert of existing embedding ID: 189\n",
      "Insert of existing embedding ID: 190\n",
      "Insert of existing embedding ID: 191\n",
      "Insert of existing embedding ID: 192\n",
      "Insert of existing embedding ID: 193\n",
      "Insert of existing embedding ID: 194\n",
      "Insert of existing embedding ID: 195\n",
      "Insert of existing embedding ID: 196\n",
      "Insert of existing embedding ID: 197\n",
      "Insert of existing embedding ID: 198\n",
      "Insert of existing embedding ID: 199\n",
      "Insert of existing embedding ID: 200\n"
     ]
    }
   ],
   "source": [
    "# Create a collection for the posts\n",
    "collection_posts = vectordb_2datasets.get_or_create_collection(name=\"collection_posts\",\n",
    "                                                               )\n",
    "collection_posts.add(documents=documents_posts,\n",
    "                     metadatas=metadatas_posts,\n",
    "                     ids=ids_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I’m up now I’m available @client_services_am @weekend_dispatch',\n",
       " 'BEEN UNDER THE WEATHER FOR A FEW DAYS BUT I CAN’T COMPLAIN CAUSE I’M STILL LIVING & ABLE….LET’S MAKE TODAY BETTER THAN YESTERDAY',\n",
       " 'Client: Verizon - MD\\nDate: 1/19/2024\\nTime: ASAP\\nAddress:  Flagger Force\\nOrder: 574952\\nNotes:  Please comment if you are available, thank you!',\n",
       " 'Client: NPL - Washington, PA\\nDate: 12/13/22\\nAddress: 69 Market St Brownsville Pa \\nOrder# 536569\\nStart Time:  ASAP\\nNotes: Please comment below or call the OSC if you are available.',\n",
       " 'It’s suppose to storm tonight so I’m available @client_services_transition @client_services_pm @client_services_transition @client_services_pm',\n",
       " 'Order: 577546\\nClient: BGE Front Street\\nAddress: 1101 Russell Street, Baltimore\\nDate: 2/16/24\\nStart: 19:00\\n\\n\\nOrder: 577549\\nClient: BGE Piney Orchard\\nAddress: 730 New Waugh Chapel Road, Ondeton\\nDate: 2/16/24\\nStart: 19:00',\n",
       " 'Cl available in cpa but willing to travel',\n",
       " 'Pick Up: 220 8th Avenue NW, Glen Burnie, MD 21061\\nDrop Off: 6256 Shady Side Road , Shady Side MD, 20764\\n\\n\\nCrew Leads on site will take PLTs back when job is completed.',\n",
       " 'Client: Verizon - MD\\nDate: 8/11/22\\nAddress:  29321 Gaither Rd. Gaithersburg, MD\\nOrder #: 526933\\nStart time: ASAP\\nNotes: Please comment below or call the OSC if you are available, thank you! 🙂',\n",
       " 'Waiting to find out where the lines are down']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns a list of the first 10 items in the collection\n",
    "collection_posts.peek()['documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the client\n",
    "PERSIST_DIRECTORY = \"/home/ubuntu/thesis_GenAI/data/vector_db\"\n",
    "\n",
    "# Initialize the database\n",
    "# vectordb_2datasets = chromadb.PersistentClient(path=PERSIST_DIRECTORY, \n",
    "#                                                settings=Settings(allow_reset=True,\n",
    "#                                                ))                                                                 \n",
    "                                                                 \n",
    "# vectordb_2datasets.reset()\n",
    "\n",
    "# Delete the collection\n",
    "# vectordb_2datasets.delete_collection(name=\"collection_comments\")\n",
    "# vectordb_2datasets.delete_collection(name=\"collection_posts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Create LangChain Objects and Retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 250 in the collection of comments.\n",
      "There are 196 in the collection of posts.\n"
     ]
    }
   ],
   "source": [
    "# Define the open-source embedding function ()\n",
    "#embedding_func = SentenceTransformerEmbeddings(model_name=\"all-mpnet-base-v2\")\n",
    "embedding_func = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Passing a Chroma Client into Langchain\n",
    "langchain_chroma_comments = Chroma(client=vectordb_2datasets,                        \n",
    "                         collection_name=\"collection_comments\",\n",
    "                         embedding_function=embedding_func,\n",
    ")\n",
    "print(\"There are\", langchain_chroma_comments._collection.count(), \"in the collection of comments.\")\n",
    "\n",
    "\n",
    "# Passing a Chroma Client into Langchain\n",
    "langchain_chroma_posts = Chroma(client=vectordb_2datasets,                        \n",
    "                         collection_name=\"collection_posts\",\n",
    "                         embedding_function=embedding_func,\n",
    ")\n",
    "print(\"There are\", langchain_chroma_posts._collection.count(), \"in the collection of posts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata comments's description\n",
    "metadata_field_info_comments = [\n",
    "    AttributeInfo(\n",
    "        name=\"stream_name\",\n",
    "        description=\"The stream where the comment was poste. One of ['Jobs','Water Break','Safety & Operations','OSC, We Can Help','Flagger Force Connect','The Whiteboard','Test Stream']\",\n",
    "        type=\"object\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"created_date\",\n",
    "        description=\"The datetime when the comment was posted\",\n",
    "        type=\"object\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"post_id\",\n",
    "        description=\"The id of the post where the comment was posted\",\n",
    "        type=\"int64\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"comment_id\",\n",
    "        description=\"The id of the comment\",\n",
    "        type=\"int64\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"like_count\",\n",
    "        description=\"The number of likes received by the comment\",\n",
    "        type=\"int64\",        \n",
    "    ),    \n",
    "    AttributeInfo(\n",
    "        name=\"report_count\",\n",
    "        description=\"The number of reports where the comment appears\",\n",
    "        type=\"int64\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"username\",\n",
    "        description=\"The username of the author of the comment\",\n",
    "        type=\"object\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"author_user_id\",\n",
    "        description=\"The id of the author of the comment\",\n",
    "        type=\"object\",\n",
    "    ),    \n",
    "    AttributeInfo(\n",
    "        name=\"author_position\",\n",
    "        description=\"The position of the author of the comment. One of ['Advanced Crew Leader','Crew Member','Crew Leader','Weekend Dispatch','Lead Instructor','Area Supervisor','Field Trainer 1','Warehouse Coordinator','Field Trainer 2','Executive Assistant','Internal Communications Manager','Field Manager','Safety Professional','Internal Communications Coordinator', 'Employee Services Supervisor','Safety Advocate', and many more...]\",\n",
    "        type=\"object\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"author_status\",\n",
    "        description=\"The status of the author of the comment. One of ['active','suspended']\",\n",
    "        type=\"object\",\n",
    "    ),\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/chat (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fa82a239b70>: Failed to establish a new connection: [Errno 111] Connection refused'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m~/thesis_GenAI/ollama_first/.env_rag/lib/python3.10/site-packages/urllib3/connection.py:198\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 198\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/thesis_GenAI/ollama_first/.env_rag/lib/python3.10/site-packages/urllib3/util/connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "File \u001b[0;32m~/thesis_GenAI/ollama_first/.env_rag/lib/python3.10/site-packages/urllib3/util/connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 73\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/thesis_GenAI/ollama_first/.env_rag/lib/python3.10/site-packages/urllib3/connectionpool.py:793\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 793\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m~/thesis_GenAI/ollama_first/.env_rag/lib/python3.10/site-packages/urllib3/connectionpool.py:496\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 496\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_content_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[0;32m~/thesis_GenAI/ollama_first/.env_rag/lib/python3.10/site-packages/urllib3/connection.py:400\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mputheader(header, value)\n\u001b[0;32m--> 400\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;66;03m# If we're given a body we start sending that in chunks.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:1278\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1278\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:1038\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1038\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1041\u001b[0m \n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:976\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m--> 976\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/thesis_GenAI/ollama_first/.env_rag/lib/python3.10/site-packages/urllib3/connection.py:238\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;66;03m# If we're tunneling it means we're connected to our proxy.\u001b[39;00m\n",
      "File \u001b[0;32m~/thesis_GenAI/ollama_first/.env_rag/lib/python3.10/site-packages/urllib3/connection.py:213\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 213\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    215\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;66;03m# Audit hooks are only available in Python 3.8+\u001b[39;00m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x7fa82a239b70>: Failed to establish a new connection: [Errno 111] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/thesis_GenAI/ollama_first/.env_rag/lib/python3.10/site-packages/requests/adapters.py:589\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 589\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/thesis_GenAI/ollama_first/.env_rag/lib/python3.10/site-packages/urllib3/connectionpool.py:847\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    845\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m--> 847\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    850\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/thesis_GenAI/ollama_first/.env_rag/lib/python3.10/site-packages/urllib3/util/retry.py:515\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    514\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[0;32m--> 515\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    517\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/chat (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fa82a239b70>: Failed to establish a new connection: [Errno 111] Connection refused'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 16\u001b[0m\n\u001b[1;32m      7\u001b[0m llm \u001b[38;5;241m=\u001b[39m ChatOllama(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmistral\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m retriever_comments \u001b[38;5;241m=\u001b[39m SelfQueryRetriever\u001b[38;5;241m.\u001b[39mfrom_llm(    \n\u001b[1;32m     10\u001b[0m     llm,\n\u001b[1;32m     11\u001b[0m     langchain_chroma_comments,\n\u001b[1;32m     12\u001b[0m     document_content_description,    \n\u001b[1;32m     13\u001b[0m     metadata_field_info_comments,\n\u001b[1;32m     14\u001b[0m )\n\u001b[0;32m---> 16\u001b[0m results_a \u001b[38;5;241m=\u001b[39m \u001b[43mretriever_comments\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat are some comments about birthday congratulations\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m results_a\n",
      "File \u001b[0;32m~/thesis_GenAI/ollama_first/.env_rag/lib/python3.10/site-packages/langchain_core/retrievers.py:194\u001b[0m, in \u001b[0;36mBaseRetriever.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Invoke the retriever to get relevant documents.\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \n\u001b[1;32m    177\u001b[0m \u001b[38;5;124;03mMain entry point for synchronous retriever invocations.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03m    retriever.invoke(\"query\")\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    193\u001b[0m config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m--> 194\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/thesis_GenAI/ollama_first/.env_rag/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:148\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     emit_warning()\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/thesis_GenAI/ollama_first/.env_rag/lib/python3.10/site-packages/langchain_core/retrievers.py:323\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[0;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    322\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_error(e)\n\u001b[0;32m--> 323\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    325\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_end(\n\u001b[1;32m    326\u001b[0m         result,\n\u001b[1;32m    327\u001b[0m     )\n",
      "File \u001b[0;32m~/thesis_GenAI/ollama_first/.env_rag/lib/python3.10/site-packages/langchain_core/retrievers.py:316\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[0;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m _kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_arg_supported:\n\u001b[0;32m--> 316\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    320\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n",
      "File \u001b[0;32m~/thesis_GenAI/ollama_first/.env_rag/lib/python3.10/site-packages/langchain/retrievers/self_query/base.py:234\u001b[0m, in \u001b[0;36mSelfQueryRetriever._get_relevant_documents\u001b[0;34m(self, query, run_manager)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_relevant_documents\u001b[39m(\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m, run_manager: CallbackManagerForRetrieverRun\n\u001b[1;32m    225\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m    226\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get documents relevant for a query.\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \n\u001b[1;32m    228\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;124;03m        List of relevant documents\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 234\u001b[0m     structured_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_constructor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[1;32m    238\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated Query: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstructured_query\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/thesis_GenAI/ollama_first/.env_rag/lib/python3.10/site-packages/langchain_core/runnables/base.py:4427\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4421\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m   4422\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4423\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   4424\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   4425\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   4426\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[0;32m-> 4427\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4428\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4429\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4430\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4431\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/thesis_GenAI/ollama_first/.env_rag/lib/python3.10/site-packages/langchain_core/runnables/base.py:2393\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   2391\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2392\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[0;32m-> 2393\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2394\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2395\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   2396\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2397\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2398\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2399\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2400\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   2401\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/thesis_GenAI/ollama_first/.env_rag/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:170\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    166\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    167\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    169\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 170\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    180\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/thesis_GenAI/ollama_first/.env_rag/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:599\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    592\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    593\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    597\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    598\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 599\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/thesis_GenAI/ollama_first/.env_rag/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:456\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    455\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 456\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    457\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    458\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    460\u001b[0m ]\n\u001b[1;32m    461\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/thesis_GenAI/ollama_first/.env_rag/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:446\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    445\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 446\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m         )\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    454\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/thesis_GenAI/ollama_first/.env_rag/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:671\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 671\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    675\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/thesis_GenAI/ollama_first/.env_rag/lib/python3.10/site-packages/langchain_community/chat_models/ollama.py:259\u001b[0m, in \u001b[0;36mChatOllama._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate\u001b[39m(\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    237\u001b[0m     messages: List[BaseMessage],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    241\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResult:\n\u001b[1;32m    242\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call out to Ollama's generate endpoint.\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \n\u001b[1;32m    244\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;124;03m            ])\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 259\u001b[0m     final_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_chat_stream_with_aggregation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m     chat_generation \u001b[38;5;241m=\u001b[39m ChatGeneration(\n\u001b[1;32m    267\u001b[0m         message\u001b[38;5;241m=\u001b[39mAIMessage(content\u001b[38;5;241m=\u001b[39mfinal_chunk\u001b[38;5;241m.\u001b[39mtext),\n\u001b[1;32m    268\u001b[0m         generation_info\u001b[38;5;241m=\u001b[39mfinal_chunk\u001b[38;5;241m.\u001b[39mgeneration_info,\n\u001b[1;32m    269\u001b[0m     )\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatResult(generations\u001b[38;5;241m=\u001b[39m[chat_generation])\n",
      "File \u001b[0;32m~/thesis_GenAI/ollama_first/.env_rag/lib/python3.10/site-packages/langchain_community/chat_models/ollama.py:190\u001b[0m, in \u001b[0;36mChatOllama._chat_stream_with_aggregation\u001b[0;34m(self, messages, stop, run_manager, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_chat_stream_with_aggregation\u001b[39m(\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    183\u001b[0m     messages: List[BaseMessage],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    188\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatGenerationChunk:\n\u001b[1;32m    189\u001b[0m     final_chunk: Optional[ChatGenerationChunk] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m stream_resp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_stream(messages, stop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m stream_resp:\n\u001b[1;32m    192\u001b[0m             chunk \u001b[38;5;241m=\u001b[39m _chat_stream_response_to_chat_generation_chunk(stream_resp)\n",
      "File \u001b[0;32m~/thesis_GenAI/ollama_first/.env_rag/lib/python3.10/site-packages/langchain_community/chat_models/ollama.py:162\u001b[0m, in \u001b[0;36mChatOllama._create_chat_stream\u001b[0;34m(self, messages, stop, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_chat_stream\u001b[39m(\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    154\u001b[0m     messages: List[BaseMessage],\n\u001b[1;32m    155\u001b[0m     stop: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    157\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    158\u001b[0m     payload \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_messages_to_ollama_messages(messages),\n\u001b[1;32m    161\u001b[0m     }\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_stream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpayload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_url\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/api/chat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/thesis_GenAI/ollama_first/.env_rag/lib/python3.10/site-packages/langchain_community/llms/ollama.py:231\u001b[0m, in \u001b[0;36m_OllamaCommon._create_stream\u001b[0;34m(self, api_url, payload, stop, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     request_payload \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: payload\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m: payload\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m, []),\n\u001b[1;32m    228\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    229\u001b[0m     }\n\u001b[0;32m--> 231\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mContent-Type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mapplication/json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m response\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n",
      "File \u001b[0;32m~/thesis_GenAI/ollama_first/.env_rag/lib/python3.10/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/thesis_GenAI/ollama_first/.env_rag/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/thesis_GenAI/ollama_first/.env_rag/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/thesis_GenAI/ollama_first/.env_rag/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/thesis_GenAI/ollama_first/.env_rag/lib/python3.10/site-packages/requests/adapters.py:622\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _SSLError):\n\u001b[1;32m    619\u001b[0m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[1;32m    620\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m--> 622\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/chat (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fa82a239b70>: Failed to establish a new connection: [Errno 111] Connection refused'))"
     ]
    }
   ],
   "source": [
    "# Creating our self-querying retriever for comments\n",
    "document_content_description = \"Comments on social network posts\"\n",
    "#llm = ChatOllama(model=\"mistral\")\n",
    "\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain_community.chat_models.ollama import ChatOllama\n",
    "llm = ChatOllama(model=\"mistral\")\n",
    "\n",
    "retriever_comments = SelfQueryRetriever.from_llm(    \n",
    "    llm,\n",
    "    langchain_chroma_comments,\n",
    "    document_content_description,    \n",
    "    metadata_field_info_comments,\n",
    ")\n",
    "\n",
    "results_a = retriever_comments.invoke(\"What are some comments about birthday congratulations\")\n",
    "results_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posts Metadata description\n",
    "metadata_field_info_post = [\n",
    "    AttributeInfo(\n",
    "        name=\"stream_name\",\n",
    "        description=\"The stream where the comment was poste. One of ['Jobs','Water Break','Safety & Operations','OSC, We Can Help','Flagger Force Connect','The Whiteboard','Test Stream']\",\n",
    "        type=\"object\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"stream_id\",\n",
    "        description=\"The id of the stream where the post was posted\",\n",
    "        type=\"int64\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"post_id\",\n",
    "        description=\"The id of the post\",\n",
    "        type=\"int64\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"action\",\n",
    "        description=\"The id of the post where the comment was posted\",\n",
    "        type=\"object\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"created\",\n",
    "        description=\"The datetime when the post was create\",\n",
    "        type=\"object\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"title\",\n",
    "        description=\"The title of the post\",\n",
    "        type=\"object\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"like_count\",\n",
    "        description=\"The number of likes received by the post\",\n",
    "        type=\"int64\",        \n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"comment_count\",\n",
    "        description=\"The number of comments received by the post\",\n",
    "        type=\"int64\",        \n",
    "    ),   \n",
    "    AttributeInfo(\n",
    "        name=\"mentions\",\n",
    "        description=\"The usernames that were mention in the post\",\n",
    "        type=\"object\",\n",
    "    ),        \n",
    "    # AttributeInfo(\n",
    "    #     name=\"labels\",\n",
    "    #     description=\"The keywords found in the post\",\n",
    "    #     type=\"int64\",\n",
    "    # ),\n",
    "    AttributeInfo(\n",
    "        name=\"username\",\n",
    "        description=\"The username of the author of the post\",\n",
    "        type=\"object\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"author_user_id\",\n",
    "        description=\"The id of the author of the post\",\n",
    "        type=\"object\",\n",
    "    ),    \n",
    "    AttributeInfo(\n",
    "        name=\"author_position\",\n",
    "        description=\"The position of the author of the post. One of ['Advanced Crew Leader','Crew Member','Crew Leader','Weekend Dispatch','Lead Instructor','Area Supervisor','Field Trainer 1','Warehouse Coordinator','Field Trainer 2','Executive Assistant','Internal Communications Manager','Field Manager','Safety Professional','Internal Communications Coordinator', 'Employee Services Supervisor','Safety Advocate', and many more...]\",\n",
    "        type=\"object\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"author_status\",\n",
    "        description=\"The status of the author of the post. One of ['active','suspended']\",\n",
    "        type=\"object\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='I need work on 7/4/23 and thank you', metadata={'action': 'POSTED', 'author_position': 'Crew Member', 'author_status': 'active', 'author_user_id': '2941f06f-db75-44cd-8422-668d8362125a', 'comment_count': 4, 'created': '2023-06-28 20:10:28', 'like_count': 1, 'post_id': 6762569, 'stream_id': 9254, 'stream_name': 'Jobs', 'title': 'Cm- Available', 'username': 'Cindy_Knight'}),\n",
       " Document(page_content='About 1 month ago, I had the chance to catch up with Crew Leader @Chaad_TerrySr to celebrate his 5 year anniversary.  Chaad is one of our key leaders supporting the PECO-Flagger Force partnership!  Thank you Chaad for 5 years of outstanding support to our clients, your focus on keeping our team members safe and providing a valuable service to our community!  Congratulations!', metadata={'action': 'POSTED', 'author_position': 'President & CEO', 'author_status': 'active', 'author_user_id': '314f3df5-80c3-432d-8446-666622b10fb6', 'comment_count': 19, 'created': '2022-03-28 10:09:26', 'like_count': 34, 'mentions': 'Chaad_TerrySr', 'post_id': 5156400, 'stream_id': 5745, 'stream_name': 'Safety & Operations', 'title': '5 Years of Dedicated Support - Chaad Terry', 'username': 'mike_doner'}),\n",
       " Document(page_content='Anytime and day', metadata={'action': 'POSTED', 'author_position': 'Crew Member', 'author_status': 'suspended', 'author_user_id': '1e962099-87e1-4890-af7b-4974a455685a', 'comment_count': 0, 'created': '2022-07-27 19:22:24', 'like_count': 0, 'post_id': 5582095, 'stream_id': 9254, 'stream_name': 'Jobs', 'title': 'Available for work', 'username': 'James_Patterson2'}),\n",
       " Document(page_content=\"OSC........DON'T CALL TIL MONDAY!\\nEVERYONE HAVE A AWESOME WEEKEND, YOU DESERVED IT!\", metadata={'action': 'POSTED', 'author_position': 'Advanced Crew Leader', 'author_status': 'suspended', 'author_user_id': 'fc08abd7-d7dc-4d5e-b5c0-f372bbbb762e', 'comment_count': 1, 'created': '2023-05-19 21:50:56', 'like_count': 8, 'post_id': 6608939, 'stream_id': 6787, 'stream_name': 'Water Break', 'username': 'John_Stacy'})]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating our self-querying retriever\n",
    "document_content_description = \"Posts in social network\"\n",
    "llm = ChatOllama(model=\"mistral\")\n",
    "\n",
    "retriever_posts = SelfQueryRetriever.from_llm(    \n",
    "    llm,\n",
    "    langchain_chroma_posts,\n",
    "    document_content_description,    \n",
    "    metadata_field_info_post,\n",
    ")\n",
    "\n",
    "# This example only specifies a query\n",
    "result_b = retriever_posts.invoke(\"What are some posts about birthday congratulations\")\n",
    "result_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ensemble retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "# initialize the ensemble retriever\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[retriever_comments, retriever_posts], weights=[0.5, 0.5]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Happy Birthday', metadata={'author_position': 'Crew Member', 'author_status': 'suspended', 'author_user_id': 'c40c2d53-7c19-441e-b925-f07a3eaa8c9a', 'comment_id': 5500647, 'created_date': '2023-03-18 15:07:17', 'like_count': 1, 'post_id': 6365853, 'report_count': 0, 'stream_name': 'Water Break', 'username': 'Russell_Spicer'}),\n",
       " Document(page_content='I need work on 7/4/23 and thank you', metadata={'action': 'POSTED', 'author_position': 'Crew Member', 'author_status': 'active', 'author_user_id': '2941f06f-db75-44cd-8422-668d8362125a', 'comment_count': 4, 'created': '2023-06-28 20:10:28', 'like_count': 1, 'post_id': 6762569, 'stream_id': 9254, 'stream_name': 'Jobs', 'title': 'Cm- Available', 'username': 'Cindy_Knight'}),\n",
       " Document(page_content='Congratulations', metadata={'author_position': 'Crew Leader', 'author_status': 'suspended', 'author_user_id': 'c89cd870-1347-4a5d-acaa-d7abf1c7efa3', 'comment_id': 5671293, 'created_date': '2023-05-01 23:45:54', 'like_count': 0, 'post_id': 6515225, 'report_count': 0, 'stream_name': 'Safety & Operations', 'username': 'Shannon_Eachus'}),\n",
       " Document(page_content='About 1 month ago, I had the chance to catch up with Crew Leader @Chaad_TerrySr to celebrate his 5 year anniversary.  Chaad is one of our key leaders supporting the PECO-Flagger Force partnership!  Thank you Chaad for 5 years of outstanding support to our clients, your focus on keeping our team members safe and providing a valuable service to our community!  Congratulations!', metadata={'action': 'POSTED', 'author_position': 'President & CEO', 'author_status': 'active', 'author_user_id': '314f3df5-80c3-432d-8446-666622b10fb6', 'comment_count': 19, 'created': '2022-03-28 10:09:26', 'like_count': 34, 'mentions': 'Chaad_TerrySr', 'post_id': 5156400, 'stream_id': 5745, 'stream_name': 'Safety & Operations', 'title': '5 Years of Dedicated Support - Chaad Terry', 'username': 'mike_doner'}),\n",
       " Document(page_content='🙏happy birthday 🙏', metadata={'author_position': 'Crew Member', 'author_status': 'suspended', 'author_user_id': 'c40c2d53-7c19-441e-b925-f07a3eaa8c9a', 'comment_id': 5915651, 'created_date': '2023-06-30 18:03:57', 'like_count': 1, 'post_id': 6770961, 'report_count': 0, 'stream_name': 'Water Break', 'username': 'Russell_Spicer'}),\n",
       " Document(page_content='Anytime and day', metadata={'action': 'POSTED', 'author_position': 'Crew Member', 'author_status': 'suspended', 'author_user_id': '1e962099-87e1-4890-af7b-4974a455685a', 'comment_count': 0, 'created': '2022-07-27 19:22:24', 'like_count': 0, 'post_id': 5582095, 'stream_id': 9254, 'stream_name': 'Jobs', 'title': 'Available for work', 'username': 'James_Patterson2'}),\n",
       " Document(page_content='Congratulations 👏👏🎉🎉', metadata={'author_position': 'Crew Leader', 'author_status': 'active', 'author_user_id': 'd02f17c0-194f-4bbd-b13f-53644bdcc5c8', 'comment_id': 6429150, 'created_date': '2023-11-10 21:18:46', 'like_count': 1, 'post_id': 7229098, 'report_count': 0, 'stream_name': 'Water Break', 'username': 'Kimberly_Locke'}),\n",
       " Document(page_content=\"OSC........DON'T CALL TIL MONDAY!\\nEVERYONE HAVE A AWESOME WEEKEND, YOU DESERVED IT!\", metadata={'action': 'POSTED', 'author_position': 'Advanced Crew Leader', 'author_status': 'suspended', 'author_user_id': 'fc08abd7-d7dc-4d5e-b5c0-f372bbbb762e', 'comment_count': 1, 'created': '2023-05-19 21:50:56', 'like_count': 8, 'post_id': 6608939, 'stream_id': 6787, 'stream_name': 'Water Break', 'username': 'John_Stacy'})]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = ensemble_retriever.invoke(\"birthday congratulations\")\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 200 in the collection of comments.\n"
     ]
    }
   ],
   "source": [
    "# Passing a Chroma Client into Langchain\n",
    "langchain_chroma = Chroma(    \n",
    "    client=vectordb_2datasets,\n",
    "    collection_name=\"collection_comments\",\n",
    "    #embedding_function=embedding_func,\n",
    ")\n",
    "\n",
    "print(\"There are\", langchain_chroma._collection.count(), \"in the collection of comments.\")\n",
    "#print(\"There are\", langchain_chroma._collection_posts.count(), \"in the collection of posts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 50 in the collection.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Collection(name=collection_posts)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Passing a Chroma Client into Langchain\n",
    "langchain_chroma_post = Chroma(    \n",
    "    client=vectordb_2datasets,\n",
    "    collection_name=\"collection_posts\",\n",
    "    #embedding_function=embedding_func,\n",
    ")\n",
    "\n",
    "print(\"There are\", langchain_chroma_post._collection.count(), \"in the collection.\")\n",
    "#print(\"There are\", langchain_chroma._collection_posts.count(), \"in the collection of posts.\")\n",
    "langchain_chroma_post._collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You must provide embeddings or a function to compute them",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[101], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Test the langchain_chroma_post\u001b[39;00m\n\u001b[0;32m      2\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat it got said about Jonathan_Muha\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m docs \u001b[38;5;241m=\u001b[39m \u001b[43mlangchain_chroma_post\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(docs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mpage_content)\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:349\u001b[0m, in \u001b[0;36mChroma.similarity_search\u001b[1;34m(self, query, k, filter, **kwargs)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimilarity_search\u001b[39m(\n\u001b[0;32m    333\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    334\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    338\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[0;32m    339\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run similarity search with Chroma.\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \n\u001b[0;32m    341\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;124;03m        List[Document]: List of documents most similar to the query text.\u001b[39;00m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 349\u001b[0m     docs_and_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimilarity_search_with_score(\n\u001b[0;32m    350\u001b[0m         query, k, \u001b[38;5;28mfilter\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfilter\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    351\u001b[0m     )\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [doc \u001b[38;5;28;01mfor\u001b[39;00m doc, _ \u001b[38;5;129;01min\u001b[39;00m docs_and_scores]\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:430\u001b[0m, in \u001b[0;36mChroma.similarity_search_with_score\u001b[1;34m(self, query, k, filter, where_document, **kwargs)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run similarity search with Chroma with distance.\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \n\u001b[0;32m    419\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;124;03m    Lower score represents more similarity.\u001b[39;00m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    429\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 430\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__query_collection(\n\u001b[0;32m    431\u001b[0m         query_texts\u001b[38;5;241m=\u001b[39m[query],\n\u001b[0;32m    432\u001b[0m         n_results\u001b[38;5;241m=\u001b[39mk,\n\u001b[0;32m    433\u001b[0m         where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfilter\u001b[39m,\n\u001b[0;32m    434\u001b[0m         where_document\u001b[38;5;241m=\u001b[39mwhere_document,\n\u001b[0;32m    435\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    436\u001b[0m     )\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m     query_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function\u001b[38;5;241m.\u001b[39membed_query(query)\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\langchain_core\\utils\\utils.py:35\u001b[0m, in \u001b[0;36mxor_args.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     29\u001b[0m     invalid_group_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(arg_groups[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m invalid_groups]\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     31\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExactly one argument in each of the following\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     32\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m groups must be defined:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(invalid_group_names)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     34\u001b[0m     )\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:156\u001b[0m, in \u001b[0;36mChroma.__query_collection\u001b[1;34m(self, query_texts, query_embeddings, n_results, where, where_document, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m    153\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import chromadb python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    154\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install chromadb`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    155\u001b[0m     )\n\u001b[1;32m--> 156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collection\u001b[38;5;241m.\u001b[39mquery(\n\u001b[0;32m    157\u001b[0m     query_texts\u001b[38;5;241m=\u001b[39mquery_texts,\n\u001b[0;32m    158\u001b[0m     query_embeddings\u001b[38;5;241m=\u001b[39mquery_embeddings,\n\u001b[0;32m    159\u001b[0m     n_results\u001b[38;5;241m=\u001b[39mn_results,\n\u001b[0;32m    160\u001b[0m     where\u001b[38;5;241m=\u001b[39mwhere,\n\u001b[0;32m    161\u001b[0m     where_document\u001b[38;5;241m=\u001b[39mwhere_document,\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    163\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\envs\\ollama\\lib\\site-packages\\chromadb\\api\\models\\Collection.py:207\u001b[0m, in \u001b[0;36mCollection.query\u001b[1;34m(self, query_embeddings, query_texts, n_results, where, where_document, include)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m query_embeddings \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 207\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    208\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must provide embeddings or a function to compute them\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;66;03m# We know query texts is not None at this point, cast for the typechecker\u001b[39;00m\n\u001b[0;32m    211\u001b[0m     query_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function(\n\u001b[0;32m    212\u001b[0m         cast(List[Document], query_texts)\n\u001b[0;32m    213\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: You must provide embeddings or a function to compute them"
     ]
    }
   ],
   "source": [
    "# Test the langchain_chroma_post\n",
    "query = \"What it got said about Jonathan_Muha\"\n",
    "docs = langchain_chroma_post.similarity_search(query)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have a safe day, @Jonathan_Muha!\n"
     ]
    }
   ],
   "source": [
    "# Create a database\n",
    "\n",
    "# create the open-source embedding function\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-mpnet-base-v2\")\n",
    "\n",
    "# save to disk\n",
    "db = Chroma.from_documents(docs,\n",
    "                           embedding_function,\n",
    "                           #ids=ids,\n",
    "                           persist_directory=PERSIST_DIRECTORY)\n",
    "\n",
    "# Test the db\n",
    "query = \"What it got said about Jonathan_Muha\"\n",
    "docs = db.similarity_search(query)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating our self-querying retriever\n",
    "\n",
    "Now we can instantiate our retriever. To do this we’ll need to provide some information upfront about the metadata fields that our documents support and a short description of the document contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata description\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"stream_name\",\n",
    "        description=\"The stream where the comment was poste. One of ['Jobs','Water Break','Safety & Operations','OSC, We Can Help','Flagger Force Connect','The Whiteboard','Test Stream']\",\n",
    "        type=\"object\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"created_date\",\n",
    "        description=\"The datetime when the comment was posted\",\n",
    "        type=\"object\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"post_id\",\n",
    "        description=\"The id of the post where the comment was posted\",\n",
    "        type=\"int64\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"comment_id\",\n",
    "        description=\"The id of the comment\",\n",
    "        type=\"int64\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"like_count\",\n",
    "        description=\"The number of likes received by the comment\",\n",
    "        type=\"int64\",        \n",
    "    ),    \n",
    "    AttributeInfo(\n",
    "        name=\"report_count\",\n",
    "        description=\"The number of reports where the comment appears\",\n",
    "        type=\"int64\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"username\",\n",
    "        description=\"The username of the author of the comment\",\n",
    "        type=\"object\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"author_user_id\",\n",
    "        description=\"The id of the author of the comment\",\n",
    "        type=\"object\",\n",
    "    ),    \n",
    "    AttributeInfo(\n",
    "        name=\"author_position\",\n",
    "        description=\"The position of the author of the comment. One of ['Advanced Crew Leader','Crew Member','Crew Leader','Weekend Dispatch','Lead Instructor','Area Supervisor','Field Trainer 1','Warehouse Coordinator','Field Trainer 2','Executive Assistant','Internal Communications Manager','Field Manager','Safety Professional','Internal Communications Coordinator', 'Employee Services Supervisor','Safety Advocate', and many more...]\",\n",
    "        type=\"object\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"author_status\",\n",
    "        description=\"The position of the author of the comment. One of ['active','suspended']\",\n",
    "        type=\"object\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Creating our self-querying retriever\n",
    "document_content_description = \"Comments on social network posts\"\n",
    "llm = ChatOllama(model=\"mistral\")\n",
    "\n",
    "retriever = SelfQueryRetriever.from_llm(    \n",
    "    llm,\n",
    "    db,\n",
    "    document_content_description,    \n",
    "    metadata_field_info,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Testing out the retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Congratulations', metadata={'author_position': 'Crew Leader', 'author_status': 'suspended', 'author_user_id': 'e62d292b-7a01-4aa9-ab5a-e6fbfaa6e326', 'comment_id': 3927754, 'created_date': '2022-01-26 00:17:59', 'like_count': 0, 'post_id': 4989194, 'report_count': 0, 'stream_name': 'Safety & Operations', 'username': 'Donnie_Ziegler'}),\n",
       " Document(page_content='Congratulations', metadata={'author_position': 'Advanced Crew Leader', 'author_status': 'active', 'author_user_id': '5a3ca39e-5c41-4501-8eab-6a9ed0a62044', 'comment_id': 4686674, 'created_date': '2022-08-14 02:01:54', 'like_count': 0, 'post_id': 5643777, 'report_count': 0, 'stream_name': 'Safety & Operations', 'username': 'William_MobleyJr'}),\n",
       " Document(page_content='Congratulations', metadata={'author_position': 'Crew Member', 'author_status': 'suspended', 'author_user_id': '74f383df-5aa7-4efb-af99-5f96405dadc8', 'comment_id': 5163635, 'created_date': '2022-12-17 00:01:52', 'like_count': 0, 'post_id': 6082644, 'report_count': 0, 'stream_name': 'Safety & Operations', 'username': 'Tiffanie_Gaskins'}),\n",
       " Document(page_content='Congratulations 👏👏', metadata={'author_position': 'Advanced Crew Leader', 'author_status': 'active', 'author_user_id': '9c0fe286-e9ab-4000-a826-dbe70230a4c2', 'comment_id': 5528987, 'created_date': '2023-03-26 19:08:11', 'like_count': 0, 'post_id': 6337268, 'report_count': 0, 'stream_name': 'Safety & Operations', 'username': 'Towanda_Gordon'})]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This example only specifies a query\n",
    "retriever.invoke(\"What are two comments about congratulations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "username\n",
       "FlaggerForce        8\n",
       "weekend_dispatch    8\n",
       "Karen_Stroup        8\n",
       "Linwood_DavisJr     6\n",
       "Jessica_Beers       5\n",
       "                   ..\n",
       "Deon_McDaniel       1\n",
       "Adrienne_Long       1\n",
       "Stephen_Michael     1\n",
       "Towanda_Gordon      1\n",
       "Kyndra_Edwards      1\n",
       "Name: count, Length: 201, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comments_to_test['username'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='What did the buffalo say to his son when he dropped him off at school?\\nBison!!!! 😂🤣😭 @Jeffrey_Williams @Seth_Lee 😂🤣😭', metadata={'author_position': 'Field Trainer 1', 'author_status': 'suspended', 'author_user_id': 'f1555029-1597-4d3e-9199-4ebc04ed9702', 'comment_id': 4695288, 'created_date': '2022-08-16 19:19:26', 'like_count': 6, 'post_id': 5653172, 'report_count': 0, 'stream_name': 'Water Break', 'username': 'Collette_Monaghan'}),\n",
       " Document(page_content='As @Julie_Snedeker mentioned the focus here is to stop tampering with Flagger Forced issued equipment. The cameras believe it or not are in the vehicles for YOUR SAFETY. If you pick up the cell phone it says to put it down... if your following to close it says to back off... it is easy to sit and nitpick a photo but it is difficult to follow company policy.', metadata={'author_position': 'Safety Manager', 'author_status': 'active', 'author_user_id': '2aac35e8-f970-4434-9b46-56274384cf89', 'comment_id': 6601009, 'created_date': '2023-12-28 01:54:16', 'like_count': 6, 'post_id': 7367779, 'report_count': 0, 'stream_name': 'Safety & Operations', 'username': 'Scott_Richwine'}),\n",
       " Document(page_content='The background is clearly in a parking lot... anyone who has towed a PCMS understands the drum bases go in the back of the pickup truck.', metadata={'author_position': 'Safety Manager', 'author_status': 'active', 'author_user_id': '2aac35e8-f970-4434-9b46-56274384cf89', 'comment_id': 6601009, 'created_date': '2023-12-28 01:54:16', 'like_count': 6, 'post_id': 7367779, 'report_count': 0, 'stream_name': 'Safety & Operations', 'username': 'Scott_Richwine'})]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This example only specifies a filter\n",
    "retriever.invoke(\"What is a highly liked (above 4) comment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment_id\n",
       "6601009    6\n",
       "4695288    6\n",
       "5959837    4\n",
       "3993841    4\n",
       "6468179    4\n",
       "          ..\n",
       "5031138    0\n",
       "5049534    0\n",
       "5067432    0\n",
       "5068273    0\n",
       "6865894    0\n",
       "Name: like_count, Length: 300, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group by to find the comments with highest number of likes\n",
    "df_comments_to_test.groupby('comment_id')['like_count'].sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting the client\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "PERSIST_DIRECTORY = \"C:\\\\Users\\\\eduar\\\\Documents\\\\Master_Thesis\\\\GenAI_Thesis_Beekeeper\\\\data\\\\datasets_db\"\n",
    "\n",
    "chromadb_client = chromadb.PersistentClient(path=PERSIST_DIRECTORY, settings=Settings(allow_reset=True))\n",
    "chromadb_client.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Thank you Robert, I appreciate your knowledge\"\n",
    "docs = db.similarity_search(query)\n",
    "print(docs[0].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "\n",
    "PERSIST_DIRECTORY = \"C:\\\\Users\\\\eduar\\\\Documents\\\\Master_Thesis\\\\GenAI_Thesis_Beekeeper\\\\data\\\\datasets_db\"\n",
    "# embeddings = SentenceTransformerEmbeddings(model_name=\"all-mpnet-base-v2\")\n",
    "embeddings = OllamaEmbeddings(model=\"mistral\") \n",
    "\n",
    "persistent_client = chromadb.PersistentClient(path=PERSIST_DIRECTORY, settings=Settings(allow_reset=True))\n",
    "collection_comments = persistent_client.get_or_create_collection(\"collection_comments\",\n",
    "                                                        metadata={\"hnsw:space\": \"l2\"}, # Squared L2 norm(l2) is the default, inner product('ip') or cosine similarity('cosine')                                                              \n",
    "                                                        embedding_function=embeddings\n",
    "                                                        )\n",
    " # Add data to collection\n",
    "collection_comments.add(documents=documents,\n",
    "                        metadatas=metadatas,\n",
    "                        ids=ids\n",
    "                        )\n",
    "\n",
    "langchain_chroma = Chroma(\n",
    "    client=persistent_client,\n",
    "    collection_name=\"collection_comments\",\n",
    "    embedding_function=embeddings\n",
    ")\n",
    "\n",
    "print(\"There are\", langchain_chroma._collection.count(), \"in the collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting the client\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "PERSIST_DIRECTORY = \"C:\\\\Users\\\\eduar\\\\Documents\\\\Master_Thesis\\\\GenAI_Thesis_Beekeeper\\\\data\\\\datasets_db\"\n",
    "\n",
    "chromadb_client = chromadb.PersistentClient(path=PERSIST_DIRECTORY, settings=Settings(allow_reset=True))\n",
    "chromadb_client.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "#from langchain_chroma import Chroma\n",
    "#from langchain_community.embeddings import OllamaEmbeddings\n",
    "#import chromadb.utils.embedding_functions as embedding_functions\n",
    "from chromadb.config import Settings\n",
    "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "      \n",
    "PERSIST_DIRECTORY = \"C:\\\\Users\\\\eduar\\\\Documents\\\\Master_Thesis\\\\GenAI_Thesis_Beekeeper\\\\data\\\\datasets_db\"\n",
    "embeddings = SentenceTransformerEmbeddings(model_name=\"all-mpnet-base-v2\")    \n",
    "    \n",
    "\n",
    "# Function to create and load data to the database\n",
    "\"\"\"\n",
    "The embedding function takes text as input, and performs tokenization and embedding. If no embedding function is supplied, Chroma will use sentence transformer as a default.\n",
    "https://docs.trychroma.com/embeddings#sentence-transformers\n",
    "By default, Chroma uses all-MiniLM-L6-v2\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def upload_to_chromadb(documents, metadatas, ids):\n",
    "    try:            \n",
    "        # create the open-source embedding function\n",
    "        # embedding = OllamaEmbeddings(model=\"mistral\")\n",
    "        # embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")   # Default\n",
    "        embeddings = SentenceTransformerEmbeddings(model_name=\"all-mpnet-base-v2\")          # Best model from included in ChromaDB\n",
    "        \n",
    "        # Initialize ChromaDB client\n",
    "        # load it into Chroma\n",
    "        db = Chroma.from_documents(documents, embeddings,\n",
    "                                    persist_directory=PERSIST_DIRECTORY)\n",
    "               \n",
    "        # Create a comment's collection\n",
    "        collection_comments = chromadb_client.create_collection(name=\"comments_collection\",\n",
    "                                                              metadata={\"hnsw:space\": \"l2\"}, # Squared L2 norm(l2) is the default, inner product('ip') or cosine similarity('cosine')                                                              \n",
    "                                                              embedding_function=embeddings\n",
    "                                                              )        \n",
    "        \n",
    "        # Add data to collection\n",
    "        collection_comments.add(documents=documents,\n",
    "                                metadatas=metadatas,\n",
    "                                ids=ids\n",
    "                                )\n",
    "        print(\"Data uploaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to upload data: {e}\")\n",
    "\n",
    "upload_to_chromadb(documents, metadatas, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ollama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
